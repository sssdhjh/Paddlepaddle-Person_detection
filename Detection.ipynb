{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-03-24T06:50:45.720725Z",
     "iopub.status.busy": "2023-03-24T06:50:45.720098Z",
     "iopub.status.idle": "2023-03-24T06:51:15.711946Z",
     "shell.execute_reply": "2023-03-24T06:51:15.710890Z",
     "shell.execute_reply.started": "2023-03-24T06:50:45.720690Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://mirror.baidu.com/pypi/simple\r\n",
      "Collecting paddlex==2.1.0\r\n",
      "  Downloading https://mirror.baidu.com/pypi/packages/ca/03/b401c6a34685aa698e7c2fbcfad029892cbfa4b562eaaa7722037fef86ed/paddlex-2.1.0-py3-none-any.whl (1.6 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: scipy in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlex==2.1.0) (1.3.0)\r\n",
      "Requirement already satisfied: visualdl>=2.2.2 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlex==2.1.0) (2.4.0)\r\n",
      "Collecting lap\r\n",
      "  Downloading https://mirror.baidu.com/pypi/packages/bf/64/d9fb6a75b15e783952b2fec6970f033462e67db32dc43dfbb404c14e91c2/lap-0.4.0.tar.gz (1.5 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\r\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\r\n",
      "\u001b[?25hCollecting motmetrics\r\n",
      "  Downloading https://mirror.baidu.com/pypi/packages/45/41/b019fe934eb811b9aba9b335f852305b804b9c66f098d7e35c2bdb09d1c8/motmetrics-1.2.5-py3-none-any.whl (161 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m161.1/161.1 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: shapely>=1.7.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlex==2.1.0) (2.0.1)\r\n",
      "Collecting paddleslim==2.2.1\r\n",
      "  Downloading https://mirror.baidu.com/pypi/packages/0b/dc/f46c4669d4cb35de23581a2380d55bf9d38bb6855aab1978fdb956d85da6/paddleslim-2.2.1-py3-none-any.whl (310 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m310.9/310.9 kB\u001b[0m \u001b[31m29.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting scikit-learn==0.23.2\r\n",
      "  Downloading https://mirror.baidu.com/pypi/packages/f4/cb/64623369f348e9bfb29ff898a57ac7c91ed4921f228e9726546614d63ccb/scikit_learn-0.23.2-cp37-cp37m-manylinux1_x86_64.whl (6.8 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: flask-cors in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlex==2.1.0) (3.0.8)\r\n",
      "Requirement already satisfied: tqdm in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlex==2.1.0) (4.65.0)\r\n",
      "Requirement already satisfied: pyyaml in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlex==2.1.0) (5.1.2)\r\n",
      "Requirement already satisfied: openpyxl in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlex==2.1.0) (3.0.5)\r\n",
      "Collecting pycocotools\r\n",
      "  Downloading https://mirror.baidu.com/pypi/packages/ef/c6/90220be3b39fbc4cbd203775ca47dd8dc97fae06fbd2b500637395621b7c/pycocotools-2.0.6.tar.gz (24 kB)\r\n",
      "  Installing build dependencies ... \u001b[?25ldone\r\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\r\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\r\n",
      "\u001b[?25hRequirement already satisfied: colorama in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlex==2.1.0) (0.4.4)\r\n",
      "Requirement already satisfied: opencv-python in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlex==2.1.0) (4.7.0.72)\r\n",
      "Requirement already satisfied: chardet in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlex==2.1.0) (3.0.4)\r\n",
      "Requirement already satisfied: pillow in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddleslim==2.2.1->paddlex==2.1.0) (8.2.0)\r\n",
      "Requirement already satisfied: pyzmq in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddleslim==2.2.1->paddlex==2.1.0) (23.2.1)\r\n",
      "Requirement already satisfied: matplotlib in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddleslim==2.2.1->paddlex==2.1.0) (2.2.3)\r\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from scikit-learn==0.23.2->paddlex==2.1.0) (0.14.1)\r\n",
      "Requirement already satisfied: numpy>=1.13.3 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from scikit-learn==0.23.2->paddlex==2.1.0) (1.19.5)\r\n",
      "Collecting threadpoolctl>=2.0.0\r\n",
      "  Downloading https://mirror.baidu.com/pypi/packages/61/cf/6e354304bcb9c6413c4e02a747b600061c21d38ba51e7e544ac7bc66aecc/threadpoolctl-3.1.0-py3-none-any.whl (14 kB)\r\n",
      "Requirement already satisfied: protobuf>=3.11.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl>=2.2.2->paddlex==2.1.0) (3.20.0)\r\n",
      "Requirement already satisfied: requests in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl>=2.2.2->paddlex==2.1.0) (2.24.0)\r\n",
      "Requirement already satisfied: pandas in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl>=2.2.2->paddlex==2.1.0) (1.1.5)\r\n",
      "Requirement already satisfied: Flask-Babel>=1.0.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl>=2.2.2->paddlex==2.1.0) (1.0.0)\r\n",
      "Requirement already satisfied: flask>=1.1.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl>=2.2.2->paddlex==2.1.0) (1.1.1)\r\n",
      "Requirement already satisfied: six>=1.14.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl>=2.2.2->paddlex==2.1.0) (1.16.0)\r\n",
      "Requirement already satisfied: bce-python-sdk in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl>=2.2.2->paddlex==2.1.0) (0.8.53)\r\n",
      "Collecting xmltodict>=0.12.0\r\n",
      "  Downloading https://mirror.baidu.com/pypi/packages/94/db/fd0326e331726f07ff7f40675cd86aa804bfd2e5016c727fa761c934990e/xmltodict-0.13.0-py2.py3-none-any.whl (10.0 kB)\r\n",
      "Requirement already satisfied: et-xmlfile in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from openpyxl->paddlex==2.1.0) (1.0.1)\r\n",
      "Requirement already satisfied: jdcal in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from openpyxl->paddlex==2.1.0) (1.4.1)\r\n",
      "Requirement already satisfied: itsdangerous>=0.24 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flask>=1.1.1->visualdl>=2.2.2->paddlex==2.1.0) (1.1.0)\r\n",
      "Requirement already satisfied: click>=5.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flask>=1.1.1->visualdl>=2.2.2->paddlex==2.1.0) (8.0.4)\r\n",
      "Requirement already satisfied: Jinja2>=2.10.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flask>=1.1.1->visualdl>=2.2.2->paddlex==2.1.0) (3.0.0)\r\n",
      "Requirement already satisfied: Werkzeug>=0.15 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flask>=1.1.1->visualdl>=2.2.2->paddlex==2.1.0) (0.16.0)\r\n",
      "Requirement already satisfied: Babel>=2.3 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from Flask-Babel>=1.0.0->visualdl>=2.2.2->paddlex==2.1.0) (2.8.0)\r\n",
      "Requirement already satisfied: pytz in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from Flask-Babel>=1.0.0->visualdl>=2.2.2->paddlex==2.1.0) (2019.3)\r\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from matplotlib->paddleslim==2.2.1->paddlex==2.1.0) (2.8.2)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from matplotlib->paddleslim==2.2.1->paddlex==2.1.0) (0.10.0)\r\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from matplotlib->paddleslim==2.2.1->paddlex==2.1.0) (3.0.9)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from matplotlib->paddleslim==2.2.1->paddlex==2.1.0) (1.1.0)\r\n",
      "Requirement already satisfied: pycryptodome>=3.8.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from bce-python-sdk->visualdl>=2.2.2->paddlex==2.1.0) (3.9.9)\r\n",
      "Requirement already satisfied: future>=0.6.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from bce-python-sdk->visualdl>=2.2.2->paddlex==2.1.0) (0.18.0)\r\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests->visualdl>=2.2.2->paddlex==2.1.0) (2.8)\r\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests->visualdl>=2.2.2->paddlex==2.1.0) (1.25.6)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests->visualdl>=2.2.2->paddlex==2.1.0) (2019.9.11)\r\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from click>=5.1->flask>=1.1.1->visualdl>=2.2.2->paddlex==2.1.0) (4.2.0)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0.0rc2 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from Jinja2>=2.10.1->flask>=1.1.1->visualdl>=2.2.2->paddlex==2.1.0) (2.0.1)\r\n",
      "Requirement already satisfied: setuptools in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from kiwisolver>=1.0.1->matplotlib->paddleslim==2.2.1->paddlex==2.1.0) (41.4.0)\r\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from importlib-metadata->click>=5.1->flask>=1.1.1->visualdl>=2.2.2->paddlex==2.1.0) (3.8.1)\r\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from importlib-metadata->click>=5.1->flask>=1.1.1->visualdl>=2.2.2->paddlex==2.1.0) (4.3.0)\r\n",
      "Building wheels for collected packages: lap, pycocotools\r\n",
      "  Building wheel for lap (setup.py) ... \u001b[?25ldone\r\n",
      "\u001b[?25h  Created wheel for lap: filename=lap-0.4.0-cp37-cp37m-linux_x86_64.whl size=1593868 sha256=6cc04c93055687a2451e9a476ae00578651f26d47b9c0835b5d2d88048849deb\r\n",
      "  Stored in directory: /home/aistudio/.cache/pip/wheels/95/5f/20/9e2b2cfb8b2bfae5a5374e947511a47c8909e74aaf6d6d4464\r\n",
      "  Building wheel for pycocotools (pyproject.toml) ... \u001b[?25ldone\r\n",
      "\u001b[?25h  Created wheel for pycocotools: filename=pycocotools-2.0.6-cp37-cp37m-linux_x86_64.whl size=275102 sha256=dc8a32aad8bf85daa18b705126356566ff7aa9ae16319a6db38067b49ab5f622\r\n",
      "  Stored in directory: /home/aistudio/.cache/pip/wheels/aa/8d/b1/0b72d6fd177590eb1d615c319107402bcb326ebe94ac41b330\r\n",
      "Successfully built lap pycocotools\r\n",
      "Installing collected packages: lap, xmltodict, threadpoolctl, scikit-learn, pycocotools, paddleslim, motmetrics, paddlex\r\n",
      "  Attempting uninstall: scikit-learn\r\n",
      "    Found existing installation: scikit-learn 0.22.1\r\n",
      "    Uninstalling scikit-learn-0.22.1:\r\n",
      "      Successfully uninstalled scikit-learn-0.22.1\r\n",
      "Successfully installed lap-0.4.0 motmetrics-1.2.5 paddleslim-2.2.1 paddlex-2.1.0 pycocotools-2.0.6 scikit-learn-0.23.2 threadpoolctl-3.1.0 xmltodict-0.13.0\r\n",
      "\r\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.0.1\u001b[0m\r\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "%cd ~  # 设置当前目录路径\n",
    "!unzip data/data132692/VOCdataset.zip -d work/dataset  # 将自制数据集进行解压\n",
    "!pip install paddlex==2.1.0 -i https://mirror.baidu.com/pypi/simple  # 下载paddlex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[03-12 16:34:28 MainThread @logger.py:242]\u001b[0m Argv: /opt/conda/envs/python35-paddle120-env/bin/paddlex --split_dataset --format VOC --dataset_dir work/dataset/VOCdataset --val_value 0.2 --test_value 0.1\r\n",
      "\u001b[0m\u001b[33m[03-12 16:34:28 MainThread @utils.py:79]\u001b[0m \u001b[5m\u001b[33mWRN\u001b[0m paddlepaddle version: 2.3.2. The dynamic graph version of PARL is under development, not fully tested and supported\r\n",
      "\u001b[0m/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/parl/remote/communication.py:38: FutureWarning: 'pyarrow.default_serialization_context' is deprecated as of 2.0.0 and will be removed in a future version. Use pickle or the pyarrow IPC functionality instead.\r\n",
      "  context = pyarrow.default_serialization_context()\r\n",
      "\u001b[0m/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/matplotlib/__init__.py:107: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\r\n",
      "  from collections import MutableMapping\r\n",
      "\u001b[0m/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/matplotlib/rcsetup.py:20: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\r\n",
      "  from collections import Iterable, Mapping\r\n",
      "\u001b[0m/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/matplotlib/colors.py:53: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\r\n",
      "  from collections import Sized\r\n",
      "\u001b[0m2023-03-12 16:34:29,842-WARNING: type object 'QuantizationTransformPass' has no attribute '_supported_quantizable_op_type'\r\n",
      "\u001b[0m2023-03-12 16:34:29,842-WARNING: If you want to use training-aware and post-training quantization, please use Paddle >= 1.8.4 or develop version\r\n",
      "\u001b[0m2023-03-12 16:34:32 [INFO]\tDataset split starts...\u001b[0m\r\n",
      "\u001b[0m2023-03-12 16:34:32 [INFO]\tDataset split done.\u001b[0m\r\n",
      "\u001b[0m2023-03-12 16:34:32 [INFO]\tTrain samples: 490\u001b[0m\r\n",
      "\u001b[0m2023-03-12 16:34:32 [INFO]\tEval samples: 140\u001b[0m\r\n",
      "\u001b[0m2023-03-12 16:34:32 [INFO]\tTest samples: 70\u001b[0m\r\n",
      "\u001b[0m2023-03-12 16:34:32 [INFO]\tSplit files saved in work/dataset/VOCdataset\u001b[0m\r\n",
      "\u001b[0m\u001b[0m"
     ]
    }
   ],
   "source": [
    "!paddlex --split_dataset --format VOC --dataset_dir 'work/dataset/VOCdataset' --val_value 0.2 --test_value 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[03-12 16:34:35 MainThread @utils.py:79] WRN paddlepaddle version: 2.3.2. The dynamic graph version of PARL is under development, not fully tested and supported\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/parl/remote/communication.py:38: FutureWarning: 'pyarrow.default_serialization_context' is deprecated as of 2.0.0 and will be removed in a future version. Use pickle or the pyarrow IPC functionality instead.\r\n",
      "  context = pyarrow.default_serialization_context()\r\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/matplotlib/__init__.py:107: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\r\n",
      "  from collections import MutableMapping\r\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/matplotlib/rcsetup.py:20: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\r\n",
      "  from collections import Iterable, Mapping\r\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/matplotlib/colors.py:53: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\r\n",
      "  from collections import Sized\r\n",
      "2023-03-12 16:34:36,750-WARNING: type object 'QuantizationTransformPass' has no attribute '_supported_quantizable_op_type'\r\n",
      "2023-03-12 16:34:36,752-WARNING: If you want to use training-aware and post-training quantization, please use Paddle >= 1.8.4 or develop version\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-03-12 16:34:38 [INFO]\tStarting to read file list from dataset...\r\n",
      "2023-03-12 16:34:38 [INFO]\t490 samples in file work/dataset/VOCdataset/train_list.txt, including 490 positive samples and 0 negative samples.\r\n",
      "creating index...\r\n",
      "index created!\r\n",
      "2023-03-12 16:34:38 [INFO]\tStarting to read file list from dataset...\r\n",
      "2023-03-12 16:34:38 [INFO]\t140 samples in file work/dataset/VOCdataset/val_list.txt, including 140 positive samples and 0 negative samples.\r\n",
      "creating index...\r\n",
      "index created!\r\n"
     ]
    }
   ],
   "source": [
    "# 数据增强\n",
    "import paddlex as pdx\n",
    "from paddlex import transforms as T\n",
    "train_transforms = T.Compose([\n",
    "    T.RandomHorizontalFlip(),\n",
    "    T.RandomDistort(),\n",
    "    T.RandomExpand(),\n",
    "    T.RandomCrop(),\n",
    "    T.ResizeByShort(short_size=250, max_size=-1),\n",
    "    T.Normalize()\n",
    "])\n",
    "eval_transforms = T.Compose([\n",
    "    T.ResizeByShort(short_size=250, max_size=-1),\n",
    "    T.Normalize()\n",
    "])\n",
    "\n",
    "# 加载数据集\n",
    "train_dataset = pdx.datasets.VOCDetection(\n",
    "                        data_dir=r'work/dataset/VOCdataset',\n",
    "                        file_list=r'work/dataset/VOCdataset/train_list.txt',\n",
    "                        label_list=r'work/dataset/VOCdataset/labels.txt',\n",
    "                        transforms=train_transforms,\n",
    "                        # shuffle=True\n",
    "                        )\n",
    "eval_dataset = pdx.datasets.VOCDetection(\n",
    "                        data_dir=r'work/dataset/VOCdataset',\n",
    "                        file_list=r'work/dataset/VOCdataset/val_list.txt',\n",
    "                        label_list=r'work/dataset/VOCdataset/labels.txt',\n",
    "                        transforms=eval_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\r\n",
      "2023-03-12 16:34:39 [INFO]\tDownloading ResNet50_cos_pretrained.pdparams from https://paddledet.bj.bcebos.com/models/pretrained/ResNet50_cos_pretrained.pdparams\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0312 16:34:38.871008   205 gpu_resources.cc:61] Please NOTE: device: 0, GPU Compute Capability: 7.0, Driver API Version: 11.2, Runtime API Version: 11.2\r\n",
      "W0312 16:34:38.876703   205 gpu_resources.cc:91] device: 0, cuDNN Version: 8.2.\r\n",
      "100%|██████████| 92063/92063 [00:05<00:00, 17697.11KB/s]\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-03-12 16:34:44 [INFO]\tLoading pretrained model from output/faster_rcnn_r50_fpn/pretrain/ResNet50_cos_pretrained.pdparams\r\n",
      "2023-03-12 16:34:44 [WARNING]\tneck.fpn_inner_res2_sum_lateral.weight is not in pretrained model\r\n",
      "2023-03-12 16:34:44 [WARNING]\tneck.fpn_inner_res2_sum_lateral.bias is not in pretrained model\r\n",
      "2023-03-12 16:34:44 [WARNING]\tneck.fpn_res2_sum.weight is not in pretrained model\r\n",
      "2023-03-12 16:34:44 [WARNING]\tneck.fpn_res2_sum.bias is not in pretrained model\r\n",
      "2023-03-12 16:34:44 [WARNING]\tneck.fpn_inner_res3_sum_lateral.weight is not in pretrained model\r\n",
      "2023-03-12 16:34:44 [WARNING]\tneck.fpn_inner_res3_sum_lateral.bias is not in pretrained model\r\n",
      "2023-03-12 16:34:44 [WARNING]\tneck.fpn_res3_sum.weight is not in pretrained model\r\n",
      "2023-03-12 16:34:44 [WARNING]\tneck.fpn_res3_sum.bias is not in pretrained model\r\n",
      "2023-03-12 16:34:44 [WARNING]\tneck.fpn_inner_res4_sum_lateral.weight is not in pretrained model\r\n",
      "2023-03-12 16:34:44 [WARNING]\tneck.fpn_inner_res4_sum_lateral.bias is not in pretrained model\r\n",
      "2023-03-12 16:34:44 [WARNING]\tneck.fpn_res4_sum.weight is not in pretrained model\r\n",
      "2023-03-12 16:34:44 [WARNING]\tneck.fpn_res4_sum.bias is not in pretrained model\r\n",
      "2023-03-12 16:34:44 [WARNING]\tneck.fpn_inner_res5_sum.weight is not in pretrained model\r\n",
      "2023-03-12 16:34:44 [WARNING]\tneck.fpn_inner_res5_sum.bias is not in pretrained model\r\n",
      "2023-03-12 16:34:44 [WARNING]\tneck.fpn_res5_sum.weight is not in pretrained model\r\n",
      "2023-03-12 16:34:44 [WARNING]\tneck.fpn_res5_sum.bias is not in pretrained model\r\n",
      "2023-03-12 16:34:44 [WARNING]\trpn_head.rpn_feat.rpn_conv.weight is not in pretrained model\r\n",
      "2023-03-12 16:34:44 [WARNING]\trpn_head.rpn_feat.rpn_conv.bias is not in pretrained model\r\n",
      "2023-03-12 16:34:44 [WARNING]\trpn_head.rpn_rois_score.weight is not in pretrained model\r\n",
      "2023-03-12 16:34:44 [WARNING]\trpn_head.rpn_rois_score.bias is not in pretrained model\r\n",
      "2023-03-12 16:34:44 [WARNING]\trpn_head.rpn_rois_delta.weight is not in pretrained model\r\n",
      "2023-03-12 16:34:44 [WARNING]\trpn_head.rpn_rois_delta.bias is not in pretrained model\r\n",
      "2023-03-12 16:34:44 [WARNING]\tbbox_head.head.fc6.weight is not in pretrained model\r\n",
      "2023-03-12 16:34:44 [WARNING]\tbbox_head.head.fc6.bias is not in pretrained model\r\n",
      "2023-03-12 16:34:44 [WARNING]\tbbox_head.head.fc7.weight is not in pretrained model\r\n",
      "2023-03-12 16:34:44 [WARNING]\tbbox_head.head.fc7.bias is not in pretrained model\r\n",
      "2023-03-12 16:34:44 [WARNING]\tbbox_head.bbox_score.weight is not in pretrained model\r\n",
      "2023-03-12 16:34:44 [WARNING]\tbbox_head.bbox_score.bias is not in pretrained model\r\n",
      "2023-03-12 16:34:44 [WARNING]\tbbox_head.bbox_delta.weight is not in pretrained model\r\n",
      "2023-03-12 16:34:44 [WARNING]\tbbox_head.bbox_delta.bias is not in pretrained model\r\n",
      "2023-03-12 16:34:44 [INFO]\tThere are 265/295 variables loaded into FasterRCNN.\r\n",
      "2023-03-12 16:34:51 [INFO]\t[TRAIN] Epoch=1/10, Step=10/490, loss_rpn_cls=0.683901, loss_rpn_reg=0.016006, loss_bbox_cls=0.222010, loss_bbox_reg=0.018043, loss=0.939959, lr=0.000250, time_each_step=0.67s, eta=0:56:25\r\n",
      "2023-03-12 16:34:53 [INFO]\t[TRAIN] Epoch=1/10, Step=20/490, loss_rpn_cls=0.629229, loss_rpn_reg=0.007990, loss_bbox_cls=0.042717, loss_bbox_reg=0.000145, loss=0.680081, lr=0.000250, time_each_step=0.14s, eta=0:12:3\r\n",
      "2023-03-12 16:34:54 [INFO]\t[TRAIN] Epoch=1/10, Step=30/490, loss_rpn_cls=0.577947, loss_rpn_reg=0.014060, loss_bbox_cls=0.112831, loss_bbox_reg=0.047623, loss=0.752461, lr=0.000250, time_each_step=0.16s, eta=0:13:2\r\n",
      "2023-03-12 16:34:57 [INFO]\t[TRAIN] Epoch=1/10, Step=40/490, loss_rpn_cls=0.388991, loss_rpn_reg=0.012125, loss_bbox_cls=0.087677, loss_bbox_reg=0.000350, loss=0.489143, lr=0.000250, time_each_step=0.27s, eta=0:22:23\r\n",
      "2023-03-12 16:34:59 [INFO]\t[TRAIN] Epoch=1/10, Step=50/490, loss_rpn_cls=0.205171, loss_rpn_reg=0.009249, loss_bbox_cls=0.047836, loss_bbox_reg=0.000214, loss=0.262470, lr=0.000250, time_each_step=0.16s, eta=0:13:39\r\n",
      "2023-03-12 16:35:00 [INFO]\t[TRAIN] Epoch=1/10, Step=60/490, loss_rpn_cls=0.192838, loss_rpn_reg=0.007171, loss_bbox_cls=0.146415, loss_bbox_reg=0.101352, loss=0.447777, lr=0.000250, time_each_step=0.15s, eta=0:12:16\r\n",
      "2023-03-12 16:35:02 [INFO]\t[TRAIN] Epoch=1/10, Step=70/490, loss_rpn_cls=0.184388, loss_rpn_reg=0.071969, loss_bbox_cls=0.183412, loss_bbox_reg=0.111832, loss=0.551601, lr=0.000250, time_each_step=0.15s, eta=0:12:33\r\n",
      "2023-03-12 16:35:03 [INFO]\t[TRAIN] Epoch=1/10, Step=80/490, loss_rpn_cls=0.139427, loss_rpn_reg=0.005842, loss_bbox_cls=0.055566, loss_bbox_reg=0.046622, loss=0.247457, lr=0.000250, time_each_step=0.15s, eta=0:12:22\r\n",
      "2023-03-12 16:35:05 [INFO]\t[TRAIN] Epoch=1/10, Step=90/490, loss_rpn_cls=0.072979, loss_rpn_reg=0.008120, loss_bbox_cls=0.027420, loss_bbox_reg=0.000813, loss=0.109332, lr=0.000250, time_each_step=0.16s, eta=0:13:24\r\n",
      "2023-03-12 16:35:06 [INFO]\t[TRAIN] Epoch=1/10, Step=100/490, loss_rpn_cls=0.080085, loss_rpn_reg=0.004777, loss_bbox_cls=0.019449, loss_bbox_reg=0.001247, loss=0.105559, lr=0.000250, time_each_step=0.16s, eta=0:12:51\r\n",
      "2023-03-12 16:35:08 [INFO]\t[TRAIN] Epoch=1/10, Step=110/490, loss_rpn_cls=0.039673, loss_rpn_reg=0.003846, loss_bbox_cls=0.056664, loss_bbox_reg=0.026814, loss=0.126997, lr=0.000250, time_each_step=0.14s, eta=0:11:22\r\n",
      "2023-03-12 16:35:10 [INFO]\t[TRAIN] Epoch=1/10, Step=120/490, loss_rpn_cls=0.171448, loss_rpn_reg=0.049219, loss_bbox_cls=0.078512, loss_bbox_reg=0.065558, loss=0.364738, lr=0.000250, time_each_step=0.18s, eta=0:15:2\r\n",
      "2023-03-12 16:35:12 [INFO]\t[TRAIN] Epoch=1/10, Step=130/490, loss_rpn_cls=0.110689, loss_rpn_reg=0.023953, loss_bbox_cls=0.055043, loss_bbox_reg=0.034331, loss=0.224015, lr=0.000250, time_each_step=0.19s, eta=0:15:49\r\n",
      "2023-03-12 16:35:13 [INFO]\t[TRAIN] Epoch=1/10, Step=140/490, loss_rpn_cls=0.063196, loss_rpn_reg=0.010854, loss_bbox_cls=0.073665, loss_bbox_reg=0.086818, loss=0.234533, lr=0.000250, time_each_step=0.18s, eta=0:14:46\r\n",
      "2023-03-12 16:35:15 [INFO]\t[TRAIN] Epoch=1/10, Step=150/490, loss_rpn_cls=0.059363, loss_rpn_reg=0.011827, loss_bbox_cls=0.056047, loss_bbox_reg=0.038521, loss=0.165758, lr=0.000250, time_each_step=0.19s, eta=0:15:31\r\n",
      "2023-03-12 16:35:17 [INFO]\t[TRAIN] Epoch=1/10, Step=160/490, loss_rpn_cls=0.035023, loss_rpn_reg=0.002815, loss_bbox_cls=0.092723, loss_bbox_reg=0.081216, loss=0.211778, lr=0.000250, time_each_step=0.19s, eta=0:15:30\r\n",
      "2023-03-12 16:35:19 [INFO]\t[TRAIN] Epoch=1/10, Step=170/490, loss_rpn_cls=0.070604, loss_rpn_reg=0.008125, loss_bbox_cls=0.057485, loss_bbox_reg=0.048721, loss=0.184935, lr=0.000250, time_each_step=0.18s, eta=0:14:46\r\n",
      "2023-03-12 16:35:21 [INFO]\t[TRAIN] Epoch=1/10, Step=180/490, loss_rpn_cls=0.048077, loss_rpn_reg=0.015062, loss_bbox_cls=0.048697, loss_bbox_reg=0.049224, loss=0.161061, lr=0.000250, time_each_step=0.19s, eta=0:15:3\r\n",
      "2023-03-12 16:35:23 [INFO]\t[TRAIN] Epoch=1/10, Step=190/490, loss_rpn_cls=0.037512, loss_rpn_reg=0.003333, loss_bbox_cls=0.063280, loss_bbox_reg=0.039964, loss=0.144089, lr=0.000250, time_each_step=0.18s, eta=0:14:55\r\n",
      "2023-03-12 16:35:25 [INFO]\t[TRAIN] Epoch=1/10, Step=200/490, loss_rpn_cls=0.074836, loss_rpn_reg=0.009670, loss_bbox_cls=0.054664, loss_bbox_reg=0.043143, loss=0.182312, lr=0.000250, time_each_step=0.19s, eta=0:15:4\r\n",
      "2023-03-12 16:35:26 [INFO]\t[TRAIN] Epoch=1/10, Step=210/490, loss_rpn_cls=0.023378, loss_rpn_reg=0.005287, loss_bbox_cls=0.064298, loss_bbox_reg=0.071229, loss=0.164192, lr=0.000250, time_each_step=0.18s, eta=0:14:28\r\n",
      "2023-03-12 16:35:28 [INFO]\t[TRAIN] Epoch=1/10, Step=220/490, loss_rpn_cls=0.046835, loss_rpn_reg=0.020624, loss_bbox_cls=0.205523, loss_bbox_reg=0.222418, loss=0.495399, lr=0.000250, time_each_step=0.18s, eta=0:14:30\r\n",
      "2023-03-12 16:35:30 [INFO]\t[TRAIN] Epoch=1/10, Step=230/490, loss_rpn_cls=0.029344, loss_rpn_reg=0.006338, loss_bbox_cls=0.063225, loss_bbox_reg=0.072271, loss=0.171177, lr=0.000250, time_each_step=0.19s, eta=0:14:59\r\n",
      "2023-03-12 16:35:32 [INFO]\t[TRAIN] Epoch=1/10, Step=240/490, loss_rpn_cls=0.027695, loss_rpn_reg=0.008802, loss_bbox_cls=0.289830, loss_bbox_reg=0.262142, loss=0.588468, lr=0.000250, time_each_step=0.2s, eta=0:15:46\r\n",
      "2023-03-12 16:35:34 [INFO]\t[TRAIN] Epoch=1/10, Step=250/490, loss_rpn_cls=0.020176, loss_rpn_reg=0.005498, loss_bbox_cls=0.063326, loss_bbox_reg=0.029585, loss=0.118586, lr=0.000250, time_each_step=0.2s, eta=0:16:7\r\n",
      "2023-03-12 16:35:36 [INFO]\t[TRAIN] Epoch=1/10, Step=260/490, loss_rpn_cls=0.016525, loss_rpn_reg=0.004094, loss_bbox_cls=0.079235, loss_bbox_reg=0.123475, loss=0.223328, lr=0.000250, time_each_step=0.18s, eta=0:14:21\r\n",
      "2023-03-12 16:35:38 [INFO]\t[TRAIN] Epoch=1/10, Step=270/490, loss_rpn_cls=0.030455, loss_rpn_reg=0.013661, loss_bbox_cls=0.050793, loss_bbox_reg=0.096040, loss=0.190948, lr=0.000250, time_each_step=0.19s, eta=0:14:45\r\n",
      "2023-03-12 16:35:40 [INFO]\t[TRAIN] Epoch=1/10, Step=280/490, loss_rpn_cls=0.025337, loss_rpn_reg=0.002641, loss_bbox_cls=0.042045, loss_bbox_reg=0.046802, loss=0.116825, lr=0.000250, time_each_step=0.18s, eta=0:14:34\r\n",
      "2023-03-12 16:35:41 [INFO]\t[TRAIN] Epoch=1/10, Step=290/490, loss_rpn_cls=0.021474, loss_rpn_reg=0.003450, loss_bbox_cls=0.061475, loss_bbox_reg=0.050173, loss=0.136572, lr=0.000250, time_each_step=0.18s, eta=0:13:53\r\n",
      "2023-03-12 16:35:43 [INFO]\t[TRAIN] Epoch=1/10, Step=300/490, loss_rpn_cls=0.034647, loss_rpn_reg=0.007144, loss_bbox_cls=0.079510, loss_bbox_reg=0.087857, loss=0.209158, lr=0.000250, time_each_step=0.19s, eta=0:15:13\r\n",
      "2023-03-12 16:35:45 [INFO]\t[TRAIN] Epoch=1/10, Step=310/490, loss_rpn_cls=0.081041, loss_rpn_reg=0.013003, loss_bbox_cls=0.171571, loss_bbox_reg=0.186426, loss=0.452040, lr=0.000250, time_each_step=0.19s, eta=0:14:46\r\n",
      "2023-03-12 16:35:47 [INFO]\t[TRAIN] Epoch=1/10, Step=320/490, loss_rpn_cls=0.020900, loss_rpn_reg=0.002699, loss_bbox_cls=0.036554, loss_bbox_reg=0.042755, loss=0.102908, lr=0.000250, time_each_step=0.19s, eta=0:14:57\r\n",
      "2023-03-12 16:35:49 [INFO]\t[TRAIN] Epoch=1/10, Step=330/490, loss_rpn_cls=0.051961, loss_rpn_reg=0.025590, loss_bbox_cls=0.113999, loss_bbox_reg=0.086249, loss=0.277799, lr=0.000250, time_each_step=0.18s, eta=0:14:18\r\n",
      "2023-03-12 16:35:51 [INFO]\t[TRAIN] Epoch=1/10, Step=340/490, loss_rpn_cls=0.036531, loss_rpn_reg=0.004403, loss_bbox_cls=0.076768, loss_bbox_reg=0.076843, loss=0.194544, lr=0.000250, time_each_step=0.19s, eta=0:14:30\r\n",
      "2023-03-12 16:35:53 [INFO]\t[TRAIN] Epoch=1/10, Step=350/490, loss_rpn_cls=0.039538, loss_rpn_reg=0.009532, loss_bbox_cls=0.074892, loss_bbox_reg=0.124940, loss=0.248901, lr=0.000250, time_each_step=0.19s, eta=0:14:33\r\n",
      "2023-03-12 16:35:54 [INFO]\t[TRAIN] Epoch=1/10, Step=360/490, loss_rpn_cls=0.055426, loss_rpn_reg=0.019016, loss_bbox_cls=0.061079, loss_bbox_reg=0.069943, loss=0.205465, lr=0.000250, time_each_step=0.18s, eta=0:13:55\r\n",
      "2023-03-12 16:35:56 [INFO]\t[TRAIN] Epoch=1/10, Step=370/490, loss_rpn_cls=0.022457, loss_rpn_reg=0.002950, loss_bbox_cls=0.034708, loss_bbox_reg=0.050010, loss=0.110126, lr=0.000250, time_each_step=0.19s, eta=0:14:43\r\n",
      "2023-03-12 16:35:58 [INFO]\t[TRAIN] Epoch=1/10, Step=380/490, loss_rpn_cls=0.017971, loss_rpn_reg=0.002525, loss_bbox_cls=0.031082, loss_bbox_reg=0.042840, loss=0.094418, lr=0.000250, time_each_step=0.19s, eta=0:14:40\r\n",
      "2023-03-12 16:36:00 [INFO]\t[TRAIN] Epoch=1/10, Step=390/490, loss_rpn_cls=0.014225, loss_rpn_reg=0.002382, loss_bbox_cls=0.041209, loss_bbox_reg=0.022851, loss=0.080667, lr=0.000250, time_each_step=0.18s, eta=0:14:7\r\n",
      "2023-03-12 16:36:02 [INFO]\t[TRAIN] Epoch=1/10, Step=400/490, loss_rpn_cls=0.016926, loss_rpn_reg=0.002770, loss_bbox_cls=0.067669, loss_bbox_reg=0.040484, loss=0.127849, lr=0.000250, time_each_step=0.18s, eta=0:14:14\r\n",
      "2023-03-12 16:36:04 [INFO]\t[TRAIN] Epoch=1/10, Step=410/490, loss_rpn_cls=0.128435, loss_rpn_reg=0.056971, loss_bbox_cls=0.087044, loss_bbox_reg=0.092153, loss=0.364602, lr=0.000250, time_each_step=0.23s, eta=0:17:24\r\n",
      "2023-03-12 16:36:06 [INFO]\t[TRAIN] Epoch=1/10, Step=420/490, loss_rpn_cls=0.021723, loss_rpn_reg=0.004698, loss_bbox_cls=0.041111, loss_bbox_reg=0.033518, loss=0.101050, lr=0.000250, time_each_step=0.19s, eta=0:14:44\r\n",
      "2023-03-12 16:36:08 [INFO]\t[TRAIN] Epoch=1/10, Step=430/490, loss_rpn_cls=0.135628, loss_rpn_reg=0.042779, loss_bbox_cls=0.057084, loss_bbox_reg=0.043348, loss=0.278839, lr=0.000250, time_each_step=0.19s, eta=0:14:53\r\n",
      "2023-03-12 16:36:10 [INFO]\t[TRAIN] Epoch=1/10, Step=440/490, loss_rpn_cls=0.023050, loss_rpn_reg=0.006303, loss_bbox_cls=0.035588, loss_bbox_reg=0.046297, loss=0.111237, lr=0.000250, time_each_step=0.2s, eta=0:15:21\r\n",
      "2023-03-12 16:36:12 [INFO]\t[TRAIN] Epoch=1/10, Step=450/490, loss_rpn_cls=0.030096, loss_rpn_reg=0.010870, loss_bbox_cls=0.059957, loss_bbox_reg=0.090666, loss=0.191589, lr=0.000250, time_each_step=0.19s, eta=0:14:17\r\n",
      "2023-03-12 16:36:14 [INFO]\t[TRAIN] Epoch=1/10, Step=460/490, loss_rpn_cls=0.019093, loss_rpn_reg=0.004047, loss_bbox_cls=0.043133, loss_bbox_reg=0.022353, loss=0.088626, lr=0.000250, time_each_step=0.21s, eta=0:15:48\r\n",
      "2023-03-12 16:36:16 [INFO]\t[TRAIN] Epoch=1/10, Step=470/490, loss_rpn_cls=0.040497, loss_rpn_reg=0.013163, loss_bbox_cls=0.084550, loss_bbox_reg=0.096325, loss=0.234536, lr=0.000250, time_each_step=0.21s, eta=0:16:8\r\n",
      "2023-03-12 16:36:18 [INFO]\t[TRAIN] Epoch=1/10, Step=480/490, loss_rpn_cls=0.024759, loss_rpn_reg=0.005879, loss_bbox_cls=0.045808, loss_bbox_reg=0.040140, loss=0.116586, lr=0.000250, time_each_step=0.19s, eta=0:14:14\r\n",
      "2023-03-12 16:36:20 [INFO]\t[TRAIN] Epoch=1/10, Step=490/490, loss_rpn_cls=0.011574, loss_rpn_reg=0.003269, loss_bbox_cls=0.069092, loss_bbox_reg=0.067174, loss=0.151109, lr=0.000250, time_each_step=0.19s, eta=0:14:11\r\n",
      "2023-03-12 16:36:20 [INFO]\t[TRAIN] Epoch 1 finished, loss_rpn_cls=0.10574465, loss_rpn_reg=0.012723012, loss_bbox_cls=0.07973736, loss_bbox_reg=0.059736535, loss=0.25794157 .\r\n",
      "2023-03-12 16:36:20 [INFO]\tStart to evaluate(total_samples=140, total_steps=140)...\r\n",
      "2023-03-12 16:36:36 [INFO]\tAccumulating evaluatation results...\r\n",
      "2023-03-12 16:36:36 [INFO]\t[EVAL] Finished, Epoch=1, bbox_map=41.871642 .\r\n",
      "2023-03-12 16:36:37 [INFO]\tModel saved in output/faster_rcnn_r50_fpn/best_model.\r\n",
      "2023-03-12 16:36:37 [INFO]\tCurrent evaluated best model on eval_dataset is epoch_1, bbox_map=41.87164221161458\r\n",
      "2023-03-12 16:36:38 [INFO]\tModel saved in output/faster_rcnn_r50_fpn/epoch_1.\r\n",
      "2023-03-12 16:36:41 [INFO]\t[TRAIN] Epoch=2/10, Step=10/490, loss_rpn_cls=0.028013, loss_rpn_reg=0.007543, loss_bbox_cls=0.076284, loss_bbox_reg=0.092663, loss=0.204503, lr=0.000250, time_each_step=0.23s, eta=0:19:17\r\n",
      "2023-03-12 16:36:42 [INFO]\t[TRAIN] Epoch=2/10, Step=20/490, loss_rpn_cls=0.028505, loss_rpn_reg=0.011317, loss_bbox_cls=0.058082, loss_bbox_reg=0.052261, loss=0.150166, lr=0.000250, time_each_step=0.18s, eta=0:15:39\r\n",
      "2023-03-12 16:36:44 [INFO]\t[TRAIN] Epoch=2/10, Step=30/490, loss_rpn_cls=0.016588, loss_rpn_reg=0.003599, loss_bbox_cls=0.043075, loss_bbox_reg=0.046098, loss=0.109360, lr=0.000250, time_each_step=0.19s, eta=0:16:14\r\n",
      "2023-03-12 16:36:46 [INFO]\t[TRAIN] Epoch=2/10, Step=40/490, loss_rpn_cls=0.065278, loss_rpn_reg=0.025403, loss_bbox_cls=0.073873, loss_bbox_reg=0.060033, loss=0.224587, lr=0.000250, time_each_step=0.19s, eta=0:15:53\r\n",
      "2023-03-12 16:36:48 [INFO]\t[TRAIN] Epoch=2/10, Step=50/490, loss_rpn_cls=0.018710, loss_rpn_reg=0.006699, loss_bbox_cls=0.046923, loss_bbox_reg=0.056332, loss=0.128665, lr=0.000250, time_each_step=0.18s, eta=0:15:43\r\n",
      "2023-03-12 16:36:50 [INFO]\t[TRAIN] Epoch=2/10, Step=60/490, loss_rpn_cls=0.024185, loss_rpn_reg=0.002769, loss_bbox_cls=0.046827, loss_bbox_reg=0.060930, loss=0.134712, lr=0.000250, time_each_step=0.21s, eta=0:17:48\r\n",
      "2023-03-12 16:36:52 [INFO]\t[TRAIN] Epoch=2/10, Step=70/490, loss_rpn_cls=0.049114, loss_rpn_reg=0.029454, loss_bbox_cls=0.075703, loss_bbox_reg=0.114778, loss=0.269049, lr=0.000250, time_each_step=0.18s, eta=0:15:18\r\n",
      "2023-03-12 16:36:54 [INFO]\t[TRAIN] Epoch=2/10, Step=80/490, loss_rpn_cls=0.026057, loss_rpn_reg=0.001166, loss_bbox_cls=0.043549, loss_bbox_reg=0.065831, loss=0.136603, lr=0.000250, time_each_step=0.18s, eta=0:15:21\r\n",
      "2023-03-12 16:36:56 [INFO]\t[TRAIN] Epoch=2/10, Step=90/490, loss_rpn_cls=0.019721, loss_rpn_reg=0.002960, loss_bbox_cls=0.062567, loss_bbox_reg=0.076897, loss=0.162146, lr=0.000250, time_each_step=0.18s, eta=0:15:15\r\n",
      "2023-03-12 16:36:57 [INFO]\t[TRAIN] Epoch=2/10, Step=100/490, loss_rpn_cls=0.015385, loss_rpn_reg=0.004759, loss_bbox_cls=0.063964, loss_bbox_reg=0.090619, loss=0.174726, lr=0.000250, time_each_step=0.18s, eta=0:14:57\r\n",
      "2023-03-12 16:36:59 [INFO]\t[TRAIN] Epoch=2/10, Step=110/490, loss_rpn_cls=0.017535, loss_rpn_reg=0.007543, loss_bbox_cls=0.035750, loss_bbox_reg=0.081916, loss=0.142744, lr=0.000250, time_each_step=0.18s, eta=0:15:0\r\n",
      "2023-03-12 16:37:01 [INFO]\t[TRAIN] Epoch=2/10, Step=120/490, loss_rpn_cls=0.062776, loss_rpn_reg=0.038433, loss_bbox_cls=0.131147, loss_bbox_reg=0.204407, loss=0.436763, lr=0.000250, time_each_step=0.18s, eta=0:15:11\r\n",
      "2023-03-12 16:37:03 [INFO]\t[TRAIN] Epoch=2/10, Step=130/490, loss_rpn_cls=0.031573, loss_rpn_reg=0.017515, loss_bbox_cls=0.126952, loss_bbox_reg=0.129134, loss=0.305174, lr=0.000250, time_each_step=0.18s, eta=0:15:20\r\n",
      "2023-03-12 16:37:04 [INFO]\t[TRAIN] Epoch=2/10, Step=140/490, loss_rpn_cls=0.027289, loss_rpn_reg=0.009756, loss_bbox_cls=0.047321, loss_bbox_reg=0.054989, loss=0.139356, lr=0.000250, time_each_step=0.18s, eta=0:15:2\r\n",
      "2023-03-12 16:37:06 [INFO]\t[TRAIN] Epoch=2/10, Step=150/490, loss_rpn_cls=0.016669, loss_rpn_reg=0.007280, loss_bbox_cls=0.100242, loss_bbox_reg=0.098110, loss=0.222300, lr=0.000250, time_each_step=0.17s, eta=0:14:33\r\n",
      "2023-03-12 16:37:08 [INFO]\t[TRAIN] Epoch=2/10, Step=160/490, loss_rpn_cls=0.020215, loss_rpn_reg=0.006298, loss_bbox_cls=0.054867, loss_bbox_reg=0.089184, loss=0.170565, lr=0.000250, time_each_step=0.18s, eta=0:15:15\r\n",
      "2023-03-12 16:37:10 [INFO]\t[TRAIN] Epoch=2/10, Step=170/490, loss_rpn_cls=0.015774, loss_rpn_reg=0.006181, loss_bbox_cls=0.065750, loss_bbox_reg=0.049165, loss=0.136870, lr=0.000250, time_each_step=0.19s, eta=0:15:40\r\n",
      "2023-03-12 16:37:12 [INFO]\t[TRAIN] Epoch=2/10, Step=180/490, loss_rpn_cls=0.021131, loss_rpn_reg=0.036899, loss_bbox_cls=0.029517, loss_bbox_reg=0.058793, loss=0.146340, lr=0.000250, time_each_step=0.19s, eta=0:15:24\r\n",
      "2023-03-12 16:37:14 [INFO]\t[TRAIN] Epoch=2/10, Step=190/490, loss_rpn_cls=0.009320, loss_rpn_reg=0.002346, loss_bbox_cls=0.036944, loss_bbox_reg=0.048893, loss=0.097503, lr=0.000250, time_each_step=0.18s, eta=0:14:47\r\n",
      "2023-03-12 16:37:15 [INFO]\t[TRAIN] Epoch=2/10, Step=200/490, loss_rpn_cls=0.007786, loss_rpn_reg=0.002272, loss_bbox_cls=0.044962, loss_bbox_reg=0.064935, loss=0.119955, lr=0.000250, time_each_step=0.18s, eta=0:14:56\r\n",
      "2023-03-12 16:37:18 [INFO]\t[TRAIN] Epoch=2/10, Step=210/490, loss_rpn_cls=0.028543, loss_rpn_reg=0.014491, loss_bbox_cls=0.089739, loss_bbox_reg=0.074536, loss=0.207309, lr=0.000250, time_each_step=0.22s, eta=0:17:41\r\n",
      "2023-03-12 16:37:19 [INFO]\t[TRAIN] Epoch=2/10, Step=220/490, loss_rpn_cls=0.033476, loss_rpn_reg=0.029161, loss_bbox_cls=0.094557, loss_bbox_reg=0.129208, loss=0.286402, lr=0.000250, time_each_step=0.17s, eta=0:14:30\r\n",
      "2023-03-12 16:37:21 [INFO]\t[TRAIN] Epoch=2/10, Step=230/490, loss_rpn_cls=0.009921, loss_rpn_reg=0.002621, loss_bbox_cls=0.041755, loss_bbox_reg=0.078845, loss=0.133143, lr=0.000250, time_each_step=0.19s, eta=0:15:48\r\n",
      "2023-03-12 16:37:23 [INFO]\t[TRAIN] Epoch=2/10, Step=240/490, loss_rpn_cls=0.109188, loss_rpn_reg=0.025584, loss_bbox_cls=0.095513, loss_bbox_reg=0.063090, loss=0.293374, lr=0.000250, time_each_step=0.2s, eta=0:16:20\r\n",
      "2023-03-12 16:37:25 [INFO]\t[TRAIN] Epoch=2/10, Step=250/490, loss_rpn_cls=0.018140, loss_rpn_reg=0.005727, loss_bbox_cls=0.042504, loss_bbox_reg=0.087849, loss=0.154220, lr=0.000250, time_each_step=0.18s, eta=0:15:3\r\n",
      "2023-03-12 16:37:27 [INFO]\t[TRAIN] Epoch=2/10, Step=260/490, loss_rpn_cls=0.005489, loss_rpn_reg=0.003947, loss_bbox_cls=0.049356, loss_bbox_reg=0.064003, loss=0.122795, lr=0.000250, time_each_step=0.18s, eta=0:14:39\r\n",
      "2023-03-12 16:37:29 [INFO]\t[TRAIN] Epoch=2/10, Step=270/490, loss_rpn_cls=0.013675, loss_rpn_reg=0.004443, loss_bbox_cls=0.042448, loss_bbox_reg=0.069886, loss=0.130452, lr=0.000250, time_each_step=0.17s, eta=0:14:18\r\n",
      "2023-03-12 16:37:30 [INFO]\t[TRAIN] Epoch=2/10, Step=280/490, loss_rpn_cls=0.006190, loss_rpn_reg=0.004328, loss_bbox_cls=0.017785, loss_bbox_reg=0.042015, loss=0.070318, lr=0.000250, time_each_step=0.18s, eta=0:14:37\r\n",
      "2023-03-12 16:37:32 [INFO]\t[TRAIN] Epoch=2/10, Step=290/490, loss_rpn_cls=0.009653, loss_rpn_reg=0.000711, loss_bbox_cls=0.048208, loss_bbox_reg=0.096615, loss=0.155187, lr=0.000250, time_each_step=0.18s, eta=0:14:39\r\n",
      "2023-03-12 16:37:34 [INFO]\t[TRAIN] Epoch=2/10, Step=300/490, loss_rpn_cls=0.010536, loss_rpn_reg=0.007108, loss_bbox_cls=0.038927, loss_bbox_reg=0.095372, loss=0.151943, lr=0.000250, time_each_step=0.21s, eta=0:16:21\r\n",
      "2023-03-12 16:37:36 [INFO]\t[TRAIN] Epoch=2/10, Step=310/490, loss_rpn_cls=0.033257, loss_rpn_reg=0.009978, loss_bbox_cls=0.097752, loss_bbox_reg=0.130078, loss=0.271064, lr=0.000250, time_each_step=0.19s, eta=0:15:15\r\n",
      "2023-03-12 16:37:38 [INFO]\t[TRAIN] Epoch=2/10, Step=320/490, loss_rpn_cls=0.009143, loss_rpn_reg=0.002748, loss_bbox_cls=0.049283, loss_bbox_reg=0.083551, loss=0.144726, lr=0.000250, time_each_step=0.19s, eta=0:15:3\r\n",
      "2023-03-12 16:37:40 [INFO]\t[TRAIN] Epoch=2/10, Step=330/490, loss_rpn_cls=0.015397, loss_rpn_reg=0.016747, loss_bbox_cls=0.086591, loss_bbox_reg=0.158072, loss=0.276807, lr=0.000250, time_each_step=0.18s, eta=0:14:40\r\n",
      "2023-03-12 16:37:42 [INFO]\t[TRAIN] Epoch=2/10, Step=340/490, loss_rpn_cls=0.018584, loss_rpn_reg=0.005478, loss_bbox_cls=0.036392, loss_bbox_reg=0.056612, loss=0.117066, lr=0.000250, time_each_step=0.19s, eta=0:15:32\r\n",
      "2023-03-12 16:37:44 [INFO]\t[TRAIN] Epoch=2/10, Step=350/490, loss_rpn_cls=0.015715, loss_rpn_reg=0.013504, loss_bbox_cls=0.057462, loss_bbox_reg=0.111899, loss=0.198581, lr=0.000250, time_each_step=0.21s, eta=0:16:44\r\n",
      "2023-03-12 16:37:46 [INFO]\t[TRAIN] Epoch=2/10, Step=360/490, loss_rpn_cls=0.011624, loss_rpn_reg=0.001045, loss_bbox_cls=0.046278, loss_bbox_reg=0.044625, loss=0.103573, lr=0.000250, time_each_step=0.19s, eta=0:15:5\r\n",
      "2023-03-12 16:37:48 [INFO]\t[TRAIN] Epoch=2/10, Step=370/490, loss_rpn_cls=0.008248, loss_rpn_reg=0.002226, loss_bbox_cls=0.035873, loss_bbox_reg=0.072374, loss=0.118721, lr=0.000250, time_each_step=0.18s, eta=0:14:45\r\n",
      "2023-03-12 16:37:49 [INFO]\t[TRAIN] Epoch=2/10, Step=380/490, loss_rpn_cls=0.005285, loss_rpn_reg=0.001486, loss_bbox_cls=0.048868, loss_bbox_reg=0.084024, loss=0.139663, lr=0.000250, time_each_step=0.18s, eta=0:14:31\r\n",
      "2023-03-12 16:37:51 [INFO]\t[TRAIN] Epoch=2/10, Step=390/490, loss_rpn_cls=0.006639, loss_rpn_reg=0.004735, loss_bbox_cls=0.028193, loss_bbox_reg=0.022685, loss=0.062252, lr=0.000250, time_each_step=0.18s, eta=0:14:9\r\n",
      "2023-03-12 16:37:53 [INFO]\t[TRAIN] Epoch=2/10, Step=400/490, loss_rpn_cls=0.007181, loss_rpn_reg=0.011973, loss_bbox_cls=0.030905, loss_bbox_reg=0.062299, loss=0.112359, lr=0.000250, time_each_step=0.18s, eta=0:14:15\r\n",
      "2023-03-12 16:37:55 [INFO]\t[TRAIN] Epoch=2/10, Step=410/490, loss_rpn_cls=0.015528, loss_rpn_reg=0.021355, loss_bbox_cls=0.022135, loss_bbox_reg=0.002793, loss=0.061811, lr=0.000250, time_each_step=0.19s, eta=0:14:50\r\n",
      "2023-03-12 16:37:57 [INFO]\t[TRAIN] Epoch=2/10, Step=420/490, loss_rpn_cls=0.009523, loss_rpn_reg=0.004767, loss_bbox_cls=0.048472, loss_bbox_reg=0.087412, loss=0.150174, lr=0.000250, time_each_step=0.17s, eta=0:13:50\r\n",
      "2023-03-12 16:37:58 [INFO]\t[TRAIN] Epoch=2/10, Step=430/490, loss_rpn_cls=0.012227, loss_rpn_reg=0.022144, loss_bbox_cls=0.042886, loss_bbox_reg=0.063568, loss=0.140824, lr=0.000250, time_each_step=0.18s, eta=0:14:10\r\n",
      "2023-03-12 16:38:00 [INFO]\t[TRAIN] Epoch=2/10, Step=440/490, loss_rpn_cls=0.020301, loss_rpn_reg=0.024471, loss_bbox_cls=0.030681, loss_bbox_reg=0.064979, loss=0.140432, lr=0.000250, time_each_step=0.18s, eta=0:14:20\r\n",
      "2023-03-12 16:38:02 [INFO]\t[TRAIN] Epoch=2/10, Step=450/490, loss_rpn_cls=0.009543, loss_rpn_reg=0.007625, loss_bbox_cls=0.083474, loss_bbox_reg=0.101254, loss=0.201896, lr=0.000250, time_each_step=0.18s, eta=0:14:4\r\n",
      "2023-03-12 16:38:04 [INFO]\t[TRAIN] Epoch=2/10, Step=460/490, loss_rpn_cls=0.011292, loss_rpn_reg=0.009377, loss_bbox_cls=0.066253, loss_bbox_reg=0.073877, loss=0.160799, lr=0.000250, time_each_step=0.18s, eta=0:13:59\r\n",
      "2023-03-12 16:38:06 [INFO]\t[TRAIN] Epoch=2/10, Step=470/490, loss_rpn_cls=0.022537, loss_rpn_reg=0.020640, loss_bbox_cls=0.062991, loss_bbox_reg=0.056794, loss=0.162961, lr=0.000250, time_each_step=0.18s, eta=0:14:5\r\n",
      "2023-03-12 16:38:07 [INFO]\t[TRAIN] Epoch=2/10, Step=480/490, loss_rpn_cls=0.002570, loss_rpn_reg=0.001864, loss_bbox_cls=0.058135, loss_bbox_reg=0.062079, loss=0.124648, lr=0.000250, time_each_step=0.17s, eta=0:13:28\r\n",
      "2023-03-12 16:38:09 [INFO]\t[TRAIN] Epoch=2/10, Step=490/490, loss_rpn_cls=0.007785, loss_rpn_reg=0.006767, loss_bbox_cls=0.059517, loss_bbox_reg=0.079976, loss=0.154045, lr=0.000250, time_each_step=0.17s, eta=0:13:34\r\n",
      "2023-03-12 16:38:09 [INFO]\t[TRAIN] Epoch 2 finished, loss_rpn_cls=0.021782689, loss_rpn_reg=0.011475853, loss_bbox_cls=0.060455393, loss_bbox_reg=0.07699035, loss=0.17070429 .\r\n",
      "2023-03-12 16:38:09 [INFO]\tStart to evaluate(total_samples=140, total_steps=140)...\r\n",
      "2023-03-12 16:38:24 [INFO]\tAccumulating evaluatation results...\r\n",
      "2023-03-12 16:38:24 [INFO]\t[EVAL] Finished, Epoch=2, bbox_map=56.043934 .\r\n",
      "2023-03-12 16:38:27 [INFO]\tModel saved in output/faster_rcnn_r50_fpn/best_model.\r\n",
      "2023-03-12 16:38:27 [INFO]\tCurrent evaluated best model on eval_dataset is epoch_2, bbox_map=56.043933824687066\r\n",
      "2023-03-12 16:38:28 [INFO]\tModel saved in output/faster_rcnn_r50_fpn/epoch_2.\r\n",
      "2023-03-12 16:38:31 [INFO]\t[TRAIN] Epoch=3/10, Step=10/490, loss_rpn_cls=0.015754, loss_rpn_reg=0.008893, loss_bbox_cls=0.139479, loss_bbox_reg=0.161398, loss=0.325524, lr=0.000250, time_each_step=0.23s, eta=0:17:18\r\n",
      "2023-03-12 16:38:32 [INFO]\t[TRAIN] Epoch=3/10, Step=20/490, loss_rpn_cls=0.170832, loss_rpn_reg=0.050377, loss_bbox_cls=0.159901, loss_bbox_reg=0.102598, loss=0.483708, lr=0.000250, time_each_step=0.18s, eta=0:14:7\r\n",
      "2023-03-12 16:38:34 [INFO]\t[TRAIN] Epoch=3/10, Step=30/490, loss_rpn_cls=0.016683, loss_rpn_reg=0.003485, loss_bbox_cls=0.048177, loss_bbox_reg=0.041201, loss=0.109546, lr=0.000250, time_each_step=0.18s, eta=0:13:59\r\n",
      "2023-03-12 16:38:36 [INFO]\t[TRAIN] Epoch=3/10, Step=40/490, loss_rpn_cls=0.010705, loss_rpn_reg=0.011589, loss_bbox_cls=0.082589, loss_bbox_reg=0.159170, loss=0.264053, lr=0.000250, time_each_step=0.18s, eta=0:13:37\r\n",
      "2023-03-12 16:38:38 [INFO]\t[TRAIN] Epoch=3/10, Step=50/490, loss_rpn_cls=0.020219, loss_rpn_reg=0.010083, loss_bbox_cls=0.070708, loss_bbox_reg=0.098208, loss=0.199218, lr=0.000250, time_each_step=0.18s, eta=0:14:2\r\n",
      "2023-03-12 16:38:40 [INFO]\t[TRAIN] Epoch=3/10, Step=60/490, loss_rpn_cls=0.009087, loss_rpn_reg=0.003776, loss_bbox_cls=0.042533, loss_bbox_reg=0.051651, loss=0.107048, lr=0.000250, time_each_step=0.18s, eta=0:13:58\r\n",
      "2023-03-12 16:38:42 [INFO]\t[TRAIN] Epoch=3/10, Step=70/490, loss_rpn_cls=0.019166, loss_rpn_reg=0.037676, loss_bbox_cls=0.107889, loss_bbox_reg=0.123120, loss=0.287851, lr=0.000250, time_each_step=0.19s, eta=0:14:12\r\n",
      "2023-03-12 16:38:44 [INFO]\t[TRAIN] Epoch=3/10, Step=80/490, loss_rpn_cls=0.009409, loss_rpn_reg=0.004019, loss_bbox_cls=0.083895, loss_bbox_reg=0.127823, loss=0.225145, lr=0.000250, time_each_step=0.2s, eta=0:14:38\r\n",
      "2023-03-12 16:38:46 [INFO]\t[TRAIN] Epoch=3/10, Step=90/490, loss_rpn_cls=0.004678, loss_rpn_reg=0.001552, loss_bbox_cls=0.032626, loss_bbox_reg=0.085248, loss=0.124103, lr=0.000250, time_each_step=0.21s, eta=0:15:36\r\n",
      "2023-03-12 16:38:48 [INFO]\t[TRAIN] Epoch=3/10, Step=100/490, loss_rpn_cls=0.017202, loss_rpn_reg=0.002284, loss_bbox_cls=0.089086, loss_bbox_reg=0.113941, loss=0.222513, lr=0.000250, time_each_step=0.18s, eta=0:13:45\r\n",
      "2023-03-12 16:38:49 [INFO]\t[TRAIN] Epoch=3/10, Step=110/490, loss_rpn_cls=0.027219, loss_rpn_reg=0.016384, loss_bbox_cls=0.073596, loss_bbox_reg=0.094427, loss=0.211626, lr=0.000250, time_each_step=0.2s, eta=0:14:31\r\n",
      "2023-03-12 16:38:51 [INFO]\t[TRAIN] Epoch=3/10, Step=120/490, loss_rpn_cls=0.028276, loss_rpn_reg=0.036515, loss_bbox_cls=0.075277, loss_bbox_reg=0.140657, loss=0.280725, lr=0.000250, time_each_step=0.18s, eta=0:13:41\r\n",
      "2023-03-12 16:38:53 [INFO]\t[TRAIN] Epoch=3/10, Step=130/490, loss_rpn_cls=0.013681, loss_rpn_reg=0.013889, loss_bbox_cls=0.071380, loss_bbox_reg=0.154731, loss=0.253681, lr=0.000250, time_each_step=0.18s, eta=0:13:36\r\n",
      "2023-03-12 16:38:55 [INFO]\t[TRAIN] Epoch=3/10, Step=140/490, loss_rpn_cls=0.014025, loss_rpn_reg=0.007928, loss_bbox_cls=0.034303, loss_bbox_reg=0.038114, loss=0.094370, lr=0.000250, time_each_step=0.18s, eta=0:13:29\r\n",
      "2023-03-12 16:38:57 [INFO]\t[TRAIN] Epoch=3/10, Step=150/490, loss_rpn_cls=0.013929, loss_rpn_reg=0.025875, loss_bbox_cls=0.076512, loss_bbox_reg=0.072726, loss=0.189043, lr=0.000250, time_each_step=0.18s, eta=0:13:7\r\n",
      "2023-03-12 16:38:58 [INFO]\t[TRAIN] Epoch=3/10, Step=160/490, loss_rpn_cls=0.005536, loss_rpn_reg=0.003829, loss_bbox_cls=0.082008, loss_bbox_reg=0.092288, loss=0.183662, lr=0.000250, time_each_step=0.18s, eta=0:13:22\r\n",
      "2023-03-12 16:39:00 [INFO]\t[TRAIN] Epoch=3/10, Step=170/490, loss_rpn_cls=0.013174, loss_rpn_reg=0.008449, loss_bbox_cls=0.058573, loss_bbox_reg=0.064648, loss=0.144845, lr=0.000250, time_each_step=0.18s, eta=0:13:10\r\n",
      "2023-03-12 16:39:02 [INFO]\t[TRAIN] Epoch=3/10, Step=180/490, loss_rpn_cls=0.005104, loss_rpn_reg=0.023538, loss_bbox_cls=0.034305, loss_bbox_reg=0.089469, loss=0.152416, lr=0.000250, time_each_step=0.19s, eta=0:13:49\r\n",
      "2023-03-12 16:39:04 [INFO]\t[TRAIN] Epoch=3/10, Step=190/490, loss_rpn_cls=0.001394, loss_rpn_reg=0.003734, loss_bbox_cls=0.035148, loss_bbox_reg=0.057714, loss=0.097991, lr=0.000250, time_each_step=0.18s, eta=0:13:12\r\n",
      "2023-03-12 16:39:06 [INFO]\t[TRAIN] Epoch=3/10, Step=200/490, loss_rpn_cls=0.002161, loss_rpn_reg=0.002846, loss_bbox_cls=0.046454, loss_bbox_reg=0.065946, loss=0.117407, lr=0.000250, time_each_step=0.19s, eta=0:13:47\r\n",
      "2023-03-12 16:39:08 [INFO]\t[TRAIN] Epoch=3/10, Step=210/490, loss_rpn_cls=0.004393, loss_rpn_reg=0.004193, loss_bbox_cls=0.039518, loss_bbox_reg=0.068465, loss=0.116570, lr=0.000250, time_each_step=0.18s, eta=0:13:19\r\n",
      "2023-03-12 16:39:09 [INFO]\t[TRAIN] Epoch=3/10, Step=220/490, loss_rpn_cls=0.013378, loss_rpn_reg=0.017123, loss_bbox_cls=0.078415, loss_bbox_reg=0.132847, loss=0.241764, lr=0.000250, time_each_step=0.18s, eta=0:13:30\r\n",
      "2023-03-12 16:39:11 [INFO]\t[TRAIN] Epoch=3/10, Step=230/490, loss_rpn_cls=0.006136, loss_rpn_reg=0.009615, loss_bbox_cls=0.055665, loss_bbox_reg=0.076891, loss=0.148308, lr=0.000250, time_each_step=0.2s, eta=0:14:39\r\n",
      "2023-03-12 16:39:13 [INFO]\t[TRAIN] Epoch=3/10, Step=240/490, loss_rpn_cls=0.004403, loss_rpn_reg=0.005550, loss_bbox_cls=0.134797, loss_bbox_reg=0.185149, loss=0.329899, lr=0.000250, time_each_step=0.19s, eta=0:13:57\r\n",
      "2023-03-12 16:39:15 [INFO]\t[TRAIN] Epoch=3/10, Step=250/490, loss_rpn_cls=0.003374, loss_rpn_reg=0.008590, loss_bbox_cls=0.028765, loss_bbox_reg=0.064632, loss=0.105360, lr=0.000250, time_each_step=0.19s, eta=0:13:36\r\n",
      "2023-03-12 16:39:17 [INFO]\t[TRAIN] Epoch=3/10, Step=260/490, loss_rpn_cls=0.006909, loss_rpn_reg=0.001465, loss_bbox_cls=0.040316, loss_bbox_reg=0.030366, loss=0.079056, lr=0.000250, time_each_step=0.2s, eta=0:14:4\r\n",
      "2023-03-12 16:39:19 [INFO]\t[TRAIN] Epoch=3/10, Step=270/490, loss_rpn_cls=0.003778, loss_rpn_reg=0.009459, loss_bbox_cls=0.044842, loss_bbox_reg=0.064878, loss=0.122956, lr=0.000250, time_each_step=0.18s, eta=0:13:20\r\n",
      "2023-03-12 16:39:21 [INFO]\t[TRAIN] Epoch=3/10, Step=280/490, loss_rpn_cls=0.005519, loss_rpn_reg=0.002711, loss_bbox_cls=0.048807, loss_bbox_reg=0.053488, loss=0.110526, lr=0.000250, time_each_step=0.19s, eta=0:13:42\r\n",
      "2023-03-12 16:39:23 [INFO]\t[TRAIN] Epoch=3/10, Step=290/490, loss_rpn_cls=0.001380, loss_rpn_reg=0.003118, loss_bbox_cls=0.023898, loss_bbox_reg=0.094459, loss=0.122854, lr=0.000250, time_each_step=0.18s, eta=0:13:2\r\n",
      "2023-03-12 16:39:25 [INFO]\t[TRAIN] Epoch=3/10, Step=300/490, loss_rpn_cls=0.002677, loss_rpn_reg=0.004430, loss_bbox_cls=0.028555, loss_bbox_reg=0.059707, loss=0.095368, lr=0.000250, time_each_step=0.19s, eta=0:13:19\r\n",
      "2023-03-12 16:39:27 [INFO]\t[TRAIN] Epoch=3/10, Step=310/490, loss_rpn_cls=0.005733, loss_rpn_reg=0.012584, loss_bbox_cls=0.115872, loss_bbox_reg=0.136950, loss=0.271139, lr=0.000250, time_each_step=0.19s, eta=0:13:28\r\n",
      "2023-03-12 16:39:29 [INFO]\t[TRAIN] Epoch=3/10, Step=320/490, loss_rpn_cls=0.001035, loss_rpn_reg=0.002600, loss_bbox_cls=0.086127, loss_bbox_reg=0.118171, loss=0.207933, lr=0.000250, time_each_step=0.22s, eta=0:15:1\r\n",
      "2023-03-12 16:39:30 [INFO]\t[TRAIN] Epoch=3/10, Step=330/490, loss_rpn_cls=0.003278, loss_rpn_reg=0.016332, loss_bbox_cls=0.084737, loss_bbox_reg=0.143168, loss=0.247515, lr=0.000250, time_each_step=0.18s, eta=0:12:59\r\n",
      "2023-03-12 16:39:32 [INFO]\t[TRAIN] Epoch=3/10, Step=340/490, loss_rpn_cls=0.025478, loss_rpn_reg=0.010334, loss_bbox_cls=0.039465, loss_bbox_reg=0.090937, loss=0.166213, lr=0.000250, time_each_step=0.18s, eta=0:12:41\r\n",
      "2023-03-12 16:39:34 [INFO]\t[TRAIN] Epoch=3/10, Step=350/490, loss_rpn_cls=0.015794, loss_rpn_reg=0.014583, loss_bbox_cls=0.080560, loss_bbox_reg=0.099321, loss=0.210258, lr=0.000250, time_each_step=0.18s, eta=0:12:46\r\n",
      "2023-03-12 16:39:36 [INFO]\t[TRAIN] Epoch=3/10, Step=360/490, loss_rpn_cls=0.012254, loss_rpn_reg=0.010410, loss_bbox_cls=0.049453, loss_bbox_reg=0.055275, loss=0.127393, lr=0.000250, time_each_step=0.15s, eta=0:10:51\r\n",
      "2023-03-12 16:39:37 [INFO]\t[TRAIN] Epoch=3/10, Step=370/490, loss_rpn_cls=0.006301, loss_rpn_reg=0.003860, loss_bbox_cls=0.031039, loss_bbox_reg=0.053908, loss=0.095108, lr=0.000250, time_each_step=0.16s, eta=0:11:21\r\n",
      "2023-03-12 16:39:39 [INFO]\t[TRAIN] Epoch=3/10, Step=380/490, loss_rpn_cls=0.001461, loss_rpn_reg=0.000812, loss_bbox_cls=0.024140, loss_bbox_reg=0.041584, loss=0.067997, lr=0.000250, time_each_step=0.15s, eta=0:11:6\r\n",
      "2023-03-12 16:39:40 [INFO]\t[TRAIN] Epoch=3/10, Step=390/490, loss_rpn_cls=0.022555, loss_rpn_reg=0.000848, loss_bbox_cls=0.043844, loss_bbox_reg=0.052440, loss=0.119687, lr=0.000250, time_each_step=0.15s, eta=0:11:10\r\n",
      "2023-03-12 16:39:42 [INFO]\t[TRAIN] Epoch=3/10, Step=400/490, loss_rpn_cls=0.015637, loss_rpn_reg=0.005133, loss_bbox_cls=0.060255, loss_bbox_reg=0.039839, loss=0.120864, lr=0.000250, time_each_step=0.16s, eta=0:11:26\r\n",
      "2023-03-12 16:39:43 [INFO]\t[TRAIN] Epoch=3/10, Step=410/490, loss_rpn_cls=0.013851, loss_rpn_reg=0.023792, loss_bbox_cls=0.030674, loss_bbox_reg=0.017732, loss=0.086050, lr=0.000250, time_each_step=0.15s, eta=0:10:45\r\n",
      "2023-03-12 16:39:45 [INFO]\t[TRAIN] Epoch=3/10, Step=420/490, loss_rpn_cls=0.010638, loss_rpn_reg=0.006606, loss_bbox_cls=0.046869, loss_bbox_reg=0.073414, loss=0.137527, lr=0.000250, time_each_step=0.17s, eta=0:11:59\r\n",
      "2023-03-12 16:39:46 [INFO]\t[TRAIN] Epoch=3/10, Step=430/490, loss_rpn_cls=0.005978, loss_rpn_reg=0.008142, loss_bbox_cls=0.034350, loss_bbox_reg=0.037436, loss=0.085906, lr=0.000250, time_each_step=0.15s, eta=0:10:54\r\n",
      "2023-03-12 16:39:48 [INFO]\t[TRAIN] Epoch=3/10, Step=440/490, loss_rpn_cls=0.014522, loss_rpn_reg=0.001715, loss_bbox_cls=0.040940, loss_bbox_reg=0.108168, loss=0.165346, lr=0.000250, time_each_step=0.16s, eta=0:11:25\r\n",
      "2023-03-12 16:39:50 [INFO]\t[TRAIN] Epoch=3/10, Step=450/490, loss_rpn_cls=0.031821, loss_rpn_reg=0.025910, loss_bbox_cls=0.057059, loss_bbox_reg=0.055957, loss=0.170747, lr=0.000250, time_each_step=0.15s, eta=0:10:51\r\n",
      "2023-03-12 16:39:51 [INFO]\t[TRAIN] Epoch=3/10, Step=460/490, loss_rpn_cls=0.022110, loss_rpn_reg=0.012645, loss_bbox_cls=0.055692, loss_bbox_reg=0.103956, loss=0.194403, lr=0.000250, time_each_step=0.15s, eta=0:10:41\r\n",
      "2023-03-12 16:39:52 [INFO]\t[TRAIN] Epoch=3/10, Step=470/490, loss_rpn_cls=0.014957, loss_rpn_reg=0.013460, loss_bbox_cls=0.111414, loss_bbox_reg=0.141499, loss=0.281330, lr=0.000250, time_each_step=0.15s, eta=0:10:34\r\n",
      "2023-03-12 16:39:54 [INFO]\t[TRAIN] Epoch=3/10, Step=480/490, loss_rpn_cls=0.007929, loss_rpn_reg=0.004797, loss_bbox_cls=0.069572, loss_bbox_reg=0.072715, loss=0.155013, lr=0.000250, time_each_step=0.15s, eta=0:10:33\r\n",
      "2023-03-12 16:39:55 [INFO]\t[TRAIN] Epoch=3/10, Step=490/490, loss_rpn_cls=0.017224, loss_rpn_reg=0.007328, loss_bbox_cls=0.058909, loss_bbox_reg=0.086496, loss=0.169958, lr=0.000250, time_each_step=0.15s, eta=0:10:35\r\n",
      "2023-03-12 16:39:56 [INFO]\t[TRAIN] Epoch 3 finished, loss_rpn_cls=0.015325843, loss_rpn_reg=0.0108720325, loss_bbox_cls=0.057553045, loss_bbox_reg=0.08079956, loss=0.16455047 .\r\n",
      "2023-03-12 16:39:56 [INFO]\tStart to evaluate(total_samples=140, total_steps=140)...\r\n",
      "2023-03-12 16:40:08 [INFO]\tAccumulating evaluatation results...\r\n",
      "2023-03-12 16:40:08 [INFO]\t[EVAL] Finished, Epoch=3, bbox_map=55.093765 .\r\n",
      "2023-03-12 16:40:08 [INFO]\tCurrent evaluated best model on eval_dataset is epoch_2, bbox_map=56.043933824687066\r\n",
      "2023-03-12 16:40:09 [INFO]\tModel saved in output/faster_rcnn_r50_fpn/epoch_3.\r\n",
      "2023-03-12 16:40:11 [INFO]\t[TRAIN] Epoch=4/10, Step=10/490, loss_rpn_cls=0.010100, loss_rpn_reg=0.013516, loss_bbox_cls=0.081812, loss_bbox_reg=0.132478, loss=0.237906, lr=0.000250, time_each_step=0.21s, eta=0:13:6\r\n",
      "2023-03-12 16:40:12 [INFO]\t[TRAIN] Epoch=4/10, Step=20/490, loss_rpn_cls=0.037153, loss_rpn_reg=0.015841, loss_bbox_cls=0.055399, loss_bbox_reg=0.150398, loss=0.258791, lr=0.000250, time_each_step=0.13s, eta=0:8:47\r\n",
      "2023-03-12 16:40:15 [INFO]\t[TRAIN] Epoch=4/10, Step=30/490, loss_rpn_cls=0.006335, loss_rpn_reg=0.008201, loss_bbox_cls=0.035146, loss_bbox_reg=0.002066, loss=0.051748, lr=0.000250, time_each_step=0.26s, eta=0:15:39\r\n",
      "2023-03-12 16:40:16 [INFO]\t[TRAIN] Epoch=4/10, Step=40/490, loss_rpn_cls=0.015336, loss_rpn_reg=0.012741, loss_bbox_cls=0.068482, loss_bbox_reg=0.092506, loss=0.189065, lr=0.000250, time_each_step=0.19s, eta=0:11:46\r\n",
      "2023-03-12 16:40:18 [INFO]\t[TRAIN] Epoch=4/10, Step=50/490, loss_rpn_cls=0.008796, loss_rpn_reg=0.005624, loss_bbox_cls=0.055055, loss_bbox_reg=0.066595, loss=0.136070, lr=0.000250, time_each_step=0.18s, eta=0:11:32\r\n",
      "2023-03-12 16:40:20 [INFO]\t[TRAIN] Epoch=4/10, Step=60/490, loss_rpn_cls=0.002875, loss_rpn_reg=0.003477, loss_bbox_cls=0.039659, loss_bbox_reg=0.040816, loss=0.086828, lr=0.000250, time_each_step=0.2s, eta=0:12:9\r\n",
      "2023-03-12 16:40:22 [INFO]\t[TRAIN] Epoch=4/10, Step=70/490, loss_rpn_cls=0.035265, loss_rpn_reg=0.040124, loss_bbox_cls=0.130341, loss_bbox_reg=0.200648, loss=0.406378, lr=0.000250, time_each_step=0.19s, eta=0:11:39\r\n",
      "2023-03-12 16:40:24 [INFO]\t[TRAIN] Epoch=4/10, Step=80/490, loss_rpn_cls=0.005046, loss_rpn_reg=0.002663, loss_bbox_cls=0.066078, loss_bbox_reg=0.081630, loss=0.155416, lr=0.000250, time_each_step=0.19s, eta=0:11:40\r\n",
      "2023-03-12 16:40:26 [INFO]\t[TRAIN] Epoch=4/10, Step=90/490, loss_rpn_cls=0.007088, loss_rpn_reg=0.003086, loss_bbox_cls=0.045082, loss_bbox_reg=0.046779, loss=0.102035, lr=0.000250, time_each_step=0.19s, eta=0:11:36\r\n",
      "2023-03-12 16:40:28 [INFO]\t[TRAIN] Epoch=4/10, Step=100/490, loss_rpn_cls=0.022087, loss_rpn_reg=0.002260, loss_bbox_cls=0.079397, loss_bbox_reg=0.133623, loss=0.237368, lr=0.000250, time_each_step=0.21s, eta=0:12:49\r\n",
      "2023-03-12 16:40:30 [INFO]\t[TRAIN] Epoch=4/10, Step=110/490, loss_rpn_cls=0.004799, loss_rpn_reg=0.007853, loss_bbox_cls=0.050869, loss_bbox_reg=0.081764, loss=0.145285, lr=0.000250, time_each_step=0.18s, eta=0:11:11\r\n",
      "2023-03-12 16:40:32 [INFO]\t[TRAIN] Epoch=4/10, Step=120/490, loss_rpn_cls=0.021860, loss_rpn_reg=0.015748, loss_bbox_cls=0.094514, loss_bbox_reg=0.098588, loss=0.230709, lr=0.000250, time_each_step=0.18s, eta=0:11:11\r\n",
      "2023-03-12 16:40:33 [INFO]\t[TRAIN] Epoch=4/10, Step=130/490, loss_rpn_cls=0.011450, loss_rpn_reg=0.006859, loss_bbox_cls=0.091746, loss_bbox_reg=0.142360, loss=0.252415, lr=0.000250, time_each_step=0.18s, eta=0:11:14\r\n",
      "2023-03-12 16:40:35 [INFO]\t[TRAIN] Epoch=4/10, Step=140/490, loss_rpn_cls=0.004687, loss_rpn_reg=0.007551, loss_bbox_cls=0.038329, loss_bbox_reg=0.069122, loss=0.119688, lr=0.000250, time_each_step=0.18s, eta=0:11:14\r\n",
      "2023-03-12 16:40:37 [INFO]\t[TRAIN] Epoch=4/10, Step=150/490, loss_rpn_cls=0.007441, loss_rpn_reg=0.012581, loss_bbox_cls=0.081420, loss_bbox_reg=0.097713, loss=0.199155, lr=0.000250, time_each_step=0.19s, eta=0:11:38\r\n",
      "2023-03-12 16:40:39 [INFO]\t[TRAIN] Epoch=4/10, Step=160/490, loss_rpn_cls=0.004780, loss_rpn_reg=0.003588, loss_bbox_cls=0.038291, loss_bbox_reg=0.114933, loss=0.161593, lr=0.000250, time_each_step=0.18s, eta=0:10:47\r\n",
      "2023-03-12 16:40:41 [INFO]\t[TRAIN] Epoch=4/10, Step=170/490, loss_rpn_cls=0.010112, loss_rpn_reg=0.001639, loss_bbox_cls=0.052474, loss_bbox_reg=0.059238, loss=0.123463, lr=0.000250, time_each_step=0.18s, eta=0:11:10\r\n",
      "2023-03-12 16:40:43 [INFO]\t[TRAIN] Epoch=4/10, Step=180/490, loss_rpn_cls=0.005099, loss_rpn_reg=0.005292, loss_bbox_cls=0.065290, loss_bbox_reg=0.089520, loss=0.165201, lr=0.000250, time_each_step=0.18s, eta=0:10:50\r\n",
      "2023-03-12 16:40:44 [INFO]\t[TRAIN] Epoch=4/10, Step=190/490, loss_rpn_cls=0.006462, loss_rpn_reg=0.001649, loss_bbox_cls=0.038579, loss_bbox_reg=0.083077, loss=0.129767, lr=0.000250, time_each_step=0.18s, eta=0:11:9\r\n",
      "2023-03-12 16:40:46 [INFO]\t[TRAIN] Epoch=4/10, Step=200/490, loss_rpn_cls=0.022480, loss_rpn_reg=0.023205, loss_bbox_cls=0.059267, loss_bbox_reg=0.099469, loss=0.204421, lr=0.000250, time_each_step=0.19s, eta=0:11:21\r\n",
      "2023-03-12 16:40:48 [INFO]\t[TRAIN] Epoch=4/10, Step=210/490, loss_rpn_cls=0.011806, loss_rpn_reg=0.005275, loss_bbox_cls=0.043683, loss_bbox_reg=0.049397, loss=0.110161, lr=0.000250, time_each_step=0.2s, eta=0:11:58\r\n",
      "2023-03-12 16:40:50 [INFO]\t[TRAIN] Epoch=4/10, Step=220/490, loss_rpn_cls=0.026152, loss_rpn_reg=0.027570, loss_bbox_cls=0.108914, loss_bbox_reg=0.196378, loss=0.359014, lr=0.000250, time_each_step=0.18s, eta=0:10:38\r\n",
      "2023-03-12 16:40:52 [INFO]\t[TRAIN] Epoch=4/10, Step=230/490, loss_rpn_cls=0.002206, loss_rpn_reg=0.005552, loss_bbox_cls=0.033126, loss_bbox_reg=0.088651, loss=0.129535, lr=0.000250, time_each_step=0.21s, eta=0:12:19\r\n",
      "2023-03-12 16:40:54 [INFO]\t[TRAIN] Epoch=4/10, Step=240/490, loss_rpn_cls=0.017393, loss_rpn_reg=0.020730, loss_bbox_cls=0.092502, loss_bbox_reg=0.182095, loss=0.312720, lr=0.000250, time_each_step=0.18s, eta=0:10:35\r\n",
      "2023-03-12 16:40:56 [INFO]\t[TRAIN] Epoch=4/10, Step=250/490, loss_rpn_cls=0.006901, loss_rpn_reg=0.007373, loss_bbox_cls=0.027836, loss_bbox_reg=0.056411, loss=0.098521, lr=0.000250, time_each_step=0.17s, eta=0:10:20\r\n",
      "2023-03-12 16:40:57 [INFO]\t[TRAIN] Epoch=4/10, Step=260/490, loss_rpn_cls=0.000489, loss_rpn_reg=0.003333, loss_bbox_cls=0.034758, loss_bbox_reg=0.068410, loss=0.106990, lr=0.000250, time_each_step=0.19s, eta=0:11:11\r\n",
      "2023-03-12 16:40:59 [INFO]\t[TRAIN] Epoch=4/10, Step=270/490, loss_rpn_cls=0.001982, loss_rpn_reg=0.007738, loss_bbox_cls=0.039500, loss_bbox_reg=0.088444, loss=0.137664, lr=0.000250, time_each_step=0.19s, eta=0:11:21\r\n",
      "2023-03-12 16:41:01 [INFO]\t[TRAIN] Epoch=4/10, Step=280/490, loss_rpn_cls=0.003954, loss_rpn_reg=0.007205, loss_bbox_cls=0.039362, loss_bbox_reg=0.066283, loss=0.116805, lr=0.000250, time_each_step=0.19s, eta=0:11:4\r\n",
      "2023-03-12 16:41:03 [INFO]\t[TRAIN] Epoch=4/10, Step=290/490, loss_rpn_cls=0.002300, loss_rpn_reg=0.002617, loss_bbox_cls=0.048826, loss_bbox_reg=0.099306, loss=0.153048, lr=0.000250, time_each_step=0.19s, eta=0:10:53\r\n",
      "2023-03-12 16:41:05 [INFO]\t[TRAIN] Epoch=4/10, Step=300/490, loss_rpn_cls=0.016856, loss_rpn_reg=0.014222, loss_bbox_cls=0.042388, loss_bbox_reg=0.086744, loss=0.160210, lr=0.000250, time_each_step=0.19s, eta=0:10:57\r\n",
      "2023-03-12 16:41:07 [INFO]\t[TRAIN] Epoch=4/10, Step=310/490, loss_rpn_cls=0.014091, loss_rpn_reg=0.013334, loss_bbox_cls=0.079670, loss_bbox_reg=0.164140, loss=0.271234, lr=0.000250, time_each_step=0.18s, eta=0:10:35\r\n",
      "2023-03-12 16:41:09 [INFO]\t[TRAIN] Epoch=4/10, Step=320/490, loss_rpn_cls=0.002132, loss_rpn_reg=0.005359, loss_bbox_cls=0.064211, loss_bbox_reg=0.072930, loss=0.144632, lr=0.000250, time_each_step=0.18s, eta=0:10:18\r\n",
      "2023-03-12 16:41:10 [INFO]\t[TRAIN] Epoch=4/10, Step=330/490, loss_rpn_cls=0.004412, loss_rpn_reg=0.011925, loss_bbox_cls=0.111755, loss_bbox_reg=0.167938, loss=0.296029, lr=0.000250, time_each_step=0.18s, eta=0:10:37\r\n",
      "2023-03-12 16:41:12 [INFO]\t[TRAIN] Epoch=4/10, Step=340/490, loss_rpn_cls=0.001896, loss_rpn_reg=0.006083, loss_bbox_cls=0.033402, loss_bbox_reg=0.095497, loss=0.136876, lr=0.000250, time_each_step=0.18s, eta=0:10:23\r\n",
      "2023-03-12 16:41:14 [INFO]\t[TRAIN] Epoch=4/10, Step=350/490, loss_rpn_cls=0.014032, loss_rpn_reg=0.007575, loss_bbox_cls=0.068612, loss_bbox_reg=0.106417, loss=0.196636, lr=0.000250, time_each_step=0.2s, eta=0:11:16\r\n",
      "2023-03-12 16:41:16 [INFO]\t[TRAIN] Epoch=4/10, Step=360/490, loss_rpn_cls=0.018053, loss_rpn_reg=0.002493, loss_bbox_cls=0.045762, loss_bbox_reg=0.059333, loss=0.125640, lr=0.000250, time_each_step=0.19s, eta=0:10:56\r\n",
      "2023-03-12 16:41:18 [INFO]\t[TRAIN] Epoch=4/10, Step=370/490, loss_rpn_cls=0.001504, loss_rpn_reg=0.003953, loss_bbox_cls=0.040762, loss_bbox_reg=0.075258, loss=0.121476, lr=0.000250, time_each_step=0.18s, eta=0:10:26\r\n",
      "2023-03-12 16:41:20 [INFO]\t[TRAIN] Epoch=4/10, Step=380/490, loss_rpn_cls=0.005173, loss_rpn_reg=0.007998, loss_bbox_cls=0.083652, loss_bbox_reg=0.098893, loss=0.195716, lr=0.000250, time_each_step=0.18s, eta=0:10:7\r\n",
      "2023-03-12 16:41:21 [INFO]\t[TRAIN] Epoch=4/10, Step=390/490, loss_rpn_cls=0.000484, loss_rpn_reg=0.004223, loss_bbox_cls=0.043639, loss_bbox_reg=0.060812, loss=0.109159, lr=0.000250, time_each_step=0.18s, eta=0:10:28\r\n",
      "2023-03-12 16:41:23 [INFO]\t[TRAIN] Epoch=4/10, Step=400/490, loss_rpn_cls=0.019713, loss_rpn_reg=0.005278, loss_bbox_cls=0.043099, loss_bbox_reg=0.049828, loss=0.117918, lr=0.000250, time_each_step=0.21s, eta=0:11:33\r\n",
      "2023-03-12 16:41:25 [INFO]\t[TRAIN] Epoch=4/10, Step=410/490, loss_rpn_cls=0.022651, loss_rpn_reg=0.067668, loss_bbox_cls=0.096861, loss_bbox_reg=0.180267, loss=0.367447, lr=0.000250, time_each_step=0.19s, eta=0:10:49\r\n",
      "2023-03-12 16:41:27 [INFO]\t[TRAIN] Epoch=4/10, Step=420/490, loss_rpn_cls=0.003996, loss_rpn_reg=0.003933, loss_bbox_cls=0.040354, loss_bbox_reg=0.053973, loss=0.102257, lr=0.000250, time_each_step=0.18s, eta=0:10:19\r\n",
      "2023-03-12 16:41:29 [INFO]\t[TRAIN] Epoch=4/10, Step=430/490, loss_rpn_cls=0.007086, loss_rpn_reg=0.021483, loss_bbox_cls=0.056526, loss_bbox_reg=0.058300, loss=0.143396, lr=0.000250, time_each_step=0.18s, eta=0:10:6\r\n",
      "2023-03-12 16:41:31 [INFO]\t[TRAIN] Epoch=4/10, Step=440/490, loss_rpn_cls=0.000913, loss_rpn_reg=0.006507, loss_bbox_cls=0.009557, loss_bbox_reg=0.040958, loss=0.057935, lr=0.000250, time_each_step=0.18s, eta=0:10:7\r\n",
      "2023-03-12 16:41:33 [INFO]\t[TRAIN] Epoch=4/10, Step=450/490, loss_rpn_cls=0.002678, loss_rpn_reg=0.004872, loss_bbox_cls=0.117925, loss_bbox_reg=0.148754, loss=0.274228, lr=0.000250, time_each_step=0.19s, eta=0:10:52\r\n",
      "2023-03-12 16:41:35 [INFO]\t[TRAIN] Epoch=4/10, Step=460/490, loss_rpn_cls=0.008036, loss_rpn_reg=0.003024, loss_bbox_cls=0.051818, loss_bbox_reg=0.086289, loss=0.149168, lr=0.000250, time_each_step=0.18s, eta=0:9:54\r\n",
      "2023-03-12 16:41:36 [INFO]\t[TRAIN] Epoch=4/10, Step=470/490, loss_rpn_cls=0.008887, loss_rpn_reg=0.014570, loss_bbox_cls=0.071276, loss_bbox_reg=0.118678, loss=0.213412, lr=0.000250, time_each_step=0.19s, eta=0:10:20\r\n",
      "2023-03-12 16:41:38 [INFO]\t[TRAIN] Epoch=4/10, Step=480/490, loss_rpn_cls=0.000791, loss_rpn_reg=0.002271, loss_bbox_cls=0.056175, loss_bbox_reg=0.066804, loss=0.126042, lr=0.000250, time_each_step=0.18s, eta=0:10:2\r\n",
      "2023-03-12 16:41:40 [INFO]\t[TRAIN] Epoch=4/10, Step=490/490, loss_rpn_cls=0.009456, loss_rpn_reg=0.007275, loss_bbox_cls=0.033126, loss_bbox_reg=0.071935, loss=0.121791, lr=0.000250, time_each_step=0.18s, eta=0:10:13\r\n",
      "2023-03-12 16:41:40 [INFO]\t[TRAIN] Epoch 4 finished, loss_rpn_cls=0.00879906, loss_rpn_reg=0.009823988, loss_bbox_cls=0.05599461, loss_bbox_reg=0.08947639, loss=0.16409405 .\r\n",
      "2023-03-12 16:41:40 [INFO]\tStart to evaluate(total_samples=140, total_steps=140)...\r\n",
      "2023-03-12 16:41:56 [INFO]\tAccumulating evaluatation results...\r\n",
      "2023-03-12 16:41:56 [INFO]\t[EVAL] Finished, Epoch=4, bbox_map=80.648655 .\r\n",
      "2023-03-12 16:41:59 [INFO]\tModel saved in output/faster_rcnn_r50_fpn/best_model.\r\n",
      "2023-03-12 16:41:59 [INFO]\tCurrent evaluated best model on eval_dataset is epoch_4, bbox_map=80.64865547974077\r\n",
      "2023-03-12 16:42:00 [INFO]\tModel saved in output/faster_rcnn_r50_fpn/epoch_4.\r\n",
      "2023-03-12 16:42:02 [INFO]\t[TRAIN] Epoch=5/10, Step=10/490, loss_rpn_cls=0.001718, loss_rpn_reg=0.006410, loss_bbox_cls=0.074464, loss_bbox_reg=0.093380, loss=0.175972, lr=0.000250, time_each_step=0.23s, eta=0:12:38\r\n",
      "2023-03-12 16:42:04 [INFO]\t[TRAIN] Epoch=5/10, Step=20/490, loss_rpn_cls=0.029435, loss_rpn_reg=0.028510, loss_bbox_cls=0.143184, loss_bbox_reg=0.157928, loss=0.359057, lr=0.000250, time_each_step=0.17s, eta=0:9:58\r\n",
      "2023-03-12 16:42:05 [INFO]\t[TRAIN] Epoch=5/10, Step=30/490, loss_rpn_cls=0.001127, loss_rpn_reg=0.003683, loss_bbox_cls=0.047438, loss_bbox_reg=0.084601, loss=0.136849, lr=0.000250, time_each_step=0.18s, eta=0:10:20\r\n",
      "2023-03-12 16:42:07 [INFO]\t[TRAIN] Epoch=5/10, Step=40/490, loss_rpn_cls=0.016741, loss_rpn_reg=0.013834, loss_bbox_cls=0.076201, loss_bbox_reg=0.103036, loss=0.209812, lr=0.000250, time_each_step=0.18s, eta=0:10:14\r\n",
      "2023-03-12 16:42:09 [INFO]\t[TRAIN] Epoch=5/10, Step=50/490, loss_rpn_cls=0.001725, loss_rpn_reg=0.007548, loss_bbox_cls=0.021969, loss_bbox_reg=0.061587, loss=0.092829, lr=0.000250, time_each_step=0.18s, eta=0:9:58\r\n",
      "2023-03-12 16:42:11 [INFO]\t[TRAIN] Epoch=5/10, Step=60/490, loss_rpn_cls=0.002439, loss_rpn_reg=0.002282, loss_bbox_cls=0.053350, loss_bbox_reg=0.088492, loss=0.146563, lr=0.000250, time_each_step=0.17s, eta=0:9:51\r\n",
      "2023-03-12 16:42:13 [INFO]\t[TRAIN] Epoch=5/10, Step=70/490, loss_rpn_cls=0.009748, loss_rpn_reg=0.048640, loss_bbox_cls=0.059130, loss_bbox_reg=0.131646, loss=0.249164, lr=0.000250, time_each_step=0.18s, eta=0:9:58\r\n",
      "2023-03-12 16:42:14 [INFO]\t[TRAIN] Epoch=5/10, Step=80/490, loss_rpn_cls=0.005916, loss_rpn_reg=0.006714, loss_bbox_cls=0.020006, loss_bbox_reg=0.042077, loss=0.074712, lr=0.000250, time_each_step=0.18s, eta=0:10:15\r\n",
      "2023-03-12 16:42:16 [INFO]\t[TRAIN] Epoch=5/10, Step=90/490, loss_rpn_cls=0.001377, loss_rpn_reg=0.004477, loss_bbox_cls=0.026220, loss_bbox_reg=0.058356, loss=0.090431, lr=0.000250, time_each_step=0.18s, eta=0:10:1\r\n",
      "2023-03-12 16:42:18 [INFO]\t[TRAIN] Epoch=5/10, Step=100/490, loss_rpn_cls=0.012586, loss_rpn_reg=0.002329, loss_bbox_cls=0.049557, loss_bbox_reg=0.042324, loss=0.106797, lr=0.000250, time_each_step=0.18s, eta=0:10:7\r\n",
      "2023-03-12 16:42:20 [INFO]\t[TRAIN] Epoch=5/10, Step=110/490, loss_rpn_cls=0.000636, loss_rpn_reg=0.008119, loss_bbox_cls=0.039938, loss_bbox_reg=0.077497, loss=0.126190, lr=0.000250, time_each_step=0.18s, eta=0:10:5\r\n",
      "2023-03-12 16:42:22 [INFO]\t[TRAIN] Epoch=5/10, Step=120/490, loss_rpn_cls=0.054679, loss_rpn_reg=0.034745, loss_bbox_cls=0.122637, loss_bbox_reg=0.193175, loss=0.405236, lr=0.000250, time_each_step=0.18s, eta=0:9:49\r\n",
      "2023-03-12 16:42:23 [INFO]\t[TRAIN] Epoch=5/10, Step=130/490, loss_rpn_cls=0.010953, loss_rpn_reg=0.004270, loss_bbox_cls=0.084845, loss_bbox_reg=0.125312, loss=0.225380, lr=0.000250, time_each_step=0.18s, eta=0:9:59\r\n",
      "2023-03-12 16:42:25 [INFO]\t[TRAIN] Epoch=5/10, Step=140/490, loss_rpn_cls=0.002594, loss_rpn_reg=0.022606, loss_bbox_cls=0.032813, loss_bbox_reg=0.037129, loss=0.095141, lr=0.000250, time_each_step=0.21s, eta=0:11:18\r\n",
      "2023-03-12 16:42:27 [INFO]\t[TRAIN] Epoch=5/10, Step=150/490, loss_rpn_cls=0.001516, loss_rpn_reg=0.004861, loss_bbox_cls=0.051351, loss_bbox_reg=0.073688, loss=0.131416, lr=0.000250, time_each_step=0.18s, eta=0:9:56\r\n",
      "2023-03-12 16:42:29 [INFO]\t[TRAIN] Epoch=5/10, Step=160/490, loss_rpn_cls=0.001982, loss_rpn_reg=0.002707, loss_bbox_cls=0.056846, loss_bbox_reg=0.078065, loss=0.139599, lr=0.000250, time_each_step=0.18s, eta=0:9:50\r\n",
      "2023-03-12 16:42:31 [INFO]\t[TRAIN] Epoch=5/10, Step=170/490, loss_rpn_cls=0.027914, loss_rpn_reg=0.003138, loss_bbox_cls=0.055355, loss_bbox_reg=0.063613, loss=0.150020, lr=0.000250, time_each_step=0.18s, eta=0:9:56\r\n",
      "2023-03-12 16:42:33 [INFO]\t[TRAIN] Epoch=5/10, Step=180/490, loss_rpn_cls=0.002350, loss_rpn_reg=0.004734, loss_bbox_cls=0.028045, loss_bbox_reg=0.037737, loss=0.072866, lr=0.000250, time_each_step=0.18s, eta=0:9:44\r\n",
      "2023-03-12 16:42:34 [INFO]\t[TRAIN] Epoch=5/10, Step=190/490, loss_rpn_cls=0.011332, loss_rpn_reg=0.007845, loss_bbox_cls=0.055066, loss_bbox_reg=0.087811, loss=0.162053, lr=0.000250, time_each_step=0.18s, eta=0:9:46\r\n",
      "2023-03-12 16:42:36 [INFO]\t[TRAIN] Epoch=5/10, Step=200/490, loss_rpn_cls=0.001794, loss_rpn_reg=0.000992, loss_bbox_cls=0.023642, loss_bbox_reg=0.046546, loss=0.072974, lr=0.000250, time_each_step=0.18s, eta=0:9:39\r\n",
      "2023-03-12 16:42:38 [INFO]\t[TRAIN] Epoch=5/10, Step=210/490, loss_rpn_cls=0.008407, loss_rpn_reg=0.011150, loss_bbox_cls=0.033956, loss_bbox_reg=0.049639, loss=0.103152, lr=0.000250, time_each_step=0.18s, eta=0:9:44\r\n",
      "2023-03-12 16:42:40 [INFO]\t[TRAIN] Epoch=5/10, Step=220/490, loss_rpn_cls=0.004784, loss_rpn_reg=0.014245, loss_bbox_cls=0.125093, loss_bbox_reg=0.154928, loss=0.299050, lr=0.000250, time_each_step=0.17s, eta=0:9:27\r\n",
      "2023-03-12 16:42:41 [INFO]\t[TRAIN] Epoch=5/10, Step=230/490, loss_rpn_cls=0.008214, loss_rpn_reg=0.008407, loss_bbox_cls=0.014215, loss_bbox_reg=0.037206, loss=0.068042, lr=0.000250, time_each_step=0.17s, eta=0:9:20\r\n",
      "2023-03-12 16:42:43 [INFO]\t[TRAIN] Epoch=5/10, Step=240/490, loss_rpn_cls=0.016083, loss_rpn_reg=0.016607, loss_bbox_cls=0.041643, loss_bbox_reg=0.091361, loss=0.165695, lr=0.000250, time_each_step=0.18s, eta=0:9:34\r\n",
      "2023-03-12 16:42:45 [INFO]\t[TRAIN] Epoch=5/10, Step=250/490, loss_rpn_cls=0.001631, loss_rpn_reg=0.001815, loss_bbox_cls=0.028239, loss_bbox_reg=0.058704, loss=0.090389, lr=0.000250, time_each_step=0.18s, eta=0:9:25\r\n",
      "2023-03-12 16:42:47 [INFO]\t[TRAIN] Epoch=5/10, Step=260/490, loss_rpn_cls=0.000429, loss_rpn_reg=0.003129, loss_bbox_cls=0.021589, loss_bbox_reg=0.052517, loss=0.077663, lr=0.000250, time_each_step=0.19s, eta=0:9:52\r\n",
      "2023-03-12 16:42:49 [INFO]\t[TRAIN] Epoch=5/10, Step=270/490, loss_rpn_cls=0.000503, loss_rpn_reg=0.002341, loss_bbox_cls=0.033030, loss_bbox_reg=0.050413, loss=0.086286, lr=0.000250, time_each_step=0.18s, eta=0:9:29\r\n",
      "2023-03-12 16:42:50 [INFO]\t[TRAIN] Epoch=5/10, Step=280/490, loss_rpn_cls=0.012715, loss_rpn_reg=0.005094, loss_bbox_cls=0.055972, loss_bbox_reg=0.054569, loss=0.128349, lr=0.000250, time_each_step=0.18s, eta=0:9:40\r\n",
      "2023-03-12 16:42:52 [INFO]\t[TRAIN] Epoch=5/10, Step=290/490, loss_rpn_cls=0.011698, loss_rpn_reg=0.013047, loss_bbox_cls=0.044921, loss_bbox_reg=0.090370, loss=0.160036, lr=0.000250, time_each_step=0.18s, eta=0:9:38\r\n",
      "2023-03-12 16:42:54 [INFO]\t[TRAIN] Epoch=5/10, Step=300/490, loss_rpn_cls=0.001397, loss_rpn_reg=0.005037, loss_bbox_cls=0.030525, loss_bbox_reg=0.031862, loss=0.068821, lr=0.000250, time_each_step=0.2s, eta=0:10:10\r\n",
      "2023-03-12 16:42:56 [INFO]\t[TRAIN] Epoch=5/10, Step=310/490, loss_rpn_cls=0.012062, loss_rpn_reg=0.013779, loss_bbox_cls=0.088740, loss_bbox_reg=0.143207, loss=0.257788, lr=0.000250, time_each_step=0.18s, eta=0:9:16\r\n",
      "2023-03-12 16:42:58 [INFO]\t[TRAIN] Epoch=5/10, Step=320/490, loss_rpn_cls=0.001215, loss_rpn_reg=0.001464, loss_bbox_cls=0.026305, loss_bbox_reg=0.036831, loss=0.065815, lr=0.000250, time_each_step=0.21s, eta=0:10:34\r\n",
      "2023-03-12 16:43:00 [INFO]\t[TRAIN] Epoch=5/10, Step=330/490, loss_rpn_cls=0.003001, loss_rpn_reg=0.019435, loss_bbox_cls=0.052574, loss_bbox_reg=0.147234, loss=0.222244, lr=0.000250, time_each_step=0.17s, eta=0:9:6\r\n",
      "2023-03-12 16:43:02 [INFO]\t[TRAIN] Epoch=5/10, Step=340/490, loss_rpn_cls=0.001484, loss_rpn_reg=0.005357, loss_bbox_cls=0.022416, loss_bbox_reg=0.029467, loss=0.058723, lr=0.000250, time_each_step=0.18s, eta=0:9:29\r\n",
      "2023-03-12 16:43:04 [INFO]\t[TRAIN] Epoch=5/10, Step=350/490, loss_rpn_cls=0.035617, loss_rpn_reg=0.015966, loss_bbox_cls=0.106350, loss_bbox_reg=0.140348, loss=0.298281, lr=0.000250, time_each_step=0.19s, eta=0:9:34\r\n",
      "2023-03-12 16:43:05 [INFO]\t[TRAIN] Epoch=5/10, Step=360/490, loss_rpn_cls=0.002508, loss_rpn_reg=0.003633, loss_bbox_cls=0.049309, loss_bbox_reg=0.106752, loss=0.162202, lr=0.000250, time_each_step=0.17s, eta=0:9:0\r\n",
      "2023-03-12 16:43:07 [INFO]\t[TRAIN] Epoch=5/10, Step=370/490, loss_rpn_cls=0.009692, loss_rpn_reg=0.002053, loss_bbox_cls=0.025543, loss_bbox_reg=0.061447, loss=0.098736, lr=0.000250, time_each_step=0.18s, eta=0:9:3\r\n",
      "2023-03-12 16:43:09 [INFO]\t[TRAIN] Epoch=5/10, Step=380/490, loss_rpn_cls=0.000373, loss_rpn_reg=0.000553, loss_bbox_cls=0.028596, loss_bbox_reg=0.079024, loss=0.108546, lr=0.000250, time_each_step=0.17s, eta=0:8:59\r\n",
      "2023-03-12 16:43:11 [INFO]\t[TRAIN] Epoch=5/10, Step=390/490, loss_rpn_cls=0.004218, loss_rpn_reg=0.002281, loss_bbox_cls=0.041458, loss_bbox_reg=0.047948, loss=0.095904, lr=0.000250, time_each_step=0.18s, eta=0:9:6\r\n",
      "2023-03-12 16:43:12 [INFO]\t[TRAIN] Epoch=5/10, Step=400/490, loss_rpn_cls=0.012212, loss_rpn_reg=0.013490, loss_bbox_cls=0.028801, loss_bbox_reg=0.045905, loss=0.100408, lr=0.000250, time_each_step=0.18s, eta=0:9:11\r\n",
      "2023-03-12 16:43:14 [INFO]\t[TRAIN] Epoch=5/10, Step=410/490, loss_rpn_cls=0.015776, loss_rpn_reg=0.049772, loss_bbox_cls=0.095413, loss_bbox_reg=0.187382, loss=0.348343, lr=0.000250, time_each_step=0.18s, eta=0:9:0\r\n",
      "2023-03-12 16:43:16 [INFO]\t[TRAIN] Epoch=5/10, Step=420/490, loss_rpn_cls=0.004347, loss_rpn_reg=0.005857, loss_bbox_cls=0.039406, loss_bbox_reg=0.033586, loss=0.083197, lr=0.000250, time_each_step=0.18s, eta=0:9:7\r\n",
      "2023-03-12 16:43:18 [INFO]\t[TRAIN] Epoch=5/10, Step=430/490, loss_rpn_cls=0.005753, loss_rpn_reg=0.011987, loss_bbox_cls=0.099149, loss_bbox_reg=0.118961, loss=0.235850, lr=0.000250, time_each_step=0.18s, eta=0:9:1\r\n",
      "2023-03-12 16:43:20 [INFO]\t[TRAIN] Epoch=5/10, Step=440/490, loss_rpn_cls=0.013030, loss_rpn_reg=0.025550, loss_bbox_cls=0.031149, loss_bbox_reg=0.028912, loss=0.098641, lr=0.000250, time_each_step=0.18s, eta=0:9:7\r\n",
      "2023-03-12 16:43:21 [INFO]\t[TRAIN] Epoch=5/10, Step=450/490, loss_rpn_cls=0.003511, loss_rpn_reg=0.008075, loss_bbox_cls=0.069966, loss_bbox_reg=0.089746, loss=0.171298, lr=0.000250, time_each_step=0.18s, eta=0:9:10\r\n",
      "2023-03-12 16:43:23 [INFO]\t[TRAIN] Epoch=5/10, Step=460/490, loss_rpn_cls=0.019535, loss_rpn_reg=0.001321, loss_bbox_cls=0.067527, loss_bbox_reg=0.091362, loss=0.179744, lr=0.000250, time_each_step=0.18s, eta=0:9:3\r\n",
      "2023-03-12 16:43:25 [INFO]\t[TRAIN] Epoch=5/10, Step=470/490, loss_rpn_cls=0.023633, loss_rpn_reg=0.019532, loss_bbox_cls=0.059911, loss_bbox_reg=0.137897, loss=0.240973, lr=0.000250, time_each_step=0.19s, eta=0:9:13\r\n",
      "2023-03-12 16:43:27 [INFO]\t[TRAIN] Epoch=5/10, Step=480/490, loss_rpn_cls=0.000504, loss_rpn_reg=0.007696, loss_bbox_cls=0.091105, loss_bbox_reg=0.101229, loss=0.200534, lr=0.000250, time_each_step=0.18s, eta=0:9:4\r\n",
      "2023-03-12 16:43:29 [INFO]\t[TRAIN] Epoch=5/10, Step=490/490, loss_rpn_cls=0.001746, loss_rpn_reg=0.006443, loss_bbox_cls=0.023012, loss_bbox_reg=0.058240, loss=0.089441, lr=0.000250, time_each_step=0.21s, eta=0:10:9\r\n",
      "2023-03-12 16:43:29 [INFO]\t[TRAIN] Epoch 5 finished, loss_rpn_cls=0.008705978, loss_rpn_reg=0.010298472, loss_bbox_cls=0.051211517, loss_bbox_reg=0.08188908, loss=0.15210506 .\r\n",
      "2023-03-12 16:43:29 [INFO]\tStart to evaluate(total_samples=140, total_steps=140)...\r\n",
      "2023-03-12 16:43:45 [INFO]\tAccumulating evaluatation results...\r\n",
      "2023-03-12 16:43:45 [INFO]\t[EVAL] Finished, Epoch=5, bbox_map=81.696168 .\r\n",
      "2023-03-12 16:43:48 [INFO]\tModel saved in output/faster_rcnn_r50_fpn/best_model.\r\n",
      "2023-03-12 16:43:48 [INFO]\tCurrent evaluated best model on eval_dataset is epoch_5, bbox_map=81.69616808500422\r\n",
      "2023-03-12 16:43:49 [INFO]\tModel saved in output/faster_rcnn_r50_fpn/epoch_5.\r\n",
      "2023-03-12 16:43:51 [INFO]\t[TRAIN] Epoch=6/10, Step=10/490, loss_rpn_cls=0.000734, loss_rpn_reg=0.006229, loss_bbox_cls=0.091718, loss_bbox_reg=0.120831, loss=0.219513, lr=0.000250, time_each_step=0.23s, eta=0:10:36\r\n",
      "2023-03-12 16:43:53 [INFO]\t[TRAIN] Epoch=6/10, Step=20/490, loss_rpn_cls=0.000640, loss_rpn_reg=0.004552, loss_bbox_cls=0.037864, loss_bbox_reg=0.076689, loss=0.119746, lr=0.000250, time_each_step=0.18s, eta=0:8:36\r\n",
      "2023-03-12 16:43:55 [INFO]\t[TRAIN] Epoch=6/10, Step=30/490, loss_rpn_cls=0.001044, loss_rpn_reg=0.005388, loss_bbox_cls=0.033587, loss_bbox_reg=0.074918, loss=0.114936, lr=0.000250, time_each_step=0.18s, eta=0:8:23\r\n",
      "2023-03-12 16:43:56 [INFO]\t[TRAIN] Epoch=6/10, Step=40/490, loss_rpn_cls=0.005355, loss_rpn_reg=0.012282, loss_bbox_cls=0.036178, loss_bbox_reg=0.076728, loss=0.130543, lr=0.000250, time_each_step=0.17s, eta=0:8:3\r\n",
      "2023-03-12 16:43:58 [INFO]\t[TRAIN] Epoch=6/10, Step=50/490, loss_rpn_cls=0.010188, loss_rpn_reg=0.006370, loss_bbox_cls=0.016514, loss_bbox_reg=0.039295, loss=0.072368, lr=0.000250, time_each_step=0.19s, eta=0:8:58\r\n",
      "2023-03-12 16:44:00 [INFO]\t[TRAIN] Epoch=6/10, Step=60/490, loss_rpn_cls=0.006860, loss_rpn_reg=0.003396, loss_bbox_cls=0.025920, loss_bbox_reg=0.044421, loss=0.080598, lr=0.000250, time_each_step=0.18s, eta=0:8:22\r\n",
      "2023-03-12 16:44:02 [INFO]\t[TRAIN] Epoch=6/10, Step=70/490, loss_rpn_cls=0.009095, loss_rpn_reg=0.036843, loss_bbox_cls=0.052242, loss_bbox_reg=0.146353, loss=0.244532, lr=0.000250, time_each_step=0.17s, eta=0:8:1\r\n",
      "2023-03-12 16:44:03 [INFO]\t[TRAIN] Epoch=6/10, Step=80/490, loss_rpn_cls=0.001977, loss_rpn_reg=0.003083, loss_bbox_cls=0.027889, loss_bbox_reg=0.058370, loss=0.091319, lr=0.000250, time_each_step=0.17s, eta=0:8:7\r\n",
      "2023-03-12 16:44:05 [INFO]\t[TRAIN] Epoch=6/10, Step=90/490, loss_rpn_cls=0.009344, loss_rpn_reg=0.004084, loss_bbox_cls=0.048202, loss_bbox_reg=0.090576, loss=0.152206, lr=0.000250, time_each_step=0.19s, eta=0:8:45\r\n",
      "2023-03-12 16:44:07 [INFO]\t[TRAIN] Epoch=6/10, Step=100/490, loss_rpn_cls=0.010196, loss_rpn_reg=0.006421, loss_bbox_cls=0.073812, loss_bbox_reg=0.090594, loss=0.181023, lr=0.000250, time_each_step=0.18s, eta=0:8:8\r\n",
      "2023-03-12 16:44:09 [INFO]\t[TRAIN] Epoch=6/10, Step=110/490, loss_rpn_cls=0.001510, loss_rpn_reg=0.004564, loss_bbox_cls=0.027382, loss_bbox_reg=0.083494, loss=0.116950, lr=0.000250, time_each_step=0.17s, eta=0:8:2\r\n",
      "2023-03-12 16:44:11 [INFO]\t[TRAIN] Epoch=6/10, Step=120/490, loss_rpn_cls=0.015886, loss_rpn_reg=0.023347, loss_bbox_cls=0.084547, loss_bbox_reg=0.192354, loss=0.316133, lr=0.000250, time_each_step=0.17s, eta=0:7:59\r\n",
      "2023-03-12 16:44:12 [INFO]\t[TRAIN] Epoch=6/10, Step=130/490, loss_rpn_cls=0.003524, loss_rpn_reg=0.014626, loss_bbox_cls=0.064239, loss_bbox_reg=0.167467, loss=0.249857, lr=0.000250, time_each_step=0.17s, eta=0:7:57\r\n",
      "2023-03-12 16:44:14 [INFO]\t[TRAIN] Epoch=6/10, Step=140/490, loss_rpn_cls=0.000424, loss_rpn_reg=0.004658, loss_bbox_cls=0.024926, loss_bbox_reg=0.026444, loss=0.056452, lr=0.000250, time_each_step=0.18s, eta=0:8:7\r\n",
      "2023-03-12 16:44:16 [INFO]\t[TRAIN] Epoch=6/10, Step=150/490, loss_rpn_cls=0.001607, loss_rpn_reg=0.003369, loss_bbox_cls=0.051895, loss_bbox_reg=0.083079, loss=0.139950, lr=0.000250, time_each_step=0.18s, eta=0:8:6\r\n",
      "2023-03-12 16:44:18 [INFO]\t[TRAIN] Epoch=6/10, Step=160/490, loss_rpn_cls=0.001017, loss_rpn_reg=0.005917, loss_bbox_cls=0.038480, loss_bbox_reg=0.076853, loss=0.122267, lr=0.000250, time_each_step=0.18s, eta=0:8:3\r\n",
      "2023-03-12 16:44:19 [INFO]\t[TRAIN] Epoch=6/10, Step=170/490, loss_rpn_cls=0.001963, loss_rpn_reg=0.001162, loss_bbox_cls=0.024536, loss_bbox_reg=0.063372, loss=0.091034, lr=0.000250, time_each_step=0.18s, eta=0:7:59\r\n",
      "2023-03-12 16:44:21 [INFO]\t[TRAIN] Epoch=6/10, Step=180/490, loss_rpn_cls=0.003969, loss_rpn_reg=0.003155, loss_bbox_cls=0.053739, loss_bbox_reg=0.082928, loss=0.143791, lr=0.000250, time_each_step=0.19s, eta=0:8:23\r\n",
      "2023-03-12 16:44:23 [INFO]\t[TRAIN] Epoch=6/10, Step=190/490, loss_rpn_cls=0.011531, loss_rpn_reg=0.004523, loss_bbox_cls=0.016270, loss_bbox_reg=0.043565, loss=0.075890, lr=0.000250, time_each_step=0.18s, eta=0:8:0\r\n",
      "2023-03-12 16:44:25 [INFO]\t[TRAIN] Epoch=6/10, Step=200/490, loss_rpn_cls=0.002737, loss_rpn_reg=0.002175, loss_bbox_cls=0.046138, loss_bbox_reg=0.058595, loss=0.109644, lr=0.000250, time_each_step=0.17s, eta=0:7:45\r\n",
      "2023-03-12 16:44:27 [INFO]\t[TRAIN] Epoch=6/10, Step=210/490, loss_rpn_cls=0.012865, loss_rpn_reg=0.007513, loss_bbox_cls=0.046444, loss_bbox_reg=0.071998, loss=0.138819, lr=0.000250, time_each_step=0.18s, eta=0:7:54\r\n",
      "2023-03-12 16:44:28 [INFO]\t[TRAIN] Epoch=6/10, Step=220/490, loss_rpn_cls=0.013901, loss_rpn_reg=0.019223, loss_bbox_cls=0.100840, loss_bbox_reg=0.139665, loss=0.273629, lr=0.000250, time_each_step=0.18s, eta=0:7:51\r\n",
      "2023-03-12 16:44:31 [INFO]\t[TRAIN] Epoch=6/10, Step=230/490, loss_rpn_cls=0.009191, loss_rpn_reg=0.004420, loss_bbox_cls=0.042881, loss_bbox_reg=0.083731, loss=0.140224, lr=0.000250, time_each_step=0.21s, eta=0:8:54\r\n",
      "2023-03-12 16:44:32 [INFO]\t[TRAIN] Epoch=6/10, Step=240/490, loss_rpn_cls=0.003219, loss_rpn_reg=0.007130, loss_bbox_cls=0.084185, loss_bbox_reg=0.160003, loss=0.254537, lr=0.000250, time_each_step=0.17s, eta=0:7:40\r\n",
      "2023-03-12 16:44:34 [INFO]\t[TRAIN] Epoch=6/10, Step=250/490, loss_rpn_cls=0.003734, loss_rpn_reg=0.002127, loss_bbox_cls=0.026571, loss_bbox_reg=0.038730, loss=0.071161, lr=0.000250, time_each_step=0.18s, eta=0:7:43\r\n",
      "2023-03-12 16:44:36 [INFO]\t[TRAIN] Epoch=6/10, Step=260/490, loss_rpn_cls=0.000744, loss_rpn_reg=0.002758, loss_bbox_cls=0.024233, loss_bbox_reg=0.040820, loss=0.068556, lr=0.000250, time_each_step=0.16s, eta=0:6:56\r\n",
      "2023-03-12 16:44:37 [INFO]\t[TRAIN] Epoch=6/10, Step=270/490, loss_rpn_cls=0.001170, loss_rpn_reg=0.003857, loss_bbox_cls=0.026269, loss_bbox_reg=0.054864, loss=0.086160, lr=0.000250, time_each_step=0.14s, eta=0:6:10\r\n",
      "2023-03-12 16:44:38 [INFO]\t[TRAIN] Epoch=6/10, Step=280/490, loss_rpn_cls=0.001419, loss_rpn_reg=0.003524, loss_bbox_cls=0.014396, loss_bbox_reg=0.044935, loss=0.064273, lr=0.000250, time_each_step=0.13s, eta=0:6:4\r\n",
      "2023-03-12 16:44:40 [INFO]\t[TRAIN] Epoch=6/10, Step=290/490, loss_rpn_cls=0.001876, loss_rpn_reg=0.002251, loss_bbox_cls=0.031164, loss_bbox_reg=0.039632, loss=0.074922, lr=0.000250, time_each_step=0.15s, eta=0:6:32\r\n",
      "2023-03-12 16:44:41 [INFO]\t[TRAIN] Epoch=6/10, Step=300/490, loss_rpn_cls=0.000893, loss_rpn_reg=0.006026, loss_bbox_cls=0.018820, loss_bbox_reg=0.066956, loss=0.092696, lr=0.000250, time_each_step=0.14s, eta=0:6:18\r\n",
      "2023-03-12 16:44:43 [INFO]\t[TRAIN] Epoch=6/10, Step=310/490, loss_rpn_cls=0.009477, loss_rpn_reg=0.009399, loss_bbox_cls=0.095368, loss_bbox_reg=0.152106, loss=0.266350, lr=0.000250, time_each_step=0.14s, eta=0:6:22\r\n",
      "2023-03-12 16:44:44 [INFO]\t[TRAIN] Epoch=6/10, Step=320/490, loss_rpn_cls=0.024760, loss_rpn_reg=0.012078, loss_bbox_cls=0.057285, loss_bbox_reg=0.104427, loss=0.198550, lr=0.000250, time_each_step=0.14s, eta=0:6:18\r\n",
      "2023-03-12 16:44:46 [INFO]\t[TRAIN] Epoch=6/10, Step=330/490, loss_rpn_cls=0.014267, loss_rpn_reg=0.015977, loss_bbox_cls=0.102915, loss_bbox_reg=0.149106, loss=0.282265, lr=0.000250, time_each_step=0.15s, eta=0:6:25\r\n",
      "2023-03-12 16:44:47 [INFO]\t[TRAIN] Epoch=6/10, Step=340/490, loss_rpn_cls=0.004978, loss_rpn_reg=0.009029, loss_bbox_cls=0.030876, loss_bbox_reg=0.045992, loss=0.090874, lr=0.000250, time_each_step=0.14s, eta=0:6:11\r\n",
      "2023-03-12 16:44:48 [INFO]\t[TRAIN] Epoch=6/10, Step=350/490, loss_rpn_cls=0.003710, loss_rpn_reg=0.004085, loss_bbox_cls=0.072643, loss_bbox_reg=0.134016, loss=0.214454, lr=0.000250, time_each_step=0.14s, eta=0:6:9\r\n",
      "2023-03-12 16:44:50 [INFO]\t[TRAIN] Epoch=6/10, Step=360/490, loss_rpn_cls=0.000403, loss_rpn_reg=0.002271, loss_bbox_cls=0.029236, loss_bbox_reg=0.054402, loss=0.086312, lr=0.000250, time_each_step=0.14s, eta=0:6:7\r\n",
      "2023-03-12 16:44:51 [INFO]\t[TRAIN] Epoch=6/10, Step=370/490, loss_rpn_cls=0.003456, loss_rpn_reg=0.001256, loss_bbox_cls=0.026231, loss_bbox_reg=0.062260, loss=0.093203, lr=0.000250, time_each_step=0.14s, eta=0:6:1\r\n",
      "2023-03-12 16:44:53 [INFO]\t[TRAIN] Epoch=6/10, Step=380/490, loss_rpn_cls=0.000169, loss_rpn_reg=0.000762, loss_bbox_cls=0.012775, loss_bbox_reg=0.035592, loss=0.049297, lr=0.000250, time_each_step=0.14s, eta=0:6:13\r\n",
      "2023-03-12 16:44:54 [INFO]\t[TRAIN] Epoch=6/10, Step=390/490, loss_rpn_cls=0.000343, loss_rpn_reg=0.000492, loss_bbox_cls=0.022258, loss_bbox_reg=0.039921, loss=0.063014, lr=0.000250, time_each_step=0.15s, eta=0:6:23\r\n",
      "2023-03-12 16:44:56 [INFO]\t[TRAIN] Epoch=6/10, Step=400/490, loss_rpn_cls=0.012465, loss_rpn_reg=0.010628, loss_bbox_cls=0.039375, loss_bbox_reg=0.046392, loss=0.108859, lr=0.000250, time_each_step=0.14s, eta=0:6:9\r\n",
      "2023-03-12 16:44:57 [INFO]\t[TRAIN] Epoch=6/10, Step=410/490, loss_rpn_cls=0.005514, loss_rpn_reg=0.030710, loss_bbox_cls=0.020427, loss_bbox_reg=0.007203, loss=0.063855, lr=0.000250, time_each_step=0.15s, eta=0:6:29\r\n",
      "2023-03-12 16:44:59 [INFO]\t[TRAIN] Epoch=6/10, Step=420/490, loss_rpn_cls=0.001755, loss_rpn_reg=0.005062, loss_bbox_cls=0.031161, loss_bbox_reg=0.056708, loss=0.094687, lr=0.000250, time_each_step=0.15s, eta=0:6:14\r\n",
      "2023-03-12 16:45:00 [INFO]\t[TRAIN] Epoch=6/10, Step=430/490, loss_rpn_cls=0.023244, loss_rpn_reg=0.020867, loss_bbox_cls=0.045835, loss_bbox_reg=0.052979, loss=0.142925, lr=0.000250, time_each_step=0.16s, eta=0:6:46\r\n",
      "2023-03-12 16:45:02 [INFO]\t[TRAIN] Epoch=6/10, Step=440/490, loss_rpn_cls=0.007164, loss_rpn_reg=0.001900, loss_bbox_cls=0.030372, loss_bbox_reg=0.062266, loss=0.101702, lr=0.000250, time_each_step=0.14s, eta=0:5:47\r\n",
      "2023-03-12 16:45:03 [INFO]\t[TRAIN] Epoch=6/10, Step=450/490, loss_rpn_cls=0.019659, loss_rpn_reg=0.016563, loss_bbox_cls=0.084893, loss_bbox_reg=0.125183, loss=0.246298, lr=0.000250, time_each_step=0.14s, eta=0:5:49\r\n",
      "2023-03-12 16:45:04 [INFO]\t[TRAIN] Epoch=6/10, Step=460/490, loss_rpn_cls=0.008835, loss_rpn_reg=0.002328, loss_bbox_cls=0.041998, loss_bbox_reg=0.076802, loss=0.129963, lr=0.000250, time_each_step=0.14s, eta=0:5:58\r\n",
      "2023-03-12 16:45:06 [INFO]\t[TRAIN] Epoch=6/10, Step=470/490, loss_rpn_cls=0.003899, loss_rpn_reg=0.009735, loss_bbox_cls=0.089958, loss_bbox_reg=0.142920, loss=0.246513, lr=0.000250, time_each_step=0.15s, eta=0:6:10\r\n",
      "2023-03-12 16:45:07 [INFO]\t[TRAIN] Epoch=6/10, Step=480/490, loss_rpn_cls=0.000162, loss_rpn_reg=0.002990, loss_bbox_cls=0.025191, loss_bbox_reg=0.089814, loss=0.118156, lr=0.000250, time_each_step=0.15s, eta=0:6:6\r\n",
      "2023-03-12 16:45:09 [INFO]\t[TRAIN] Epoch=6/10, Step=490/490, loss_rpn_cls=0.006524, loss_rpn_reg=0.003723, loss_bbox_cls=0.032580, loss_bbox_reg=0.041746, loss=0.084573, lr=0.000250, time_each_step=0.14s, eta=0:5:39\r\n",
      "2023-03-12 16:45:09 [INFO]\t[TRAIN] Epoch 6 finished, loss_rpn_cls=0.007204593, loss_rpn_reg=0.008666413, loss_bbox_cls=0.049536537, loss_bbox_reg=0.081731595, loss=0.14713913 .\r\n",
      "2023-03-12 16:45:09 [INFO]\tStart to evaluate(total_samples=140, total_steps=140)...\r\n",
      "2023-03-12 16:45:24 [INFO]\tAccumulating evaluatation results...\r\n",
      "2023-03-12 16:45:24 [INFO]\t[EVAL] Finished, Epoch=6, bbox_map=88.355528 .\r\n",
      "2023-03-12 16:45:27 [INFO]\tModel saved in output/faster_rcnn_r50_fpn/best_model.\r\n",
      "2023-03-12 16:45:27 [INFO]\tCurrent evaluated best model on eval_dataset is epoch_6, bbox_map=88.35552798658715\r\n",
      "2023-03-12 16:45:28 [INFO]\tModel saved in output/faster_rcnn_r50_fpn/epoch_6.\r\n",
      "2023-03-12 16:45:30 [INFO]\t[TRAIN] Epoch=7/10, Step=10/490, loss_rpn_cls=0.006180, loss_rpn_reg=0.003630, loss_bbox_cls=0.079508, loss_bbox_reg=0.177171, loss=0.266490, lr=0.000250, time_each_step=0.22s, eta=0:8:5\r\n",
      "2023-03-12 16:45:32 [INFO]\t[TRAIN] Epoch=7/10, Step=20/490, loss_rpn_cls=0.005832, loss_rpn_reg=0.003467, loss_bbox_cls=0.035245, loss_bbox_reg=0.061373, loss=0.105917, lr=0.000250, time_each_step=0.18s, eta=0:6:36\r\n",
      "2023-03-12 16:45:34 [INFO]\t[TRAIN] Epoch=7/10, Step=30/490, loss_rpn_cls=0.000749, loss_rpn_reg=0.002412, loss_bbox_cls=0.022941, loss_bbox_reg=0.072308, loss=0.098410, lr=0.000250, time_each_step=0.2s, eta=0:7:11\r\n",
      "2023-03-12 16:45:36 [INFO]\t[TRAIN] Epoch=7/10, Step=40/490, loss_rpn_cls=0.012520, loss_rpn_reg=0.015685, loss_bbox_cls=0.037155, loss_bbox_reg=0.080427, loss=0.145788, lr=0.000250, time_each_step=0.17s, eta=0:6:25\r\n",
      "2023-03-12 16:45:38 [INFO]\t[TRAIN] Epoch=7/10, Step=50/490, loss_rpn_cls=0.000562, loss_rpn_reg=0.007548, loss_bbox_cls=0.022579, loss_bbox_reg=0.039359, loss=0.070048, lr=0.000250, time_each_step=0.18s, eta=0:6:33\r\n",
      "2023-03-12 16:45:39 [INFO]\t[TRAIN] Epoch=7/10, Step=60/490, loss_rpn_cls=0.001184, loss_rpn_reg=0.001991, loss_bbox_cls=0.032333, loss_bbox_reg=0.054953, loss=0.090461, lr=0.000250, time_each_step=0.18s, eta=0:6:33\r\n",
      "2023-03-12 16:45:41 [INFO]\t[TRAIN] Epoch=7/10, Step=70/490, loss_rpn_cls=0.013252, loss_rpn_reg=0.047497, loss_bbox_cls=0.070536, loss_bbox_reg=0.151789, loss=0.283074, lr=0.000250, time_each_step=0.18s, eta=0:6:27\r\n",
      "2023-03-12 16:45:43 [INFO]\t[TRAIN] Epoch=7/10, Step=80/490, loss_rpn_cls=0.000504, loss_rpn_reg=0.002693, loss_bbox_cls=0.022898, loss_bbox_reg=0.053335, loss=0.079431, lr=0.000250, time_each_step=0.17s, eta=0:6:6\r\n",
      "2023-03-12 16:45:45 [INFO]\t[TRAIN] Epoch=7/10, Step=90/490, loss_rpn_cls=0.003274, loss_rpn_reg=0.011841, loss_bbox_cls=0.011247, loss_bbox_reg=0.010954, loss=0.037316, lr=0.000250, time_each_step=0.2s, eta=0:7:16\r\n",
      "2023-03-12 16:45:47 [INFO]\t[TRAIN] Epoch=7/10, Step=100/490, loss_rpn_cls=0.001802, loss_rpn_reg=0.005907, loss_bbox_cls=0.036583, loss_bbox_reg=0.021912, loss=0.066204, lr=0.000250, time_each_step=0.19s, eta=0:6:41\r\n",
      "2023-03-12 16:45:49 [INFO]\t[TRAIN] Epoch=7/10, Step=110/490, loss_rpn_cls=0.003672, loss_rpn_reg=0.005671, loss_bbox_cls=0.068711, loss_bbox_reg=0.098045, loss=0.176099, lr=0.000250, time_each_step=0.18s, eta=0:6:20\r\n",
      "2023-03-12 16:45:50 [INFO]\t[TRAIN] Epoch=7/10, Step=120/490, loss_rpn_cls=0.038615, loss_rpn_reg=0.027481, loss_bbox_cls=0.080834, loss_bbox_reg=0.126841, loss=0.273771, lr=0.000250, time_each_step=0.18s, eta=0:6:31\r\n",
      "2023-03-12 16:45:52 [INFO]\t[TRAIN] Epoch=7/10, Step=130/490, loss_rpn_cls=0.023099, loss_rpn_reg=0.011641, loss_bbox_cls=0.113812, loss_bbox_reg=0.131886, loss=0.280438, lr=0.000250, time_each_step=0.18s, eta=0:6:27\r\n",
      "2023-03-12 16:45:54 [INFO]\t[TRAIN] Epoch=7/10, Step=140/490, loss_rpn_cls=0.000797, loss_rpn_reg=0.010742, loss_bbox_cls=0.053739, loss_bbox_reg=0.058698, loss=0.123977, lr=0.000250, time_each_step=0.18s, eta=0:6:18\r\n",
      "2023-03-12 16:45:56 [INFO]\t[TRAIN] Epoch=7/10, Step=150/490, loss_rpn_cls=0.001581, loss_rpn_reg=0.007126, loss_bbox_cls=0.059631, loss_bbox_reg=0.084662, loss=0.153000, lr=0.000250, time_each_step=0.18s, eta=0:6:16\r\n",
      "2023-03-12 16:45:57 [INFO]\t[TRAIN] Epoch=7/10, Step=160/490, loss_rpn_cls=0.004131, loss_rpn_reg=0.002763, loss_bbox_cls=0.029715, loss_bbox_reg=0.077551, loss=0.114160, lr=0.000250, time_each_step=0.18s, eta=0:6:12\r\n",
      "2023-03-12 16:45:59 [INFO]\t[TRAIN] Epoch=7/10, Step=170/490, loss_rpn_cls=0.017367, loss_rpn_reg=0.003995, loss_bbox_cls=0.042040, loss_bbox_reg=0.052226, loss=0.115628, lr=0.000250, time_each_step=0.18s, eta=0:6:24\r\n",
      "2023-03-12 16:46:01 [INFO]\t[TRAIN] Epoch=7/10, Step=180/490, loss_rpn_cls=0.001732, loss_rpn_reg=0.021190, loss_bbox_cls=0.029322, loss_bbox_reg=0.050085, loss=0.102329, lr=0.000250, time_each_step=0.19s, eta=0:6:29\r\n",
      "2023-03-12 16:46:03 [INFO]\t[TRAIN] Epoch=7/10, Step=190/490, loss_rpn_cls=0.005888, loss_rpn_reg=0.003275, loss_bbox_cls=0.016352, loss_bbox_reg=0.015613, loss=0.041127, lr=0.000250, time_each_step=0.18s, eta=0:6:21\r\n",
      "2023-03-12 16:46:05 [INFO]\t[TRAIN] Epoch=7/10, Step=200/490, loss_rpn_cls=0.000523, loss_rpn_reg=0.004149, loss_bbox_cls=0.018913, loss_bbox_reg=0.030138, loss=0.053723, lr=0.000250, time_each_step=0.18s, eta=0:6:9\r\n",
      "2023-03-12 16:46:07 [INFO]\t[TRAIN] Epoch=7/10, Step=210/490, loss_rpn_cls=0.001352, loss_rpn_reg=0.003114, loss_bbox_cls=0.037733, loss_bbox_reg=0.064738, loss=0.106938, lr=0.000250, time_each_step=0.21s, eta=0:7:2\r\n",
      "2023-03-12 16:46:09 [INFO]\t[TRAIN] Epoch=7/10, Step=220/490, loss_rpn_cls=0.002808, loss_rpn_reg=0.011606, loss_bbox_cls=0.090412, loss_bbox_reg=0.136417, loss=0.241242, lr=0.000250, time_each_step=0.17s, eta=0:5:52\r\n",
      "2023-03-12 16:46:10 [INFO]\t[TRAIN] Epoch=7/10, Step=230/490, loss_rpn_cls=0.050975, loss_rpn_reg=0.014416, loss_bbox_cls=0.034263, loss_bbox_reg=0.049810, loss=0.149465, lr=0.000250, time_each_step=0.17s, eta=0:5:54\r\n",
      "2023-03-12 16:46:12 [INFO]\t[TRAIN] Epoch=7/10, Step=240/490, loss_rpn_cls=0.001285, loss_rpn_reg=0.005388, loss_bbox_cls=0.065638, loss_bbox_reg=0.108333, loss=0.180644, lr=0.000250, time_each_step=0.19s, eta=0:6:15\r\n",
      "2023-03-12 16:46:14 [INFO]\t[TRAIN] Epoch=7/10, Step=250/490, loss_rpn_cls=0.000273, loss_rpn_reg=0.003734, loss_bbox_cls=0.029657, loss_bbox_reg=0.045699, loss=0.079363, lr=0.000250, time_each_step=0.18s, eta=0:6:5\r\n",
      "2023-03-12 16:46:16 [INFO]\t[TRAIN] Epoch=7/10, Step=260/490, loss_rpn_cls=0.006377, loss_rpn_reg=0.011842, loss_bbox_cls=0.042764, loss_bbox_reg=0.097725, loss=0.158708, lr=0.000250, time_each_step=0.18s, eta=0:5:54\r\n",
      "2023-03-12 16:46:18 [INFO]\t[TRAIN] Epoch=7/10, Step=270/490, loss_rpn_cls=0.000663, loss_rpn_reg=0.004113, loss_bbox_cls=0.024136, loss_bbox_reg=0.045636, loss=0.074549, lr=0.000250, time_each_step=0.18s, eta=0:6:3\r\n",
      "2023-03-12 16:46:19 [INFO]\t[TRAIN] Epoch=7/10, Step=280/490, loss_rpn_cls=0.001842, loss_rpn_reg=0.005032, loss_bbox_cls=0.033687, loss_bbox_reg=0.071123, loss=0.111685, lr=0.000250, time_each_step=0.17s, eta=0:5:46\r\n",
      "2023-03-12 16:46:21 [INFO]\t[TRAIN] Epoch=7/10, Step=290/490, loss_rpn_cls=0.000271, loss_rpn_reg=0.002280, loss_bbox_cls=0.015012, loss_bbox_reg=0.036517, loss=0.054079, lr=0.000250, time_each_step=0.17s, eta=0:5:43\r\n",
      "2023-03-12 16:46:23 [INFO]\t[TRAIN] Epoch=7/10, Step=300/490, loss_rpn_cls=0.000262, loss_rpn_reg=0.002276, loss_bbox_cls=0.040972, loss_bbox_reg=0.078918, loss=0.122429, lr=0.000250, time_each_step=0.18s, eta=0:6:1\r\n",
      "2023-03-12 16:46:25 [INFO]\t[TRAIN] Epoch=7/10, Step=310/490, loss_rpn_cls=0.002980, loss_rpn_reg=0.006293, loss_bbox_cls=0.064183, loss_bbox_reg=0.168873, loss=0.242329, lr=0.000250, time_each_step=0.18s, eta=0:5:51\r\n",
      "2023-03-12 16:46:26 [INFO]\t[TRAIN] Epoch=7/10, Step=320/490, loss_rpn_cls=0.000301, loss_rpn_reg=0.001611, loss_bbox_cls=0.029583, loss_bbox_reg=0.048702, loss=0.080197, lr=0.000250, time_each_step=0.18s, eta=0:5:44\r\n",
      "2023-03-12 16:46:28 [INFO]\t[TRAIN] Epoch=7/10, Step=330/490, loss_rpn_cls=0.002070, loss_rpn_reg=0.017922, loss_bbox_cls=0.138818, loss_bbox_reg=0.227430, loss=0.386241, lr=0.000250, time_each_step=0.17s, eta=0:5:36\r\n",
      "2023-03-12 16:46:30 [INFO]\t[TRAIN] Epoch=7/10, Step=340/490, loss_rpn_cls=0.003586, loss_rpn_reg=0.008588, loss_bbox_cls=0.044345, loss_bbox_reg=0.077175, loss=0.133693, lr=0.000250, time_each_step=0.17s, eta=0:5:32\r\n",
      "2023-03-12 16:46:32 [INFO]\t[TRAIN] Epoch=7/10, Step=350/490, loss_rpn_cls=0.003767, loss_rpn_reg=0.007874, loss_bbox_cls=0.056373, loss_bbox_reg=0.117237, loss=0.185251, lr=0.000250, time_each_step=0.18s, eta=0:5:44\r\n",
      "2023-03-12 16:46:33 [INFO]\t[TRAIN] Epoch=7/10, Step=360/490, loss_rpn_cls=0.009523, loss_rpn_reg=0.002199, loss_bbox_cls=0.036436, loss_bbox_reg=0.048535, loss=0.096694, lr=0.000250, time_each_step=0.17s, eta=0:5:35\r\n",
      "2023-03-12 16:46:35 [INFO]\t[TRAIN] Epoch=7/10, Step=370/490, loss_rpn_cls=0.000493, loss_rpn_reg=0.000655, loss_bbox_cls=0.030045, loss_bbox_reg=0.070085, loss=0.101278, lr=0.000250, time_each_step=0.18s, eta=0:5:40\r\n",
      "2023-03-12 16:46:37 [INFO]\t[TRAIN] Epoch=7/10, Step=380/490, loss_rpn_cls=0.000087, loss_rpn_reg=0.001979, loss_bbox_cls=0.024914, loss_bbox_reg=0.042609, loss=0.069589, lr=0.000250, time_each_step=0.19s, eta=0:5:51\r\n",
      "2023-03-12 16:46:39 [INFO]\t[TRAIN] Epoch=7/10, Step=390/490, loss_rpn_cls=0.001564, loss_rpn_reg=0.008225, loss_bbox_cls=0.028577, loss_bbox_reg=0.055718, loss=0.094084, lr=0.000250, time_each_step=0.18s, eta=0:5:37\r\n",
      "2023-03-12 16:46:41 [INFO]\t[TRAIN] Epoch=7/10, Step=400/490, loss_rpn_cls=0.003514, loss_rpn_reg=0.010094, loss_bbox_cls=0.024267, loss_bbox_reg=0.056610, loss=0.094486, lr=0.000250, time_each_step=0.18s, eta=0:5:31\r\n",
      "2023-03-12 16:46:43 [INFO]\t[TRAIN] Epoch=7/10, Step=410/490, loss_rpn_cls=0.006298, loss_rpn_reg=0.048468, loss_bbox_cls=0.142995, loss_bbox_reg=0.222859, loss=0.420620, lr=0.000250, time_each_step=0.18s, eta=0:5:40\r\n",
      "2023-03-12 16:46:44 [INFO]\t[TRAIN] Epoch=7/10, Step=420/490, loss_rpn_cls=0.012037, loss_rpn_reg=0.000991, loss_bbox_cls=0.030949, loss_bbox_reg=0.037156, loss=0.081134, lr=0.000250, time_each_step=0.19s, eta=0:5:47\r\n",
      "2023-03-12 16:46:46 [INFO]\t[TRAIN] Epoch=7/10, Step=430/490, loss_rpn_cls=0.009354, loss_rpn_reg=0.010900, loss_bbox_cls=0.081210, loss_bbox_reg=0.096542, loss=0.198005, lr=0.000250, time_each_step=0.19s, eta=0:5:53\r\n",
      "2023-03-12 16:46:48 [INFO]\t[TRAIN] Epoch=7/10, Step=440/490, loss_rpn_cls=0.000949, loss_rpn_reg=0.001821, loss_bbox_cls=0.045456, loss_bbox_reg=0.114230, loss=0.162455, lr=0.000250, time_each_step=0.17s, eta=0:5:20\r\n",
      "2023-03-12 16:46:50 [INFO]\t[TRAIN] Epoch=7/10, Step=450/490, loss_rpn_cls=0.002723, loss_rpn_reg=0.004244, loss_bbox_cls=0.103196, loss_bbox_reg=0.193514, loss=0.303676, lr=0.000250, time_each_step=0.19s, eta=0:5:48\r\n",
      "2023-03-12 16:46:52 [INFO]\t[TRAIN] Epoch=7/10, Step=460/490, loss_rpn_cls=0.003078, loss_rpn_reg=0.006325, loss_bbox_cls=0.051191, loss_bbox_reg=0.091692, loss=0.152287, lr=0.000250, time_each_step=0.17s, eta=0:5:16\r\n",
      "2023-03-12 16:46:54 [INFO]\t[TRAIN] Epoch=7/10, Step=470/490, loss_rpn_cls=0.003610, loss_rpn_reg=0.015763, loss_bbox_cls=0.109655, loss_bbox_reg=0.156089, loss=0.285117, lr=0.000250, time_each_step=0.19s, eta=0:5:34\r\n",
      "2023-03-12 16:46:55 [INFO]\t[TRAIN] Epoch=7/10, Step=480/490, loss_rpn_cls=0.001432, loss_rpn_reg=0.004087, loss_bbox_cls=0.033011, loss_bbox_reg=0.087938, loss=0.126468, lr=0.000250, time_each_step=0.17s, eta=0:5:11\r\n",
      "2023-03-12 16:46:57 [INFO]\t[TRAIN] Epoch=7/10, Step=490/490, loss_rpn_cls=0.005856, loss_rpn_reg=0.004388, loss_bbox_cls=0.025568, loss_bbox_reg=0.056641, loss=0.092452, lr=0.000250, time_each_step=0.17s, eta=0:5:7\r\n",
      "2023-03-12 16:46:57 [INFO]\t[TRAIN] Epoch 7 finished, loss_rpn_cls=0.0053305514, loss_rpn_reg=0.008565644, loss_bbox_cls=0.04748851, loss_bbox_reg=0.0826777, loss=0.14406241 .\r\n",
      "2023-03-12 16:46:57 [INFO]\tStart to evaluate(total_samples=140, total_steps=140)...\r\n",
      "2023-03-12 16:47:12 [INFO]\tAccumulating evaluatation results...\r\n",
      "2023-03-12 16:47:12 [INFO]\t[EVAL] Finished, Epoch=7, bbox_map=88.986077 .\r\n",
      "2023-03-12 16:47:15 [INFO]\tModel saved in output/faster_rcnn_r50_fpn/best_model.\r\n",
      "2023-03-12 16:47:15 [INFO]\tCurrent evaluated best model on eval_dataset is epoch_7, bbox_map=88.98607702253443\r\n",
      "2023-03-12 16:47:16 [INFO]\tModel saved in output/faster_rcnn_r50_fpn/epoch_7.\r\n",
      "2023-03-12 16:47:19 [INFO]\t[TRAIN] Epoch=8/10, Step=10/490, loss_rpn_cls=0.002787, loss_rpn_reg=0.005532, loss_bbox_cls=0.066149, loss_bbox_reg=0.101083, loss=0.175551, lr=0.000250, time_each_step=0.26s, eta=0:6:50\r\n",
      "2023-03-12 16:47:21 [INFO]\t[TRAIN] Epoch=8/10, Step=20/490, loss_rpn_cls=0.001096, loss_rpn_reg=0.008615, loss_bbox_cls=0.032692, loss_bbox_reg=0.045688, loss=0.088091, lr=0.000250, time_each_step=0.18s, eta=0:5:1\r\n",
      "2023-03-12 16:47:23 [INFO]\t[TRAIN] Epoch=8/10, Step=30/490, loss_rpn_cls=0.000549, loss_rpn_reg=0.003337, loss_bbox_cls=0.024006, loss_bbox_reg=0.058439, loss=0.086331, lr=0.000250, time_each_step=0.21s, eta=0:5:39\r\n",
      "2023-03-12 16:47:25 [INFO]\t[TRAIN] Epoch=8/10, Step=40/490, loss_rpn_cls=0.017428, loss_rpn_reg=0.042300, loss_bbox_cls=0.103999, loss_bbox_reg=0.203719, loss=0.367446, lr=0.000250, time_each_step=0.18s, eta=0:4:54\r\n",
      "2023-03-12 16:47:27 [INFO]\t[TRAIN] Epoch=8/10, Step=50/490, loss_rpn_cls=0.000232, loss_rpn_reg=0.004874, loss_bbox_cls=0.028669, loss_bbox_reg=0.065943, loss=0.099717, lr=0.000250, time_each_step=0.2s, eta=0:5:25\r\n",
      "2023-03-12 16:47:29 [INFO]\t[TRAIN] Epoch=8/10, Step=60/490, loss_rpn_cls=0.002284, loss_rpn_reg=0.001367, loss_bbox_cls=0.033515, loss_bbox_reg=0.057224, loss=0.094391, lr=0.000250, time_each_step=0.19s, eta=0:5:7\r\n",
      "2023-03-12 16:47:31 [INFO]\t[TRAIN] Epoch=8/10, Step=70/490, loss_rpn_cls=0.116225, loss_rpn_reg=0.062555, loss_bbox_cls=0.146150, loss_bbox_reg=0.188412, loss=0.513342, lr=0.000250, time_each_step=0.22s, eta=0:5:44\r\n",
      "2023-03-12 16:47:33 [INFO]\t[TRAIN] Epoch=8/10, Step=80/490, loss_rpn_cls=0.000718, loss_rpn_reg=0.001467, loss_bbox_cls=0.017653, loss_bbox_reg=0.037093, loss=0.056931, lr=0.000250, time_each_step=0.2s, eta=0:5:16\r\n",
      "2023-03-12 16:47:35 [INFO]\t[TRAIN] Epoch=8/10, Step=90/490, loss_rpn_cls=0.000593, loss_rpn_reg=0.004988, loss_bbox_cls=0.022882, loss_bbox_reg=0.055229, loss=0.083692, lr=0.000250, time_each_step=0.24s, eta=0:6:5\r\n",
      "2023-03-12 16:47:38 [INFO]\t[TRAIN] Epoch=8/10, Step=100/490, loss_rpn_cls=0.011923, loss_rpn_reg=0.006327, loss_bbox_cls=0.048978, loss_bbox_reg=0.073316, loss=0.140544, lr=0.000250, time_each_step=0.25s, eta=0:6:13\r\n",
      "2023-03-12 16:47:40 [INFO]\t[TRAIN] Epoch=8/10, Step=110/490, loss_rpn_cls=0.000325, loss_rpn_reg=0.007586, loss_bbox_cls=0.026897, loss_bbox_reg=0.054846, loss=0.089654, lr=0.000250, time_each_step=0.23s, eta=0:5:54\r\n",
      "2023-03-12 16:47:43 [INFO]\t[TRAIN] Epoch=8/10, Step=120/490, loss_rpn_cls=0.015732, loss_rpn_reg=0.039065, loss_bbox_cls=0.106568, loss_bbox_reg=0.223202, loss=0.384566, lr=0.000250, time_each_step=0.24s, eta=0:6:1\r\n",
      "2023-03-12 16:47:45 [INFO]\t[TRAIN] Epoch=8/10, Step=130/490, loss_rpn_cls=0.010546, loss_rpn_reg=0.010877, loss_bbox_cls=0.093684, loss_bbox_reg=0.108027, loss=0.223135, lr=0.000250, time_each_step=0.26s, eta=0:6:18\r\n",
      "2023-03-12 16:47:47 [INFO]\t[TRAIN] Epoch=8/10, Step=140/490, loss_rpn_cls=0.001342, loss_rpn_reg=0.008677, loss_bbox_cls=0.039742, loss_bbox_reg=0.045565, loss=0.095327, lr=0.000250, time_each_step=0.24s, eta=0:6:0\r\n",
      "2023-03-12 16:47:50 [INFO]\t[TRAIN] Epoch=8/10, Step=150/490, loss_rpn_cls=0.009561, loss_rpn_reg=0.011413, loss_bbox_cls=0.037982, loss_bbox_reg=0.067308, loss=0.126264, lr=0.000250, time_each_step=0.25s, eta=0:6:1\r\n",
      "2023-03-12 16:47:52 [INFO]\t[TRAIN] Epoch=8/10, Step=160/490, loss_rpn_cls=0.001407, loss_rpn_reg=0.002637, loss_bbox_cls=0.033449, loss_bbox_reg=0.040969, loss=0.078462, lr=0.000250, time_each_step=0.24s, eta=0:5:56\r\n",
      "2023-03-12 16:47:54 [INFO]\t[TRAIN] Epoch=8/10, Step=170/490, loss_rpn_cls=0.000813, loss_rpn_reg=0.003833, loss_bbox_cls=0.022845, loss_bbox_reg=0.034518, loss=0.062009, lr=0.000250, time_each_step=0.21s, eta=0:5:6\r\n",
      "2023-03-12 16:47:57 [INFO]\t[TRAIN] Epoch=8/10, Step=180/490, loss_rpn_cls=0.000546, loss_rpn_reg=0.005899, loss_bbox_cls=0.027444, loss_bbox_reg=0.046652, loss=0.080542, lr=0.000250, time_each_step=0.24s, eta=0:5:46\r\n",
      "2023-03-12 16:47:59 [INFO]\t[TRAIN] Epoch=8/10, Step=190/490, loss_rpn_cls=0.015729, loss_rpn_reg=0.002712, loss_bbox_cls=0.018601, loss_bbox_reg=0.026092, loss=0.063135, lr=0.000250, time_each_step=0.24s, eta=0:5:37\r\n",
      "2023-03-12 16:48:01 [INFO]\t[TRAIN] Epoch=8/10, Step=200/490, loss_rpn_cls=0.000567, loss_rpn_reg=0.001153, loss_bbox_cls=0.019197, loss_bbox_reg=0.032912, loss=0.053829, lr=0.000250, time_each_step=0.2s, eta=0:4:45\r\n",
      "2023-03-12 16:48:03 [INFO]\t[TRAIN] Epoch=8/10, Step=210/490, loss_rpn_cls=0.000228, loss_rpn_reg=0.004360, loss_bbox_cls=0.016970, loss_bbox_reg=0.055957, loss=0.077514, lr=0.000250, time_each_step=0.19s, eta=0:4:31\r\n",
      "2023-03-12 16:48:05 [INFO]\t[TRAIN] Epoch=8/10, Step=220/490, loss_rpn_cls=0.013477, loss_rpn_reg=0.013528, loss_bbox_cls=0.060609, loss_bbox_reg=0.158870, loss=0.246484, lr=0.000250, time_each_step=0.18s, eta=0:4:24\r\n",
      "2023-03-12 16:48:07 [INFO]\t[TRAIN] Epoch=8/10, Step=230/490, loss_rpn_cls=0.001383, loss_rpn_reg=0.011694, loss_bbox_cls=0.021060, loss_bbox_reg=0.044903, loss=0.079040, lr=0.000250, time_each_step=0.22s, eta=0:5:11\r\n",
      "2023-03-12 16:48:09 [INFO]\t[TRAIN] Epoch=8/10, Step=240/490, loss_rpn_cls=0.010471, loss_rpn_reg=0.009048, loss_bbox_cls=0.092596, loss_bbox_reg=0.124297, loss=0.236412, lr=0.000250, time_each_step=0.19s, eta=0:4:30\r\n",
      "2023-03-12 16:48:11 [INFO]\t[TRAIN] Epoch=8/10, Step=250/490, loss_rpn_cls=0.000158, loss_rpn_reg=0.003756, loss_bbox_cls=0.008807, loss_bbox_reg=0.021300, loss=0.034021, lr=0.000250, time_each_step=0.18s, eta=0:4:15\r\n",
      "2023-03-12 16:48:13 [INFO]\t[TRAIN] Epoch=8/10, Step=260/490, loss_rpn_cls=0.000132, loss_rpn_reg=0.003905, loss_bbox_cls=0.017271, loss_bbox_reg=0.014017, loss=0.035326, lr=0.000250, time_each_step=0.18s, eta=0:4:15\r\n",
      "2023-03-12 16:48:14 [INFO]\t[TRAIN] Epoch=8/10, Step=270/490, loss_rpn_cls=0.000887, loss_rpn_reg=0.007867, loss_bbox_cls=0.017752, loss_bbox_reg=0.034010, loss=0.060517, lr=0.000250, time_each_step=0.18s, eta=0:4:7\r\n",
      "2023-03-12 16:48:16 [INFO]\t[TRAIN] Epoch=8/10, Step=280/490, loss_rpn_cls=0.000709, loss_rpn_reg=0.003511, loss_bbox_cls=0.019831, loss_bbox_reg=0.053463, loss=0.077515, lr=0.000250, time_each_step=0.18s, eta=0:4:14\r\n",
      "2023-03-12 16:48:18 [INFO]\t[TRAIN] Epoch=8/10, Step=290/490, loss_rpn_cls=0.000192, loss_rpn_reg=0.001231, loss_bbox_cls=0.028181, loss_bbox_reg=0.056468, loss=0.086072, lr=0.000250, time_each_step=0.19s, eta=0:4:17\r\n",
      "2023-03-12 16:48:20 [INFO]\t[TRAIN] Epoch=8/10, Step=300/490, loss_rpn_cls=0.011811, loss_rpn_reg=0.003623, loss_bbox_cls=0.045239, loss_bbox_reg=0.076115, loss=0.136788, lr=0.000250, time_each_step=0.18s, eta=0:4:2\r\n",
      "2023-03-12 16:48:22 [INFO]\t[TRAIN] Epoch=8/10, Step=310/490, loss_rpn_cls=0.004395, loss_rpn_reg=0.007841, loss_bbox_cls=0.072573, loss_bbox_reg=0.126271, loss=0.211080, lr=0.000250, time_each_step=0.18s, eta=0:4:0\r\n",
      "2023-03-12 16:48:23 [INFO]\t[TRAIN] Epoch=8/10, Step=320/490, loss_rpn_cls=0.004275, loss_rpn_reg=0.006294, loss_bbox_cls=0.044830, loss_bbox_reg=0.093126, loss=0.148524, lr=0.000250, time_each_step=0.19s, eta=0:4:13\r\n",
      "2023-03-12 16:48:25 [INFO]\t[TRAIN] Epoch=8/10, Step=330/490, loss_rpn_cls=0.002257, loss_rpn_reg=0.006575, loss_bbox_cls=0.136619, loss_bbox_reg=0.183737, loss=0.329189, lr=0.000250, time_each_step=0.18s, eta=0:4:3\r\n",
      "2023-03-12 16:48:27 [INFO]\t[TRAIN] Epoch=8/10, Step=340/490, loss_rpn_cls=0.000461, loss_rpn_reg=0.007440, loss_bbox_cls=0.037502, loss_bbox_reg=0.090141, loss=0.135544, lr=0.000250, time_each_step=0.19s, eta=0:4:6\r\n",
      "2023-03-12 16:48:29 [INFO]\t[TRAIN] Epoch=8/10, Step=350/490, loss_rpn_cls=0.002738, loss_rpn_reg=0.007769, loss_bbox_cls=0.041900, loss_bbox_reg=0.109874, loss=0.162281, lr=0.000250, time_each_step=0.18s, eta=0:3:58\r\n",
      "2023-03-12 16:48:31 [INFO]\t[TRAIN] Epoch=8/10, Step=360/490, loss_rpn_cls=0.024943, loss_rpn_reg=0.009422, loss_bbox_cls=0.042025, loss_bbox_reg=0.080306, loss=0.156696, lr=0.000250, time_each_step=0.18s, eta=0:3:55\r\n",
      "2023-03-12 16:48:33 [INFO]\t[TRAIN] Epoch=8/10, Step=370/490, loss_rpn_cls=0.001184, loss_rpn_reg=0.004403, loss_bbox_cls=0.026262, loss_bbox_reg=0.053552, loss=0.085401, lr=0.000250, time_each_step=0.18s, eta=0:3:57\r\n",
      "2023-03-12 16:48:35 [INFO]\t[TRAIN] Epoch=8/10, Step=380/490, loss_rpn_cls=0.000193, loss_rpn_reg=0.001154, loss_bbox_cls=0.015372, loss_bbox_reg=0.044165, loss=0.060884, lr=0.000250, time_each_step=0.2s, eta=0:4:13\r\n",
      "2023-03-12 16:48:36 [INFO]\t[TRAIN] Epoch=8/10, Step=390/490, loss_rpn_cls=0.011020, loss_rpn_reg=0.009402, loss_bbox_cls=0.028434, loss_bbox_reg=0.047892, loss=0.096748, lr=0.000250, time_each_step=0.19s, eta=0:3:58\r\n",
      "2023-03-12 16:48:38 [INFO]\t[TRAIN] Epoch=8/10, Step=400/490, loss_rpn_cls=0.003670, loss_rpn_reg=0.008553, loss_bbox_cls=0.030516, loss_bbox_reg=0.069556, loss=0.112296, lr=0.000250, time_each_step=0.18s, eta=0:3:51\r\n",
      "2023-03-12 16:48:40 [INFO]\t[TRAIN] Epoch=8/10, Step=410/490, loss_rpn_cls=0.008232, loss_rpn_reg=0.011085, loss_bbox_cls=0.151321, loss_bbox_reg=0.235879, loss=0.406518, lr=0.000250, time_each_step=0.18s, eta=0:3:48\r\n",
      "2023-03-12 16:48:42 [INFO]\t[TRAIN] Epoch=8/10, Step=420/490, loss_rpn_cls=0.002657, loss_rpn_reg=0.002941, loss_bbox_cls=0.044501, loss_bbox_reg=0.087191, loss=0.137289, lr=0.000250, time_each_step=0.19s, eta=0:3:53\r\n",
      "2023-03-12 16:48:44 [INFO]\t[TRAIN] Epoch=8/10, Step=430/490, loss_rpn_cls=0.005974, loss_rpn_reg=0.008351, loss_bbox_cls=0.037700, loss_bbox_reg=0.061123, loss=0.113148, lr=0.000250, time_each_step=0.19s, eta=0:3:53\r\n",
      "2023-03-12 16:48:46 [INFO]\t[TRAIN] Epoch=8/10, Step=440/490, loss_rpn_cls=0.000988, loss_rpn_reg=0.010912, loss_bbox_cls=0.019772, loss_bbox_reg=0.057906, loss=0.089578, lr=0.000250, time_each_step=0.18s, eta=0:3:44\r\n",
      "2023-03-12 16:48:48 [INFO]\t[TRAIN] Epoch=8/10, Step=450/490, loss_rpn_cls=0.001279, loss_rpn_reg=0.004187, loss_bbox_cls=0.084403, loss_bbox_reg=0.129212, loss=0.219081, lr=0.000250, time_each_step=0.18s, eta=0:3:42\r\n",
      "2023-03-12 16:48:49 [INFO]\t[TRAIN] Epoch=8/10, Step=460/490, loss_rpn_cls=0.004361, loss_rpn_reg=0.000854, loss_bbox_cls=0.027506, loss_bbox_reg=0.045761, loss=0.078482, lr=0.000250, time_each_step=0.18s, eta=0:3:39\r\n",
      "2023-03-12 16:48:51 [INFO]\t[TRAIN] Epoch=8/10, Step=470/490, loss_rpn_cls=0.005123, loss_rpn_reg=0.012148, loss_bbox_cls=0.074379, loss_bbox_reg=0.157311, loss=0.248960, lr=0.000250, time_each_step=0.18s, eta=0:3:41\r\n",
      "2023-03-12 16:48:53 [INFO]\t[TRAIN] Epoch=8/10, Step=480/490, loss_rpn_cls=0.019671, loss_rpn_reg=0.008584, loss_bbox_cls=0.033805, loss_bbox_reg=0.090430, loss=0.152489, lr=0.000250, time_each_step=0.17s, eta=0:3:28\r\n",
      "2023-03-12 16:48:55 [INFO]\t[TRAIN] Epoch=8/10, Step=490/490, loss_rpn_cls=0.010170, loss_rpn_reg=0.004814, loss_bbox_cls=0.043251, loss_bbox_reg=0.084218, loss=0.142453, lr=0.000250, time_each_step=0.17s, eta=0:3:23\r\n",
      "2023-03-12 16:48:55 [INFO]\t[TRAIN] Epoch 8 finished, loss_rpn_cls=0.0065862145, loss_rpn_reg=0.00877804, loss_bbox_cls=0.045442495, loss_bbox_reg=0.078355335, loss=0.1391621 .\r\n",
      "2023-03-12 16:48:55 [INFO]\tStart to evaluate(total_samples=140, total_steps=140)...\r\n",
      "2023-03-12 16:49:10 [INFO]\tAccumulating evaluatation results...\r\n",
      "2023-03-12 16:49:10 [INFO]\t[EVAL] Finished, Epoch=8, bbox_map=93.632879 .\r\n",
      "2023-03-12 16:49:13 [INFO]\tModel saved in output/faster_rcnn_r50_fpn/best_model.\r\n",
      "2023-03-12 16:49:13 [INFO]\tCurrent evaluated best model on eval_dataset is epoch_8, bbox_map=93.63287854009332\r\n",
      "2023-03-12 16:49:14 [INFO]\tModel saved in output/faster_rcnn_r50_fpn/epoch_8.\r\n",
      "2023-03-12 16:49:17 [INFO]\t[TRAIN] Epoch=9/10, Step=10/490, loss_rpn_cls=0.028724, loss_rpn_reg=0.014321, loss_bbox_cls=0.083397, loss_bbox_reg=0.217429, loss=0.343871, lr=0.000250, time_each_step=0.25s, eta=0:4:16\r\n",
      "2023-03-12 16:49:19 [INFO]\t[TRAIN] Epoch=9/10, Step=20/490, loss_rpn_cls=0.002356, loss_rpn_reg=0.004595, loss_bbox_cls=0.038031, loss_bbox_reg=0.091980, loss=0.136963, lr=0.000250, time_each_step=0.19s, eta=0:3:17\r\n",
      "2023-03-12 16:49:20 [INFO]\t[TRAIN] Epoch=9/10, Step=30/490, loss_rpn_cls=0.001993, loss_rpn_reg=0.004100, loss_bbox_cls=0.056868, loss_bbox_reg=0.111607, loss=0.174567, lr=0.000250, time_each_step=0.18s, eta=0:3:11\r\n",
      "2023-03-12 16:49:22 [INFO]\t[TRAIN] Epoch=9/10, Step=40/490, loss_rpn_cls=0.004760, loss_rpn_reg=0.016082, loss_bbox_cls=0.042615, loss_bbox_reg=0.102981, loss=0.166438, lr=0.000250, time_each_step=0.17s, eta=0:3:1\r\n",
      "2023-03-12 16:49:24 [INFO]\t[TRAIN] Epoch=9/10, Step=50/490, loss_rpn_cls=0.001698, loss_rpn_reg=0.005573, loss_bbox_cls=0.037055, loss_bbox_reg=0.061601, loss=0.105927, lr=0.000250, time_each_step=0.19s, eta=0:3:11\r\n",
      "2023-03-12 16:49:26 [INFO]\t[TRAIN] Epoch=9/10, Step=60/490, loss_rpn_cls=0.001357, loss_rpn_reg=0.007180, loss_bbox_cls=0.043514, loss_bbox_reg=0.113839, loss=0.165891, lr=0.000250, time_each_step=0.18s, eta=0:3:2\r\n",
      "2023-03-12 16:49:28 [INFO]\t[TRAIN] Epoch=9/10, Step=70/490, loss_rpn_cls=0.004146, loss_rpn_reg=0.055937, loss_bbox_cls=0.097255, loss_bbox_reg=0.132186, loss=0.289523, lr=0.000250, time_each_step=0.18s, eta=0:3:1\r\n",
      "2023-03-12 16:49:29 [INFO]\t[TRAIN] Epoch=9/10, Step=80/490, loss_rpn_cls=0.000806, loss_rpn_reg=0.001284, loss_bbox_cls=0.037920, loss_bbox_reg=0.100524, loss=0.140534, lr=0.000250, time_each_step=0.17s, eta=0:2:55\r\n",
      "2023-03-12 16:49:31 [INFO]\t[TRAIN] Epoch=9/10, Step=90/490, loss_rpn_cls=0.001137, loss_rpn_reg=0.002424, loss_bbox_cls=0.033483, loss_bbox_reg=0.089081, loss=0.126125, lr=0.000250, time_each_step=0.16s, eta=0:2:38\r\n",
      "2023-03-12 16:49:32 [INFO]\t[TRAIN] Epoch=9/10, Step=100/490, loss_rpn_cls=0.008429, loss_rpn_reg=0.003672, loss_bbox_cls=0.019629, loss_bbox_reg=0.042096, loss=0.073825, lr=0.000250, time_each_step=0.14s, eta=0:2:21\r\n",
      "2023-03-12 16:49:34 [INFO]\t[TRAIN] Epoch=9/10, Step=110/490, loss_rpn_cls=0.001037, loss_rpn_reg=0.008327, loss_bbox_cls=0.023412, loss_bbox_reg=0.057460, loss=0.090237, lr=0.000250, time_each_step=0.14s, eta=0:2:23\r\n",
      "2023-03-12 16:49:35 [INFO]\t[TRAIN] Epoch=9/10, Step=120/490, loss_rpn_cls=0.007512, loss_rpn_reg=0.036464, loss_bbox_cls=0.061162, loss_bbox_reg=0.156194, loss=0.261332, lr=0.000250, time_each_step=0.14s, eta=0:2:21\r\n",
      "2023-03-12 16:49:37 [INFO]\t[TRAIN] Epoch=9/10, Step=130/490, loss_rpn_cls=0.003426, loss_rpn_reg=0.009801, loss_bbox_cls=0.064322, loss_bbox_reg=0.107230, loss=0.184779, lr=0.000250, time_each_step=0.15s, eta=0:2:22\r\n",
      "2023-03-12 16:49:38 [INFO]\t[TRAIN] Epoch=9/10, Step=140/490, loss_rpn_cls=0.001783, loss_rpn_reg=0.002185, loss_bbox_cls=0.035844, loss_bbox_reg=0.072476, loss=0.112287, lr=0.000250, time_each_step=0.15s, eta=0:2:23\r\n",
      "2023-03-12 16:49:40 [INFO]\t[TRAIN] Epoch=9/10, Step=150/490, loss_rpn_cls=0.007627, loss_rpn_reg=0.013686, loss_bbox_cls=0.021887, loss_bbox_reg=0.049110, loss=0.092311, lr=0.000250, time_each_step=0.17s, eta=0:2:42\r\n",
      "2023-03-12 16:49:42 [INFO]\t[TRAIN] Epoch=9/10, Step=160/490, loss_rpn_cls=0.011943, loss_rpn_reg=0.002062, loss_bbox_cls=0.017099, loss_bbox_reg=0.046298, loss=0.077402, lr=0.000250, time_each_step=0.23s, eta=0:3:24\r\n",
      "2023-03-12 16:49:44 [INFO]\t[TRAIN] Epoch=9/10, Step=170/490, loss_rpn_cls=0.000297, loss_rpn_reg=0.001602, loss_bbox_cls=0.033171, loss_bbox_reg=0.039961, loss=0.075031, lr=0.000250, time_each_step=0.22s, eta=0:3:17\r\n",
      "2023-03-12 16:49:46 [INFO]\t[TRAIN] Epoch=9/10, Step=180/490, loss_rpn_cls=0.001055, loss_rpn_reg=0.017552, loss_bbox_cls=0.023122, loss_bbox_reg=0.043197, loss=0.084926, lr=0.000250, time_each_step=0.2s, eta=0:2:56\r\n",
      "2023-03-12 16:49:48 [INFO]\t[TRAIN] Epoch=9/10, Step=190/490, loss_rpn_cls=0.000832, loss_rpn_reg=0.004953, loss_bbox_cls=0.049753, loss_bbox_reg=0.113120, loss=0.168658, lr=0.000250, time_each_step=0.14s, eta=0:2:5\r\n",
      "2023-03-12 16:49:49 [INFO]\t[TRAIN] Epoch=9/10, Step=200/490, loss_rpn_cls=0.002755, loss_rpn_reg=0.004804, loss_bbox_cls=0.030412, loss_bbox_reg=0.055073, loss=0.093044, lr=0.000250, time_each_step=0.14s, eta=0:2:7\r\n",
      "2023-03-12 16:49:50 [INFO]\t[TRAIN] Epoch=9/10, Step=210/490, loss_rpn_cls=0.007233, loss_rpn_reg=0.006019, loss_bbox_cls=0.023655, loss_bbox_reg=0.055935, loss=0.092842, lr=0.000250, time_each_step=0.14s, eta=0:2:9\r\n",
      "2023-03-12 16:49:52 [INFO]\t[TRAIN] Epoch=9/10, Step=220/490, loss_rpn_cls=0.010230, loss_rpn_reg=0.035855, loss_bbox_cls=0.092688, loss_bbox_reg=0.209991, loss=0.348764, lr=0.000250, time_each_step=0.14s, eta=0:2:3\r\n",
      "2023-03-12 16:49:53 [INFO]\t[TRAIN] Epoch=9/10, Step=230/490, loss_rpn_cls=0.000853, loss_rpn_reg=0.003988, loss_bbox_cls=0.026569, loss_bbox_reg=0.038428, loss=0.069838, lr=0.000250, time_each_step=0.14s, eta=0:2:3\r\n",
      "2023-03-12 16:49:55 [INFO]\t[TRAIN] Epoch=9/10, Step=240/490, loss_rpn_cls=0.027625, loss_rpn_reg=0.010158, loss_bbox_cls=0.091010, loss_bbox_reg=0.117037, loss=0.245829, lr=0.000250, time_each_step=0.15s, eta=0:2:6\r\n",
      "2023-03-12 16:49:56 [INFO]\t[TRAIN] Epoch=9/10, Step=250/490, loss_rpn_cls=0.001963, loss_rpn_reg=0.008720, loss_bbox_cls=0.030128, loss_bbox_reg=0.081026, loss=0.121838, lr=0.000250, time_each_step=0.14s, eta=0:2:2\r\n",
      "2023-03-12 16:49:58 [INFO]\t[TRAIN] Epoch=9/10, Step=260/490, loss_rpn_cls=0.000519, loss_rpn_reg=0.004478, loss_bbox_cls=0.028703, loss_bbox_reg=0.054000, loss=0.087700, lr=0.000250, time_each_step=0.14s, eta=0:2:0\r\n",
      "2023-03-12 16:49:59 [INFO]\t[TRAIN] Epoch=9/10, Step=270/490, loss_rpn_cls=0.000727, loss_rpn_reg=0.001807, loss_bbox_cls=0.037532, loss_bbox_reg=0.080539, loss=0.120606, lr=0.000250, time_each_step=0.14s, eta=0:2:1\r\n",
      "2023-03-12 16:50:01 [INFO]\t[TRAIN] Epoch=9/10, Step=280/490, loss_rpn_cls=0.001592, loss_rpn_reg=0.004330, loss_bbox_cls=0.062194, loss_bbox_reg=0.062950, loss=0.131067, lr=0.000250, time_each_step=0.15s, eta=0:2:6\r\n",
      "2023-03-12 16:50:02 [INFO]\t[TRAIN] Epoch=9/10, Step=290/490, loss_rpn_cls=0.000328, loss_rpn_reg=0.002386, loss_bbox_cls=0.040898, loss_bbox_reg=0.068056, loss=0.111669, lr=0.000250, time_each_step=0.14s, eta=0:1:53\r\n",
      "2023-03-12 16:50:04 [INFO]\t[TRAIN] Epoch=9/10, Step=300/490, loss_rpn_cls=0.000140, loss_rpn_reg=0.000500, loss_bbox_cls=0.031570, loss_bbox_reg=0.049725, loss=0.081935, lr=0.000250, time_each_step=0.17s, eta=0:2:11\r\n",
      "2023-03-12 16:50:05 [INFO]\t[TRAIN] Epoch=9/10, Step=310/490, loss_rpn_cls=0.004858, loss_rpn_reg=0.006652, loss_bbox_cls=0.167201, loss_bbox_reg=0.156717, loss=0.335427, lr=0.000250, time_each_step=0.15s, eta=0:2:1\r\n",
      "2023-03-12 16:50:07 [INFO]\t[TRAIN] Epoch=9/10, Step=320/490, loss_rpn_cls=0.000165, loss_rpn_reg=0.002265, loss_bbox_cls=0.019907, loss_bbox_reg=0.037995, loss=0.060332, lr=0.000250, time_each_step=0.18s, eta=0:2:14\r\n",
      "2023-03-12 16:50:09 [INFO]\t[TRAIN] Epoch=9/10, Step=330/490, loss_rpn_cls=0.000688, loss_rpn_reg=0.013093, loss_bbox_cls=0.043622, loss_bbox_reg=0.093071, loss=0.150474, lr=0.000250, time_each_step=0.22s, eta=0:2:40\r\n",
      "2023-03-12 16:50:11 [INFO]\t[TRAIN] Epoch=9/10, Step=340/490, loss_rpn_cls=0.004054, loss_rpn_reg=0.004287, loss_bbox_cls=0.037968, loss_bbox_reg=0.060948, loss=0.107257, lr=0.000250, time_each_step=0.18s, eta=0:2:11\r\n",
      "2023-03-12 16:50:13 [INFO]\t[TRAIN] Epoch=9/10, Step=350/490, loss_rpn_cls=0.004661, loss_rpn_reg=0.006160, loss_bbox_cls=0.088953, loss_bbox_reg=0.143109, loss=0.242883, lr=0.000250, time_each_step=0.19s, eta=0:2:20\r\n",
      "2023-03-12 16:50:15 [INFO]\t[TRAIN] Epoch=9/10, Step=360/490, loss_rpn_cls=0.004099, loss_rpn_reg=0.001420, loss_bbox_cls=0.020111, loss_bbox_reg=0.035519, loss=0.061150, lr=0.000250, time_each_step=0.18s, eta=0:2:12\r\n",
      "2023-03-12 16:50:17 [INFO]\t[TRAIN] Epoch=9/10, Step=370/490, loss_rpn_cls=0.006679, loss_rpn_reg=0.004704, loss_bbox_cls=0.030777, loss_bbox_reg=0.062383, loss=0.104543, lr=0.000250, time_each_step=0.2s, eta=0:2:20\r\n",
      "2023-03-12 16:50:18 [INFO]\t[TRAIN] Epoch=9/10, Step=380/490, loss_rpn_cls=0.000418, loss_rpn_reg=0.001341, loss_bbox_cls=0.014445, loss_bbox_reg=0.030394, loss=0.046598, lr=0.000250, time_each_step=0.18s, eta=0:2:5\r\n",
      "2023-03-12 16:50:20 [INFO]\t[TRAIN] Epoch=9/10, Step=390/490, loss_rpn_cls=0.005967, loss_rpn_reg=0.012235, loss_bbox_cls=0.035465, loss_bbox_reg=0.061040, loss=0.114706, lr=0.000250, time_each_step=0.18s, eta=0:2:2\r\n",
      "2023-03-12 16:50:22 [INFO]\t[TRAIN] Epoch=9/10, Step=400/490, loss_rpn_cls=0.001760, loss_rpn_reg=0.009498, loss_bbox_cls=0.032866, loss_bbox_reg=0.069674, loss=0.113799, lr=0.000250, time_each_step=0.18s, eta=0:2:4\r\n",
      "2023-03-12 16:50:24 [INFO]\t[TRAIN] Epoch=9/10, Step=410/490, loss_rpn_cls=0.004470, loss_rpn_reg=0.018582, loss_bbox_cls=0.076738, loss_bbox_reg=0.147069, loss=0.246859, lr=0.000250, time_each_step=0.18s, eta=0:2:0\r\n",
      "2023-03-12 16:50:26 [INFO]\t[TRAIN] Epoch=9/10, Step=420/490, loss_rpn_cls=0.000908, loss_rpn_reg=0.003809, loss_bbox_cls=0.036850, loss_bbox_reg=0.054620, loss=0.096187, lr=0.000250, time_each_step=0.2s, eta=0:2:11\r\n",
      "2023-03-12 16:50:27 [INFO]\t[TRAIN] Epoch=9/10, Step=430/490, loss_rpn_cls=0.001206, loss_rpn_reg=0.005874, loss_bbox_cls=0.036478, loss_bbox_reg=0.048946, loss=0.092504, lr=0.000250, time_each_step=0.18s, eta=0:1:55\r\n",
      "2023-03-12 16:50:29 [INFO]\t[TRAIN] Epoch=9/10, Step=440/490, loss_rpn_cls=0.003210, loss_rpn_reg=0.001695, loss_bbox_cls=0.035936, loss_bbox_reg=0.050685, loss=0.091525, lr=0.000250, time_each_step=0.19s, eta=0:2:1\r\n",
      "2023-03-12 16:50:32 [INFO]\t[TRAIN] Epoch=9/10, Step=450/490, loss_rpn_cls=0.000689, loss_rpn_reg=0.006006, loss_bbox_cls=0.083578, loss_bbox_reg=0.188759, loss=0.279032, lr=0.000250, time_each_step=0.22s, eta=0:2:17\r\n",
      "2023-03-12 16:50:34 [INFO]\t[TRAIN] Epoch=9/10, Step=460/490, loss_rpn_cls=0.004869, loss_rpn_reg=0.000492, loss_bbox_cls=0.059166, loss_bbox_reg=0.087440, loss=0.151967, lr=0.000250, time_each_step=0.26s, eta=0:2:31\r\n",
      "2023-03-12 16:50:36 [INFO]\t[TRAIN] Epoch=9/10, Step=470/490, loss_rpn_cls=0.016348, loss_rpn_reg=0.014488, loss_bbox_cls=0.082092, loss_bbox_reg=0.167927, loss=0.280854, lr=0.000250, time_each_step=0.19s, eta=0:1:54\r\n",
      "2023-03-12 16:50:38 [INFO]\t[TRAIN] Epoch=9/10, Step=480/490, loss_rpn_cls=0.000647, loss_rpn_reg=0.003394, loss_bbox_cls=0.039243, loss_bbox_reg=0.079643, loss=0.122926, lr=0.000250, time_each_step=0.18s, eta=0:1:50\r\n",
      "2023-03-12 16:50:40 [INFO]\t[TRAIN] Epoch=9/10, Step=490/490, loss_rpn_cls=0.000493, loss_rpn_reg=0.006183, loss_bbox_cls=0.023456, loss_bbox_reg=0.063446, loss=0.093578, lr=0.000250, time_each_step=0.18s, eta=0:1:44\r\n",
      "2023-03-12 16:50:40 [INFO]\t[TRAIN] Epoch 9 finished, loss_rpn_cls=0.0046038902, loss_rpn_reg=0.008153945, loss_bbox_cls=0.044217207, loss_bbox_reg=0.08092592, loss=0.13790096 .\r\n",
      "2023-03-12 16:50:40 [INFO]\tStart to evaluate(total_samples=140, total_steps=140)...\r\n",
      "2023-03-12 16:50:55 [INFO]\tAccumulating evaluatation results...\r\n",
      "2023-03-12 16:50:55 [INFO]\t[EVAL] Finished, Epoch=9, bbox_map=93.135401 .\r\n",
      "2023-03-12 16:50:55 [INFO]\tCurrent evaluated best model on eval_dataset is epoch_8, bbox_map=93.63287854009332\r\n",
      "2023-03-12 16:50:56 [INFO]\tModel saved in output/faster_rcnn_r50_fpn/epoch_9.\r\n",
      "2023-03-12 16:50:59 [INFO]\t[TRAIN] Epoch=10/10, Step=10/490, loss_rpn_cls=0.010390, loss_rpn_reg=0.017002, loss_bbox_cls=0.074709, loss_bbox_reg=0.142014, loss=0.244115, lr=0.000250, time_each_step=0.22s, eta=0:1:43\r\n",
      "2023-03-12 16:51:00 [INFO]\t[TRAIN] Epoch=10/10, Step=20/490, loss_rpn_cls=0.000998, loss_rpn_reg=0.015570, loss_bbox_cls=0.038507, loss_bbox_reg=0.112849, loss=0.167924, lr=0.000250, time_each_step=0.17s, eta=0:1:22\r\n",
      "2023-03-12 16:51:02 [INFO]\t[TRAIN] Epoch=10/10, Step=30/490, loss_rpn_cls=0.002675, loss_rpn_reg=0.005188, loss_bbox_cls=0.039351, loss_bbox_reg=0.086046, loss=0.133260, lr=0.000250, time_each_step=0.18s, eta=0:1:20\r\n",
      "2023-03-12 16:51:04 [INFO]\t[TRAIN] Epoch=10/10, Step=40/490, loss_rpn_cls=0.001800, loss_rpn_reg=0.011408, loss_bbox_cls=0.040510, loss_bbox_reg=0.095181, loss=0.148899, lr=0.000250, time_each_step=0.18s, eta=0:1:20\r\n",
      "2023-03-12 16:51:06 [INFO]\t[TRAIN] Epoch=10/10, Step=50/490, loss_rpn_cls=0.000682, loss_rpn_reg=0.007817, loss_bbox_cls=0.030551, loss_bbox_reg=0.053377, loss=0.092427, lr=0.000250, time_each_step=0.17s, eta=0:1:16\r\n",
      "2023-03-12 16:51:07 [INFO]\t[TRAIN] Epoch=10/10, Step=60/490, loss_rpn_cls=0.000624, loss_rpn_reg=0.001588, loss_bbox_cls=0.022747, loss_bbox_reg=0.047558, loss=0.072518, lr=0.000250, time_each_step=0.18s, eta=0:1:16\r\n",
      "2023-03-12 16:51:09 [INFO]\t[TRAIN] Epoch=10/10, Step=70/490, loss_rpn_cls=0.002665, loss_rpn_reg=0.032804, loss_bbox_cls=0.100520, loss_bbox_reg=0.194749, loss=0.330738, lr=0.000250, time_each_step=0.18s, eta=0:1:14\r\n",
      "2023-03-12 16:51:11 [INFO]\t[TRAIN] Epoch=10/10, Step=80/490, loss_rpn_cls=0.000685, loss_rpn_reg=0.002124, loss_bbox_cls=0.029070, loss_bbox_reg=0.079965, loss=0.111846, lr=0.000250, time_each_step=0.18s, eta=0:1:12\r\n",
      "2023-03-12 16:51:13 [INFO]\t[TRAIN] Epoch=10/10, Step=90/490, loss_rpn_cls=0.002521, loss_rpn_reg=0.009002, loss_bbox_cls=0.036023, loss_bbox_reg=0.106246, loss=0.153792, lr=0.000250, time_each_step=0.18s, eta=0:1:13\r\n",
      "2023-03-12 16:51:15 [INFO]\t[TRAIN] Epoch=10/10, Step=100/490, loss_rpn_cls=0.004416, loss_rpn_reg=0.015969, loss_bbox_cls=0.032896, loss_bbox_reg=0.117545, loss=0.170826, lr=0.000250, time_each_step=0.18s, eta=0:1:11\r\n",
      "2023-03-12 16:51:16 [INFO]\t[TRAIN] Epoch=10/10, Step=110/490, loss_rpn_cls=0.006571, loss_rpn_reg=0.008167, loss_bbox_cls=0.027151, loss_bbox_reg=0.060143, loss=0.102032, lr=0.000250, time_each_step=0.18s, eta=0:1:9\r\n",
      "2023-03-12 16:51:18 [INFO]\t[TRAIN] Epoch=10/10, Step=120/490, loss_rpn_cls=0.049072, loss_rpn_reg=0.031955, loss_bbox_cls=0.070897, loss_bbox_reg=0.130915, loss=0.282839, lr=0.000250, time_each_step=0.18s, eta=0:1:6\r\n",
      "2023-03-12 16:51:20 [INFO]\t[TRAIN] Epoch=10/10, Step=130/490, loss_rpn_cls=0.008279, loss_rpn_reg=0.009336, loss_bbox_cls=0.057123, loss_bbox_reg=0.142728, loss=0.217466, lr=0.000250, time_each_step=0.19s, eta=0:1:7\r\n",
      "2023-03-12 16:51:22 [INFO]\t[TRAIN] Epoch=10/10, Step=140/490, loss_rpn_cls=0.001053, loss_rpn_reg=0.004929, loss_bbox_cls=0.019736, loss_bbox_reg=0.037352, loss=0.063069, lr=0.000250, time_each_step=0.17s, eta=0:1:0\r\n",
      "2023-03-12 16:51:24 [INFO]\t[TRAIN] Epoch=10/10, Step=150/490, loss_rpn_cls=0.002270, loss_rpn_reg=0.025047, loss_bbox_cls=0.049196, loss_bbox_reg=0.090297, loss=0.166810, lr=0.000250, time_each_step=0.2s, eta=0:1:6\r\n",
      "2023-03-12 16:51:26 [INFO]\t[TRAIN] Epoch=10/10, Step=160/490, loss_rpn_cls=0.018842, loss_rpn_reg=0.002284, loss_bbox_cls=0.025063, loss_bbox_reg=0.069643, loss=0.115833, lr=0.000250, time_each_step=0.18s, eta=0:0:59\r\n",
      "2023-03-12 16:51:27 [INFO]\t[TRAIN] Epoch=10/10, Step=170/490, loss_rpn_cls=0.013539, loss_rpn_reg=0.008504, loss_bbox_cls=0.035189, loss_bbox_reg=0.052751, loss=0.109983, lr=0.000250, time_each_step=0.17s, eta=0:0:55\r\n",
      "2023-03-12 16:51:29 [INFO]\t[TRAIN] Epoch=10/10, Step=180/490, loss_rpn_cls=0.000426, loss_rpn_reg=0.005621, loss_bbox_cls=0.023443, loss_bbox_reg=0.049252, loss=0.078742, lr=0.000250, time_each_step=0.18s, eta=0:0:56\r\n",
      "2023-03-12 16:51:31 [INFO]\t[TRAIN] Epoch=10/10, Step=190/490, loss_rpn_cls=0.000495, loss_rpn_reg=0.002263, loss_bbox_cls=0.021983, loss_bbox_reg=0.033155, loss=0.057897, lr=0.000250, time_each_step=0.18s, eta=0:0:54\r\n",
      "2023-03-12 16:51:33 [INFO]\t[TRAIN] Epoch=10/10, Step=200/490, loss_rpn_cls=0.000371, loss_rpn_reg=0.003103, loss_bbox_cls=0.016234, loss_bbox_reg=0.016185, loss=0.035894, lr=0.000250, time_each_step=0.18s, eta=0:0:52\r\n",
      "2023-03-12 16:51:35 [INFO]\t[TRAIN] Epoch=10/10, Step=210/490, loss_rpn_cls=0.005706, loss_rpn_reg=0.015582, loss_bbox_cls=0.029297, loss_bbox_reg=0.076988, loss=0.127573, lr=0.000250, time_each_step=0.19s, eta=0:0:52\r\n",
      "2023-03-12 16:51:37 [INFO]\t[TRAIN] Epoch=10/10, Step=220/490, loss_rpn_cls=0.011940, loss_rpn_reg=0.023607, loss_bbox_cls=0.078448, loss_bbox_reg=0.151317, loss=0.265313, lr=0.000250, time_each_step=0.19s, eta=0:0:52\r\n",
      "2023-03-12 16:51:38 [INFO]\t[TRAIN] Epoch=10/10, Step=230/490, loss_rpn_cls=0.000188, loss_rpn_reg=0.002969, loss_bbox_cls=0.014955, loss_bbox_reg=0.036075, loss=0.054187, lr=0.000250, time_each_step=0.18s, eta=0:0:45\r\n",
      "2023-03-12 16:51:40 [INFO]\t[TRAIN] Epoch=10/10, Step=240/490, loss_rpn_cls=0.002754, loss_rpn_reg=0.004755, loss_bbox_cls=0.050287, loss_bbox_reg=0.089678, loss=0.147473, lr=0.000250, time_each_step=0.17s, eta=0:0:43\r\n",
      "2023-03-12 16:51:42 [INFO]\t[TRAIN] Epoch=10/10, Step=250/490, loss_rpn_cls=0.000198, loss_rpn_reg=0.002885, loss_bbox_cls=0.018299, loss_bbox_reg=0.030066, loss=0.051448, lr=0.000250, time_each_step=0.18s, eta=0:0:44\r\n",
      "2023-03-12 16:51:44 [INFO]\t[TRAIN] Epoch=10/10, Step=260/490, loss_rpn_cls=0.000303, loss_rpn_reg=0.000928, loss_bbox_cls=0.021838, loss_bbox_reg=0.028562, loss=0.051631, lr=0.000250, time_each_step=0.19s, eta=0:0:44\r\n",
      "2023-03-12 16:51:46 [INFO]\t[TRAIN] Epoch=10/10, Step=270/490, loss_rpn_cls=0.001923, loss_rpn_reg=0.006973, loss_bbox_cls=0.021650, loss_bbox_reg=0.047380, loss=0.077925, lr=0.000250, time_each_step=0.18s, eta=0:0:39\r\n",
      "2023-03-12 16:51:47 [INFO]\t[TRAIN] Epoch=10/10, Step=280/490, loss_rpn_cls=0.001273, loss_rpn_reg=0.012134, loss_bbox_cls=0.038118, loss_bbox_reg=0.096698, loss=0.148221, lr=0.000250, time_each_step=0.18s, eta=0:0:37\r\n",
      "2023-03-12 16:51:49 [INFO]\t[TRAIN] Epoch=10/10, Step=290/490, loss_rpn_cls=0.000595, loss_rpn_reg=0.004328, loss_bbox_cls=0.040683, loss_bbox_reg=0.072153, loss=0.117759, lr=0.000250, time_each_step=0.2s, eta=0:0:39\r\n",
      "2023-03-12 16:51:51 [INFO]\t[TRAIN] Epoch=10/10, Step=300/490, loss_rpn_cls=0.001591, loss_rpn_reg=0.006155, loss_bbox_cls=0.021951, loss_bbox_reg=0.071308, loss=0.101004, lr=0.000250, time_each_step=0.2s, eta=0:0:38\r\n",
      "2023-03-12 16:51:53 [INFO]\t[TRAIN] Epoch=10/10, Step=310/490, loss_rpn_cls=0.004865, loss_rpn_reg=0.005064, loss_bbox_cls=0.036493, loss_bbox_reg=0.106660, loss=0.153082, lr=0.000250, time_each_step=0.2s, eta=0:0:35\r\n",
      "2023-03-12 16:51:55 [INFO]\t[TRAIN] Epoch=10/10, Step=320/490, loss_rpn_cls=0.000271, loss_rpn_reg=0.001621, loss_bbox_cls=0.011237, loss_bbox_reg=0.017881, loss=0.031011, lr=0.000250, time_each_step=0.18s, eta=0:0:30\r\n",
      "2023-03-12 16:51:57 [INFO]\t[TRAIN] Epoch=10/10, Step=330/490, loss_rpn_cls=0.009483, loss_rpn_reg=0.008938, loss_bbox_cls=0.111361, loss_bbox_reg=0.173670, loss=0.303453, lr=0.000250, time_each_step=0.18s, eta=0:0:28\r\n",
      "2023-03-12 16:51:59 [INFO]\t[TRAIN] Epoch=10/10, Step=340/490, loss_rpn_cls=0.003070, loss_rpn_reg=0.004682, loss_bbox_cls=0.031635, loss_bbox_reg=0.074558, loss=0.113944, lr=0.000250, time_each_step=0.18s, eta=0:0:26\r\n",
      "2023-03-12 16:52:01 [INFO]\t[TRAIN] Epoch=10/10, Step=350/490, loss_rpn_cls=0.005440, loss_rpn_reg=0.006470, loss_bbox_cls=0.039466, loss_bbox_reg=0.048786, loss=0.100162, lr=0.000250, time_each_step=0.17s, eta=0:0:24\r\n",
      "2023-03-12 16:52:02 [INFO]\t[TRAIN] Epoch=10/10, Step=360/490, loss_rpn_cls=0.001078, loss_rpn_reg=0.001206, loss_bbox_cls=0.018846, loss_bbox_reg=0.025774, loss=0.046904, lr=0.000250, time_each_step=0.17s, eta=0:0:22\r\n",
      "2023-03-12 16:52:04 [INFO]\t[TRAIN] Epoch=10/10, Step=370/490, loss_rpn_cls=0.004028, loss_rpn_reg=0.002032, loss_bbox_cls=0.018132, loss_bbox_reg=0.050553, loss=0.074745, lr=0.000250, time_each_step=0.18s, eta=0:0:21\r\n",
      "2023-03-12 16:52:06 [INFO]\t[TRAIN] Epoch=10/10, Step=380/490, loss_rpn_cls=0.000156, loss_rpn_reg=0.001676, loss_bbox_cls=0.016646, loss_bbox_reg=0.015882, loss=0.034360, lr=0.000250, time_each_step=0.19s, eta=0:0:20\r\n",
      "2023-03-12 16:52:08 [INFO]\t[TRAIN] Epoch=10/10, Step=390/490, loss_rpn_cls=0.000635, loss_rpn_reg=0.003668, loss_bbox_cls=0.040884, loss_bbox_reg=0.067016, loss=0.112202, lr=0.000250, time_each_step=0.18s, eta=0:0:17\r\n",
      "2023-03-12 16:52:09 [INFO]\t[TRAIN] Epoch=10/10, Step=400/490, loss_rpn_cls=0.012105, loss_rpn_reg=0.011689, loss_bbox_cls=0.037566, loss_bbox_reg=0.094528, loss=0.155888, lr=0.000250, time_each_step=0.18s, eta=0:0:15\r\n",
      "2023-03-12 16:52:11 [INFO]\t[TRAIN] Epoch=10/10, Step=410/490, loss_rpn_cls=0.022154, loss_rpn_reg=0.047589, loss_bbox_cls=0.027933, loss_bbox_reg=0.017290, loss=0.114966, lr=0.000250, time_each_step=0.17s, eta=0:0:13\r\n",
      "2023-03-12 16:52:13 [INFO]\t[TRAIN] Epoch=10/10, Step=420/490, loss_rpn_cls=0.005049, loss_rpn_reg=0.005638, loss_bbox_cls=0.031834, loss_bbox_reg=0.070990, loss=0.113511, lr=0.000250, time_each_step=0.19s, eta=0:0:13\r\n",
      "2023-03-12 16:52:15 [INFO]\t[TRAIN] Epoch=10/10, Step=430/490, loss_rpn_cls=0.024015, loss_rpn_reg=0.016097, loss_bbox_cls=0.054401, loss_bbox_reg=0.053545, loss=0.148058, lr=0.000250, time_each_step=0.18s, eta=0:0:10\r\n",
      "2023-03-12 16:52:17 [INFO]\t[TRAIN] Epoch=10/10, Step=440/490, loss_rpn_cls=0.013685, loss_rpn_reg=0.010868, loss_bbox_cls=0.025797, loss_bbox_reg=0.056330, loss=0.106680, lr=0.000250, time_each_step=0.18s, eta=0:0:8\r\n",
      "2023-03-12 16:52:19 [INFO]\t[TRAIN] Epoch=10/10, Step=450/490, loss_rpn_cls=0.002093, loss_rpn_reg=0.004985, loss_bbox_cls=0.138307, loss_bbox_reg=0.219669, loss=0.365054, lr=0.000250, time_each_step=0.19s, eta=0:0:7\r\n",
      "2023-03-12 16:52:20 [INFO]\t[TRAIN] Epoch=10/10, Step=460/490, loss_rpn_cls=0.001148, loss_rpn_reg=0.014834, loss_bbox_cls=0.033161, loss_bbox_reg=0.125812, loss=0.174956, lr=0.000250, time_each_step=0.18s, eta=0:0:5\r\n",
      "2023-03-12 16:52:22 [INFO]\t[TRAIN] Epoch=10/10, Step=470/490, loss_rpn_cls=0.004466, loss_rpn_reg=0.013612, loss_bbox_cls=0.112375, loss_bbox_reg=0.139218, loss=0.269672, lr=0.000250, time_each_step=0.18s, eta=0:0:3\r\n",
      "2023-03-12 16:52:24 [INFO]\t[TRAIN] Epoch=10/10, Step=480/490, loss_rpn_cls=0.000636, loss_rpn_reg=0.004512, loss_bbox_cls=0.045117, loss_bbox_reg=0.036276, loss=0.086540, lr=0.000250, time_each_step=0.18s, eta=0:0:1\r\n",
      "2023-03-12 16:52:26 [INFO]\t[TRAIN] Epoch=10/10, Step=490/490, loss_rpn_cls=0.000738, loss_rpn_reg=0.008568, loss_bbox_cls=0.025597, loss_bbox_reg=0.079343, loss=0.114246, lr=0.000250, time_each_step=0.17s, eta=0:0:0\r\n",
      "2023-03-12 16:52:26 [INFO]\t[TRAIN] Epoch 10 finished, loss_rpn_cls=0.0060860496, loss_rpn_reg=0.008098722, loss_bbox_cls=0.04265328, loss_bbox_reg=0.07838757, loss=0.13522562 .\r\n",
      "2023-03-12 16:52:26 [INFO]\tStart to evaluate(total_samples=140, total_steps=140)...\r\n",
      "2023-03-12 16:52:41 [INFO]\tAccumulating evaluatation results...\r\n",
      "2023-03-12 16:52:41 [INFO]\t[EVAL] Finished, Epoch=10, bbox_map=94.985060 .\r\n",
      "2023-03-12 16:52:44 [INFO]\tModel saved in output/faster_rcnn_r50_fpn/best_model.\r\n",
      "2023-03-12 16:52:44 [INFO]\tCurrent evaluated best model on eval_dataset is epoch_10, bbox_map=94.98506011562284\r\n",
      "2023-03-12 16:52:45 [INFO]\tModel saved in output/faster_rcnn_r50_fpn/epoch_10.\r\n"
     ]
    }
   ],
   "source": [
    "# 模型训练  Faster RCNN\n",
    "num_classes = len(train_dataset.labels)\n",
    "print(num_classes)\n",
    "model = pdx.det.FasterRCNN(num_classes=num_classes, backbone='ResNet50')\n",
    "model.train(\n",
    "    num_epochs=10,\n",
    "    train_dataset=train_dataset,\n",
    "    train_batch_size=1,\n",
    "    eval_dataset=eval_dataset,\n",
    "    save_interval_epochs=1,\n",
    "    learning_rate=0.00025,\n",
    "    # learning_rate=0.0001,\n",
    "    # lr_decay_epochs = [3,6],\n",
    "    # lr_decay_gamma = 0.1,\n",
    "    metric='VOC',\n",
    "    save_dir='output/faster_rcnn_r50_fpn',\n",
    "    use_vdl=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-03-12 16:52:46 [INFO]\tModel[FasterRCNN] loaded.\r\n",
      "2023-03-12 16:52:46 [INFO]\tStart to evaluate(total_samples=140, total_steps=140)...\r\n",
      "2023-03-12 16:53:01 [INFO]\tAccumulating evaluatation results...\r\n",
      "eval result:\r\n",
      " OrderedDict([('bbox_map', 94.98506011562284)])\r\n"
     ]
    }
   ],
   "source": [
    "# 在验证集上进行评估\n",
    "import paddlex as pdx\n",
    "model = pdx.load_model('output/faster_rcnn_r50_fpn/best_model')  # 加载模型\n",
    "eval_result = model.evaluate(eval_dataset, batch_size=1, return_details=False)\n",
    "# eval_result = model.evaluate(eval_dataset, batch_size=1, return_details=True)\n",
    "print('eval result:\\n',eval_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-03-12 16:57:36 [INFO]\tModel[FasterRCNN] loaded.\r\n",
      "Predict Result:  [{'category_id': 0, 'category': 'Person', 'bbox': [267.6619567871094, 265.86968994140625, 176.98269653320312, 502.552978515625], 'score': 0.9902663826942444}, {'category_id': 0, 'category': 'Person', 'bbox': [267.6175231933594, 276.1723937988281, 91.35528564453125, 507.5971374511719], 'score': 0.09246087074279785}]\r\n",
      "2023-03-12 16:57:36 [INFO]\tThe visualized result is saved at ./result/visualize_12.jpg\r\n"
     ]
    }
   ],
   "source": [
    "# 模型预测\n",
    "import paddlex as pdx\n",
    "img = r'photo/12.jpg'\n",
    "model = pdx.load_model('output/faster_rcnn_r50_fpn/best_model')\n",
    "result = model.predict(img)\n",
    "print(\"Predict Result: \", result)\n",
    "pdx.det.visualize(img, result, save_dir='./result',threshold=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[03-12 16:57:41 MainThread @logger.py:242] Argv: /opt/conda/envs/python35-paddle120-env/bin/paddlex --export_inference --model_dir=output/faster_rcnn_r50_fpn/best_model --save_dir=output\r\n",
      "[03-12 16:57:41 MainThread @utils.py:79] WRN paddlepaddle version: 2.3.2. The dynamic graph version of PARL is under development, not fully tested and supported\r\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/parl/remote/communication.py:38: FutureWarning: 'pyarrow.default_serialization_context' is deprecated as of 2.0.0 and will be removed in a future version. Use pickle or the pyarrow IPC functionality instead.\r\n",
      "  context = pyarrow.default_serialization_context()\r\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/matplotlib/__init__.py:107: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\r\n",
      "  from collections import MutableMapping\r\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/matplotlib/rcsetup.py:20: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\r\n",
      "  from collections import Iterable, Mapping\r\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/matplotlib/colors.py:53: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\r\n",
      "  from collections import Sized\r\n",
      "2023-03-12 16:57:42,002-WARNING: type object 'QuantizationTransformPass' has no attribute '_supported_quantizable_op_type'\r\n",
      "2023-03-12 16:57:42,002-WARNING: If you want to use training-aware and post-training quantization, please use Paddle >= 1.8.4 or develop version\r\n",
      "W0312 16:57:43.877409  3069 gpu_resources.cc:61] Please NOTE: device: 0, GPU Compute Capability: 7.0, Driver API Version: 11.2, Runtime API Version: 11.2\r\n",
      "W0312 16:57:43.883653  3069 gpu_resources.cc:91] device: 0, cuDNN Version: 8.2.\r\n",
      "2023-03-12 16:57:44 [INFO]\tModel[FasterRCNN] loaded.\r\n",
      "2023-03-12 16:57:53 [INFO]\tThe model for the inference deployment is saved in output/inference_model.\r\n"
     ]
    }
   ],
   "source": [
    "# 转化为inference模型\n",
    "!paddlex --export_inference --model_dir=output/faster_rcnn_r50_fpn/best_model --save_dir=output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-03-24T06:52:28.869767Z",
     "iopub.status.busy": "2023-03-24T06:52:28.869039Z",
     "iopub.status.idle": "2023-03-24T06:52:33.669339Z",
     "shell.execute_reply": "2023-03-24T06:52:33.668487Z",
     "shell.execute_reply.started": "2023-03-24T06:52:28.869731Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-03-24 14:52:32 [INFO]\tModel[FasterRCNN] loaded.\r\n",
      "Predict Result:  [{'category_id': 0, 'category': 'Person', 'bbox': [201.72789001464844, 318.3688049316406, 120.42369079589844, 467.1354675292969], 'score': 0.9633339643478394}, {'category_id': 0, 'category': 'Person', 'bbox': [357.6348876953125, 295.7972106933594, 137.32931518554688, 505.8344421386719], 'score': 0.9691698551177979}, {'category_id': 0, 'category': 'Person', 'bbox': [250.74049377441406, 312.01397705078125, 123.40846252441406, 492.17193603515625], 'score': 0.2949315011501312}, {'category_id': 0, 'category': 'Person', 'bbox': [196.59852600097656, 340.4701232910156, 72.10856628417969, 418.8099060058594], 'score': 0.12481983751058578}, {'category_id': 0, 'category': 'Person', 'bbox': [216.89573669433594, 295.96002197265625, 287.16148376464844, 495.43499755859375], 'score': 0.8195303678512573}, {'category_id': 0, 'category': 'Person', 'bbox': [260.0248107910156, 319.1795959472656, 51.749908447265625, 431.9230651855469], 'score': 0.10527005791664124}]\r\n",
      "2023-03-24 14:52:33 [INFO]\tThe visualized result is saved at ./result/visualize_684.jpg\r\n"
     ]
    }
   ],
   "source": [
    "# 模型预测\n",
    "import paddlex as pdx\n",
    "img = r'photo/684.jpg'\n",
    "model = pdx.load_model('output/inference_model')\n",
    "result = model.predict(img)\n",
    "print(\"Predict Result: \", result)\n",
    "pdx.det.visualize(img, result, save_dir='./result',threshold=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
